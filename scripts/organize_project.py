#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é¡¹ç›®æ•´ç†è„šæœ¬ - æ•´ç†ä»£ç æ–‡ä»¶å¤¹ç»“æ„
"""

import os
import shutil
import json
from datetime import datetime

class ProjectOrganizer:
    def __init__(self):
        self.root_dir = os.getcwd()
        self.timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # å®šä¹‰æ–‡ä»¶åˆ†ç±»è§„åˆ™
        self.file_categories = {
            'python_scripts': {
                'extensions': ['.py'],
                'target_dir': 'src',
                'description': 'Pythonè„šæœ¬æ–‡ä»¶'
            },
            'data_files': {
                'extensions': ['.json', '.csv'],
                'target_dir': 'data',
                'description': 'æ•°æ®æ–‡ä»¶'
            },
            'html_files': {
                'extensions': ['.html'],
                'target_dir': 'html_sources',
                'description': 'HTMLæºç æ–‡ä»¶'
            },
            'reports': {
                'extensions': ['.txt', '.md'],
                'patterns': ['æŠ¥å‘Š', 'ç»Ÿè®¡', 'åˆ†æ', 'æ£€æŸ¥', 'README', 'DEPLOYMENT'],
                'target_dir': 'reports',
                'description': 'æŠ¥å‘Šå’Œæ–‡æ¡£æ–‡ä»¶'
            },
            'config_files': {
                'extensions': ['.bat', '.txt'],
                'patterns': ['requirements', 'install', 'run_', 'git_', 'commands'],
                'target_dir': 'scripts',
                'description': 'é…ç½®å’Œè¿è¡Œè„šæœ¬'
            },
            'docs': {
                'extensions': ['.md'],
                'patterns': ['README', 'LICENSE', 'CHECKLIST', 'PUBLISH'],
                'target_dir': 'docs',
                'description': 'é¡¹ç›®æ–‡æ¡£'
            }
        }
        
        # éœ€è¦åˆ›å»ºçš„ç›®å½•ç»“æ„
        self.directories = [
            'src',           # æºä»£ç 
            'data',          # æ•°æ®æ–‡ä»¶
            'data/guangdong', # å¹¿ä¸œçœæ•°æ®
            'data/archive',   # æ—§æ•°æ®å½’æ¡£
            'html_sources',   # HTMLæºç 
            'html_sources/guangdong', # å¹¿ä¸œçœHTML
            'html_sources/archive',   # æ—§HTMLå½’æ¡£
            'reports',        # æŠ¥å‘Š
            'reports/guangdong', # å¹¿ä¸œçœæŠ¥å‘Š
            'reports/archive',   # æ—§æŠ¥å‘Šå½’æ¡£
            'scripts',        # è„šæœ¬æ–‡ä»¶
            'docs',           # æ–‡æ¡£
            'backup'          # å¤‡ä»½
        ]
    
    def create_directory_structure(self):
        """åˆ›å»ºç›®å½•ç»“æ„"""
        print("ğŸ“ åˆ›å»ºç›®å½•ç»“æ„...")
        
        for directory in self.directories:
            dir_path = os.path.join(self.root_dir, directory)
            os.makedirs(dir_path, exist_ok=True)
            print(f"  âœ… åˆ›å»ºç›®å½•: {directory}")
        
        print("âœ… ç›®å½•ç»“æ„åˆ›å»ºå®Œæˆ")
    
    def analyze_files(self):
        """åˆ†æå½“å‰ç›®å½•ä¸­çš„æ–‡ä»¶"""
        print("\nğŸ” åˆ†æå½“å‰æ–‡ä»¶...")
        
        files_info = []
        
        for filename in os.listdir(self.root_dir):
            if os.path.isfile(os.path.join(self.root_dir, filename)):
                file_info = {
                    'name': filename,
                    'extension': os.path.splitext(filename)[1].lower(),
                    'size': os.path.getsize(filename),
                    'category': self.categorize_file(filename),
                    'target_dir': None
                }
                
                # ç¡®å®šç›®æ ‡ç›®å½•
                category = file_info['category']
                if category in self.file_categories:
                    file_info['target_dir'] = self.file_categories[category]['target_dir']
                
                files_info.append(file_info)
                print(f"  ğŸ“„ {filename} -> {file_info['category']} -> {file_info['target_dir']}")
        
        return files_info
    
    def categorize_file(self, filename):
        """æ ¹æ®æ–‡ä»¶åå’Œæ‰©å±•ååˆ†ç±»æ–‡ä»¶"""
        filename_lower = filename.lower()
        file_ext = os.path.splitext(filename)[1].lower()
        
        for category, rules in self.file_categories.items():
            # æ£€æŸ¥æ‰©å±•å
            if 'extensions' in rules and file_ext in rules['extensions']:
                # å¦‚æœæœ‰patternsï¼Œéœ€è¦é¢å¤–æ£€æŸ¥
                if 'patterns' in rules:
                    for pattern in rules['patterns']:
                        if pattern.lower() in filename_lower:
                            return category
                    # å¦‚æœæ²¡æœ‰åŒ¹é…çš„patternï¼Œç»§ç»­æ£€æŸ¥å…¶ä»–ç±»åˆ«
                    continue
                else:
                    return category
            
            # æ£€æŸ¥æ–‡ä»¶åæ¨¡å¼ï¼ˆå¯¹äºæ²¡æœ‰æ‰©å±•åæ£€æŸ¥çš„æƒ…å†µï¼‰
            if 'patterns' in rules and 'extensions' not in rules:
                for pattern in rules['patterns']:
                    if pattern.lower() in filename_lower:
                        return category
        
        return 'other'
    
    def backup_files(self, files_info):
        """å¤‡ä»½åŸå§‹æ–‡ä»¶"""
        print(f"\nğŸ’¾ å¤‡ä»½åŸå§‹æ–‡ä»¶...")
        
        backup_dir = os.path.join(self.root_dir, 'backup', f'backup_{self.timestamp}')
        os.makedirs(backup_dir, exist_ok=True)
        
        backup_count = 0
        for file_info in files_info:
            source_path = os.path.join(self.root_dir, file_info['name'])
            backup_path = os.path.join(backup_dir, file_info['name'])
            
            try:
                shutil.copy2(source_path, backup_path)
                backup_count += 1
                print(f"  âœ… å¤‡ä»½: {file_info['name']}")
            except Exception as e:
                print(f"  âŒ å¤‡ä»½å¤±è´¥ {file_info['name']}: {e}")
        
        print(f"âœ… å¤‡ä»½å®Œæˆï¼Œå…±å¤‡ä»½ {backup_count} ä¸ªæ–‡ä»¶")
        return backup_dir
    
    def organize_files(self, files_info):
        """æ•´ç†æ–‡ä»¶åˆ°å¯¹åº”ç›®å½•"""
        print(f"\nğŸ“‚ æ•´ç†æ–‡ä»¶...")
        
        organized_count = 0
        
        for file_info in files_info:
            if file_info['target_dir'] is None:
                print(f"  âš ï¸  è·³è¿‡æœªåˆ†ç±»æ–‡ä»¶: {file_info['name']}")
                continue
            
            source_path = os.path.join(self.root_dir, file_info['name'])
            target_dir = os.path.join(self.root_dir, file_info['target_dir'])
            target_path = os.path.join(target_dir, file_info['name'])
            
            # æ£€æŸ¥ç›®æ ‡æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
            if os.path.exists(target_path):
                # å¦‚æœå­˜åœ¨ï¼Œé‡å‘½å
                base_name, ext = os.path.splitext(file_info['name'])
                counter = 1
                while os.path.exists(target_path):
                    new_name = f"{base_name}_{counter}{ext}"
                    target_path = os.path.join(target_dir, new_name)
                    counter += 1
                print(f"  ğŸ“„ æ–‡ä»¶å·²å­˜åœ¨ï¼Œé‡å‘½åä¸º: {os.path.basename(target_path)}")
            
            try:
                shutil.move(source_path, target_path)
                organized_count += 1
                print(f"  âœ… ç§»åŠ¨: {file_info['name']} -> {file_info['target_dir']}/")
            except Exception as e:
                print(f"  âŒ ç§»åŠ¨å¤±è´¥ {file_info['name']}: {e}")
        
        print(f"âœ… æ–‡ä»¶æ•´ç†å®Œæˆï¼Œå…±æ•´ç† {organized_count} ä¸ªæ–‡ä»¶")
    
    def handle_special_files(self):
        """å¤„ç†ç‰¹æ®Šæ–‡ä»¶"""
        print(f"\nğŸ”§ å¤„ç†ç‰¹æ®Šæ–‡ä»¶...")
        
        special_moves = [
            # å°†æ—§çš„çœä»½æ•°æ®ç§»åˆ°å½’æ¡£ç›®å½•
            ('å››å·çœ*.html', 'html_sources/archive/'),
            ('äº‘å—çœ*.html', 'html_sources/archive/'),
            ('è´µå·çœ*.html', 'html_sources/archive/'),
            ('*ä¸‰çœæ•°æ®ä¸­å¿ƒåæ ‡*', 'data/archive/'),
            ('*ä¸‰çœ*.txt', 'reports/archive/'),
        ]
        
        import glob
        
        for pattern, target_dir in special_moves:
            target_path = os.path.join(self.root_dir, target_dir)
            os.makedirs(target_path, exist_ok=True)
            
            matching_files = glob.glob(pattern)
            for file_path in matching_files:
                if os.path.isfile(file_path):
                    filename = os.path.basename(file_path)
                    dest_path = os.path.join(target_path, filename)
                    
                    try:
                        shutil.move(file_path, dest_path)
                        print(f"  âœ… å½’æ¡£: {filename} -> {target_dir}")
                    except Exception as e:
                        print(f"  âŒ å½’æ¡£å¤±è´¥ {filename}: {e}")
    
    def generate_project_structure_report(self):
        """ç”Ÿæˆé¡¹ç›®ç»“æ„æŠ¥å‘Š"""
        print(f"\nğŸ“Š ç”Ÿæˆé¡¹ç›®ç»“æ„æŠ¥å‘Š...")
        
        report_path = os.path.join(self.root_dir, 'reports', f'é¡¹ç›®ç»“æ„æŠ¥å‘Š_{self.timestamp}.txt')
        
        try:
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write("é¡¹ç›®ç»“æ„æ•´ç†æŠ¥å‘Š\n")
                f.write("=" * 50 + "\n\n")
                
                f.write(f"æ•´ç†æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"é¡¹ç›®æ ¹ç›®å½•: {self.root_dir}\n\n")
                
                f.write("ç›®å½•ç»“æ„:\n")
                f.write("-" * 30 + "\n")
                
                for directory in self.directories:
                    dir_path = os.path.join(self.root_dir, directory)
                    if os.path.exists(dir_path):
                        file_count = len([f for f in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, f))])
                        f.write(f"{directory}/  ({file_count} ä¸ªæ–‡ä»¶)\n")
                        
                        # åˆ—å‡ºç›®å½•ä¸­çš„æ–‡ä»¶
                        for filename in os.listdir(dir_path):
                            file_path = os.path.join(dir_path, filename)
                            if os.path.isfile(file_path):
                                f.write(f"  - {filename}\n")
                        f.write("\n")
                
                f.write("æ–‡ä»¶åˆ†ç±»è§„åˆ™:\n")
                f.write("-" * 30 + "\n")
                for category, rules in self.file_categories.items():
                    f.write(f"{category}: {rules['description']}\n")
                    f.write(f"  ç›®æ ‡ç›®å½•: {rules['target_dir']}\n")
                    if 'extensions' in rules:
                        f.write(f"  æ‰©å±•å: {', '.join(rules['extensions'])}\n")
                    if 'patterns' in rules:
                        f.write(f"  æ–‡ä»¶åæ¨¡å¼: {', '.join(rules['patterns'])}\n")
                    f.write("\n")
            
            print(f"âœ… é¡¹ç›®ç»“æ„æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
            
        except Exception as e:
            print(f"âŒ ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")
    
    def create_readme(self):
        """åˆ›å»ºé¡¹ç›®READMEæ–‡ä»¶"""
        readme_path = os.path.join(self.root_dir, 'docs', 'README.md')
        
        readme_content = f"""# æ•°æ®ä¸­å¿ƒçˆ¬è™«é¡¹ç›®

## é¡¹ç›®æ¦‚è¿°
æœ¬é¡¹ç›®ä¸“é—¨ç”¨äºçˆ¬å–ä¸­å›½å„çœå¸‚çš„æ•°æ®ä¸­å¿ƒåˆ†å¸ƒä¿¡æ¯ï¼Œå½“å‰ä¸»è¦æ”¯æŒå¹¿ä¸œçœæ•°æ®ä¸­å¿ƒä¿¡æ¯çš„é‡‡é›†å’Œåˆ†æã€‚

## é¡¹ç›®ç»“æ„
```
Pc_ZGLZ/
â”œâ”€â”€ src/                    # æºä»£ç 
â”‚   â””â”€â”€ guangdong_datacenter_crawler.py
â”œâ”€â”€ data/                   # æ•°æ®æ–‡ä»¶
â”‚   â”œâ”€â”€ guangdong/         # å¹¿ä¸œçœæ•°æ®
â”‚   â””â”€â”€ archive/           # å½’æ¡£æ•°æ®
â”œâ”€â”€ html_sources/          # HTMLæºç 
â”‚   â”œâ”€â”€ guangdong/         # å¹¿ä¸œçœHTML
â”‚   â””â”€â”€ archive/           # æ—§HTMLå½’æ¡£
â”œâ”€â”€ reports/               # æŠ¥å‘Šæ–‡ä»¶
â”‚   â”œâ”€â”€ guangdong/         # å¹¿ä¸œçœæŠ¥å‘Š
â”‚   â””â”€â”€ archive/           # æ—§æŠ¥å‘Šå½’æ¡£
â”œâ”€â”€ scripts/               # è„šæœ¬æ–‡ä»¶
â”œâ”€â”€ docs/                  # é¡¹ç›®æ–‡æ¡£
â””â”€â”€ backup/                # å¤‡ä»½æ–‡ä»¶
```

## ä½¿ç”¨æ–¹æ³•

### å¹¿ä¸œçœæ•°æ®ä¸­å¿ƒçˆ¬è™«
```bash
python src/guangdong_datacenter_crawler.py
```

è¯¥è„šæœ¬ä¼šï¼š
1. çˆ¬å–å¹¿ä¸œçœåŠä¸»è¦åŸå¸‚çš„æ•°æ®ä¸­å¿ƒä¿¡æ¯
2. åŒ…å«æ·±åœ³ã€å¹¿å·ã€ä¸œèã€ä½›å±±ã€ç æµ·ã€ä¸­å±±ã€æƒ å·ç­‰åŸå¸‚
3. è‡ªåŠ¨å»é‡å’Œæ•°æ®éªŒè¯
4. ç”ŸæˆCSVã€JSONæ ¼å¼çš„æ•°æ®æ–‡ä»¶
5. ç”Ÿæˆè¯¦ç»†çš„åˆ†ææŠ¥å‘Š

### é¡¹ç›®æ•´ç†
```bash
python scripts/organize_project.py
```

## è¾“å‡ºæ–‡ä»¶è¯´æ˜

### æ•°æ®æ–‡ä»¶
- `data/guangdong/å¹¿ä¸œçœæ•°æ®ä¸­å¿ƒåæ ‡_[æ—¶é—´æˆ³].csv` - CSVæ ¼å¼æ•°æ®
- `data/guangdong/å¹¿ä¸œçœæ•°æ®ä¸­å¿ƒåæ ‡_[æ—¶é—´æˆ³].json` - JSONæ ¼å¼æ•°æ®

### æŠ¥å‘Šæ–‡ä»¶
- `reports/guangdong/å¹¿ä¸œçœæ•°æ®ä¸­å¿ƒåˆ†å¸ƒæŠ¥å‘Š_[æ—¶é—´æˆ³].txt` - è¯¦ç»†åˆ†ææŠ¥å‘Š

### è°ƒè¯•æ–‡ä»¶
- `html_sources/guangdong/` - ä¿å­˜çš„HTMLæºç ï¼ˆç”¨äºè°ƒè¯•ï¼‰

## æŠ€æœ¯ç‰¹ç‚¹

1. **å¤šURLç­–ç•¥**: ä½¿ç”¨å¤šç§URLå˜ä½“æé«˜æ•°æ®è¦†ç›–ç‡
2. **æ™ºèƒ½å»é‡**: åŸºäºåæ ‡ç²¾åº¦å»é™¤é‡å¤æ•°æ®
3. **åœ°ç†éªŒè¯**: ä»…ä¿ç•™å¹¿ä¸œçœåœ°ç†èŒƒå›´å†…çš„åæ ‡
4. **å®¹é”™å¤„ç†**: å®Œå–„çš„å¼‚å¸¸å¤„ç†å’Œé”™è¯¯æ¢å¤
5. **è¯¦ç»†æ—¥å¿—**: å®Œæ•´çš„çˆ¬å–è¿‡ç¨‹è®°å½•

## ä¾èµ–åŒ…
- requests - HTTPè¯·æ±‚
- pandas - æ•°æ®å¤„ç†
- json - JSONæ•°æ®å¤„ç†
- re - æ­£åˆ™è¡¨è¾¾å¼

## å®‰è£…ä¾èµ–
```bash
pip install -r requirements.txt
```

## æ›´æ–°æ—¥å¿—

### {datetime.now().strftime('%Y-%m-%d')}
- åˆ›å»ºå¹¿ä¸œçœä¸“ç”¨æ•°æ®ä¸­å¿ƒçˆ¬è™«
- é‡æ„é¡¹ç›®ç›®å½•ç»“æ„
- æ·»åŠ è‡ªåŠ¨åŒ–é¡¹ç›®æ•´ç†åŠŸèƒ½
- å®Œå–„æ–‡æ¡£å’Œä½¿ç”¨è¯´æ˜

## è®¸å¯è¯
æœ¬é¡¹ç›®ä»…ä¾›å­¦ä¹ å’Œç ”ç©¶ä½¿ç”¨ã€‚

## è”ç³»æ–¹å¼
å¦‚æœ‰é—®é¢˜è¯·æäº¤Issueæˆ–è”ç³»é¡¹ç›®ç»´æŠ¤è€…ã€‚
"""
        
        try:
            with open(readme_path, 'w', encoding='utf-8') as f:
                f.write(readme_content)
            print(f"âœ… READMEæ–‡ä»¶å·²åˆ›å»º: {readme_path}")
        except Exception as e:
            print(f"âŒ åˆ›å»ºREADMEå¤±è´¥: {e}")
    
    def run_full_organization(self):
        """è¿è¡Œå®Œæ•´çš„é¡¹ç›®æ•´ç†æµç¨‹"""
        print("ğŸš€ å¯åŠ¨é¡¹ç›®æ•´ç†...")
        print("="*60)
        
        try:
            # 1. åˆ›å»ºç›®å½•ç»“æ„
            self.create_directory_structure()
            
            # 2. åˆ†ææ–‡ä»¶
            files_info = self.analyze_files()
            
            # 3. å¤‡ä»½æ–‡ä»¶
            backup_dir = self.backup_files(files_info)
            
            # 4. æ•´ç†æ–‡ä»¶
            self.organize_files(files_info)
            
            # 5. å¤„ç†ç‰¹æ®Šæ–‡ä»¶
            self.handle_special_files()
            
            # 6. ç”ŸæˆæŠ¥å‘Š
            self.generate_project_structure_report()
            
            # 7. åˆ›å»ºREADME
            self.create_readme()
            
            print("\n" + "="*60)
            print("ğŸ‰ é¡¹ç›®æ•´ç†å®Œæˆï¼")
            print(f"âœ… æ–‡ä»¶å·²æŒ‰ç±»åˆ«æ•´ç†")
            print(f"âœ… å¤‡ä»½å·²ä¿å­˜åˆ°: backup/backup_{self.timestamp}/")
            print(f"âœ… é¡¹ç›®ç»“æ„æŠ¥å‘Šå·²ç”Ÿæˆ")
            print(f"âœ… READMEæ–‡æ¡£å·²åˆ›å»º")
            print(f"âœ… å¹¿ä¸œçœçˆ¬è™«å·²å°±ç»ª")
            
            print(f"\nğŸ“‹ ä¸‹ä¸€æ­¥æ“ä½œå»ºè®®:")
            print(f"1. è¿è¡Œå¹¿ä¸œçœçˆ¬è™«: python src/guangdong_datacenter_crawler.py")
            print(f"2. æŸ¥çœ‹é¡¹ç›®æ–‡æ¡£: docs/README.md")
            print(f"3. æŸ¥çœ‹æ•°æ®è¾“å‡º: data/guangdong/")
            
        except Exception as e:
            print(f"âŒ é¡¹ç›®æ•´ç†è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ“ æ•°æ®ä¸­å¿ƒçˆ¬è™«é¡¹ç›®æ•´ç†å·¥å…·")
    print("ğŸ¯ ç›®æ ‡ï¼šå°†é¡¹ç›®é‡æ„ä¸ºä¸“é—¨çˆ¬å–å¹¿ä¸œçœçš„æ•°æ®ä¸­å¿ƒçˆ¬è™«")
    
    organizer = ProjectOrganizer()
    organizer.run_full_organization()

if __name__ == "__main__":
    main()
