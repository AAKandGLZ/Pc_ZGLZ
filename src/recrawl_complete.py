#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¯¹æ¯”åˆ†æå’Œé‡æ–°çˆ¬å–è„šæœ¬
"""

import json
import requests
import re
import pandas as pd
import time

def compare_results():
    """å¯¹æ¯”ä¹‹å‰çš„ç»“æœå’Œè¯¦ç»†æ£€æŸ¥ç»“æœ"""
    
    print("å¯¹æ¯”åˆ†æä¹‹å‰çš„ç»“æœå’Œè¯¦ç»†æ£€æŸ¥ç»“æœ...")
    print("="*60)
    
    # è¯»å–ä¹‹å‰çš„å®Œæ•´ç»“æœ
    try:
        with open('æœ€ç»ˆå®Œæ•´ä¸‰çœæ•°æ®ä¸­å¿ƒåæ ‡.json', 'r', encoding='utf-8') as f:
            previous_data = json.load(f)
    except:
        print("æœªæ‰¾åˆ°ä¹‹å‰çš„ç»“æœæ–‡ä»¶")
        return
    
    # è¯»å–è¯¦ç»†æ£€æŸ¥ç»“æœ
    try:
        with open('è¯¦ç»†æ£€æŸ¥ç»“æœæ±‡æ€».json', 'r', encoding='utf-8') as f:
            detailed_data = json.load(f)
    except:
        print("æœªæ‰¾åˆ°è¯¦ç»†æ£€æŸ¥ç»“æœæ–‡ä»¶")
        return
    
    print('ä¹‹å‰ç»“æœä¸­çš„å››å·çœåæ ‡:')
    previous_sichuan = [item for item in previous_data if item['province'] == 'å››å·çœ']
    print(f'æ•°é‡: {len(previous_sichuan)}')
    
    previous_coords = set()
    for item in previous_sichuan:
        coord = (round(item['latitude'], 6), round(item['longitude'], 6))
        previous_coords.add(coord)
    
    print(f'\nè¯¦ç»†æ£€æŸ¥å‘ç°çš„åæ ‡:')
    detailed_coords = set()
    for coord in detailed_data['unique_coordinates']:
        coord_tuple = (round(coord['latitude'], 6), round(coord['longitude'], 6))
        detailed_coords.add(coord_tuple)
    
    print(f'\nå¯¹æ¯”åˆ†æ:')
    print(f'ä¹‹å‰ç»“æœ: {len(previous_coords)} ä¸ªå”¯ä¸€åæ ‡')
    print(f'è¯¦ç»†æ£€æŸ¥: {len(detailed_coords)} ä¸ªå”¯ä¸€åæ ‡')
    
    # æ‰¾å‡ºé—æ¼çš„åæ ‡
    missing = detailed_coords - previous_coords
    found_extra = previous_coords - detailed_coords
    
    if missing:
        print(f'\nâŒ é—æ¼çš„åæ ‡ ({len(missing)} ä¸ª):')
        for coord in missing:
            print(f'  {coord}')
    else:
        print(f'\nâœ… æ²¡æœ‰é—æ¼çš„åæ ‡')
    
    if found_extra:
        print(f'\nâ• ä¹‹å‰å¤šæ‰¾åˆ°çš„åæ ‡ ({len(found_extra)} ä¸ª):')
        for coord in found_extra:
            print(f'  {coord}')
    
    return len(missing) > 0

class FinalCompleteCrawler:
    """æœ€ç»ˆå®Œæ•´çˆ¬è™«ç±»"""
    
    def __init__(self):
        self.urls = {
            # å››å·çœçš„æ‰€æœ‰å˜ä½“
            "å››å·çœ-sichuan-sheng": "https://www.datacenters.com/locations/china/sichuan-sheng",
            "å››å·çœ-si-chuan-sheng": "https://www.datacenters.com/locations/china/si-chuan-sheng",
            "å››å·çœ-sichuan": "https://www.datacenters.com/locations/china/sichuan",
            
            # äº‘å—çœ
            "äº‘å—çœ-yunnan-sheng": "https://www.datacenters.com/locations/china/yunnan-sheng", 
            "äº‘å—çœ-yunnan": "https://www.datacenters.com/locations/china/yunnan",
            
            # è´µå·çœ
            "è´µå·çœ-guizhou-sheng": "https://www.datacenters.com/locations/china/guizhou-sheng",
            "è´µå·çœ-guizhou": "https://www.datacenters.com/locations/china/guizhou",
        }
        
        self.province_mapping = {
            "å››å·çœ-sichuan-sheng": "å››å·çœ",
            "å››å·çœ-si-chuan-sheng": "å››å·çœ",
            "å››å·çœ-sichuan": "å››å·çœ",
            "äº‘å—çœ-yunnan-sheng": "äº‘å—çœ",
            "äº‘å—çœ-yunnan": "äº‘å—çœ",
            "è´µå·çœ-guizhou-sheng": "è´µå·çœ",
            "è´µå·çœ-guizhou": "è´µå·çœ"
        }
        
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }
        
        self.all_results = []
        self.unique_coordinates = set()
    
    def extract_comprehensive_data(self, content, source_key):
        """å…¨é¢æå–é¡µé¢æ•°æ®"""
        found_data = []
        
        try:
            # æå–åæ ‡ - ä½¿ç”¨å¤šç§æ¨¡å¼
            coordinate_patterns = [
                (r'"latitude":\s*([\d\.\-]+)', r'"longitude":\s*([\d\.\-]+)'),
                (r'"lat":\s*([\d\.\-]+)', r'"lng":\s*([\d\.\-]+)'),
            ]
            
            all_coords = []
            
            for lat_pattern, lng_pattern in coordinate_patterns:
                lats = re.findall(lat_pattern, content)
                lngs = re.findall(lng_pattern, content)
                
                if lats and lngs and len(lats) == len(lngs):
                    for lat, lng in zip(lats, lngs):
                        try:
                            lat_f = float(lat)
                            lng_f = float(lng)
                            if 20 <= lat_f <= 35 and 95 <= lng_f <= 115:
                                all_coords.append((lat_f, lng_f))
                        except:
                            continue
            
            print(f"  åŸå§‹åæ ‡: {len(all_coords)} ä¸ª")
            
            # å»é‡åæ ‡
            unique_coords = []
            seen_coords = set()
            for lat, lng in all_coords:
                coord_key = (round(lat, 6), round(lng, 6))
                if coord_key not in seen_coords:
                    seen_coords.add(coord_key)
                    unique_coords.append((lat, lng))
            
            print(f"  å»é‡ååæ ‡: {len(unique_coords)} ä¸ª")
            
            # æå–åç§° - ä½¿ç”¨æ›´å…¨é¢çš„æ¨¡å¼
            name_patterns = [
                r'"name":\s*"([^"]*(?:Data Center|IDC|æ•°æ®ä¸­å¿ƒ)[^"]*)"',
                r'"title":\s*"([^"]*(?:Data Center|IDC|æ•°æ®ä¸­å¿ƒ)[^"]*)"',
                r'"name":\s*"([^"]*(?:' + self.province_mapping[source_key].replace('çœ', '') + '|Sichuan|Yunnan|Guizhou|Chengdu|CTU|GDS|Telecom|Tianfu|Mianyang|Yibin|Ziyang|Neijiang|Dazhou|Panzhihua|Nanchong|Leshan|Guangyuan|Deyang)[^"]*)"',
                r'"displayName":\s*"([^"]+)"',
                r'"label":\s*"([^"]+)"',
            ]
            
            all_names = []
            for pattern in name_patterns:
                names = re.findall(pattern, content, re.IGNORECASE)
                all_names.extend(names)
            
            # è¿‡æ»¤å’Œæ¸…ç†åç§°
            filtered_names = []
            seen_names = set()
            for name in all_names:
                clean_name = name.strip()
                if (len(clean_name) > 3 and 
                    len(clean_name) < 200 and 
                    clean_name not in seen_names):
                    
                    # æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„æ•°æ®ä¸­å¿ƒåç§°
                    keywords = ['data center', 'idc', 'æ•°æ®ä¸­å¿ƒ', 'center', 'chengdu', 'sichuan', 
                               'telecom', 'gds', 'ctu', 'tianfu', 'mianyang', 'yibin', 'ziyang',
                               'neijiang', 'dazhou', 'panzhihua', 'nanchong', 'leshan', 'guangyuan', 'deyang']
                    
                    if any(keyword in clean_name.lower() for keyword in keywords):
                        filtered_names.append(clean_name)
                        seen_names.add(clean_name)
            
            print(f"  æ‰¾åˆ°åç§°: {len(filtered_names)} ä¸ª")
            
            # ç»„åˆæ•°æ®
            province = self.province_mapping[source_key]
            
            for i, (lat, lng) in enumerate(unique_coords):
                # æ£€æŸ¥å…¨å±€é‡å¤
                global_coord_key = (round(lat, 6), round(lng, 6))
                if global_coord_key in self.unique_coordinates:
                    print(f"  è·³è¿‡é‡å¤åæ ‡: ({lat:.6f}, {lng:.6f})")
                    continue
                
                self.unique_coordinates.add(global_coord_key)
                
                # é€‰æ‹©åç§°
                if i < len(filtered_names):
                    name = filtered_names[i]
                else:
                    name = f"{province}æ•°æ®ä¸­å¿ƒ{i+1}"
                
                data_center = {
                    'province': province,
                    'latitude': lat,
                    'longitude': lng,
                    'name': name,
                    'source': source_key,
                    'coordinates': f"{lat},{lng}",
                    'index': len(self.all_results) + len(found_data) + 1
                }
                
                found_data.append(data_center)
                print(f"  âœ… {len(found_data)}. {name} - ({lat:.6f}, {lng:.6f})")
            
        except Exception as e:
            print(f"  âŒ æ•°æ®æå–é”™è¯¯: {e}")
        
        return found_data
    
    def crawl_all_sources(self):
        """é‡æ–°çˆ¬å–æ‰€æœ‰æ•°æ®æº"""
        print("\n" + "="*80)
        print("ğŸ”„ é‡æ–°çˆ¬å–æ‰€æœ‰æ•°æ®æº")
        print("="*80)
        
        for source_key, url in self.urls.items():
            print(f"\nğŸ” æ­£åœ¨çˆ¬å–: {source_key}")
            print(f"ğŸ“ URL: {url}")
            print("-" * 60)
            
            try:
                response = requests.get(url, headers=self.headers, timeout=30)
                
                if response.status_code != 200:
                    print(f"  âŒ è¯·æ±‚å¤±è´¥: {response.status_code}")
                    continue
                
                print(f"  ğŸ“„ é¡µé¢å¤§å°: {len(response.text)} å­—ç¬¦")
                
                # å…¨é¢æå–æ•°æ®
                page_data = self.extract_comprehensive_data(response.text, source_key)
                
                if page_data:
                    self.all_results.extend(page_data)
                    print(f"  âœ… æˆåŠŸæå–: {len(page_data)} ä¸ªæ•°æ®ä¸­å¿ƒ")
                else:
                    print(f"  âš ï¸ æœªæ‰¾åˆ°æ•°æ®")
                
                # è¯·æ±‚é—´éš”
                time.sleep(2)
                
            except Exception as e:
                print(f"  âŒ çˆ¬å–å¤±è´¥: {e}")
        
        print(f"\n" + "="*80)
        print(f"ğŸ‰ é‡æ–°çˆ¬å–å®Œæˆï¼æ€»è®¡æ‰¾åˆ° {len(self.all_results)} ä¸ªæ•°æ®ä¸­å¿ƒ")
        
        return self.all_results
    
    def save_final_results(self):
        """ä¿å­˜æœ€ç»ˆç»“æœ"""
        if not self.all_results:
            print("âŒ æ²¡æœ‰æ•°æ®éœ€è¦ä¿å­˜")
            return
        
        # æŒ‰çœä»½ç»Ÿè®¡
        province_stats = {}
        for result in self.all_results:
            province = result['province']
            province_stats[province] = province_stats.get(province, 0) + 1
        
        print(f"\nğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
        total = sum(province_stats.values())
        for province, count in province_stats.items():
            print(f"  ğŸ“ {province}: {count} ä¸ªæ•°æ®ä¸­å¿ƒ")
        print(f"  ğŸ¯ æ€»è®¡: {total} ä¸ªæ•°æ®ä¸­å¿ƒ")
        
        # ä¿å­˜CSV
        csv_file = "é‡æ–°çˆ¬å–å®Œæ•´ä¸‰çœæ•°æ®ä¸­å¿ƒåæ ‡.csv"
        try:
            df = pd.DataFrame(self.all_results)
            df.to_csv(csv_file, index=False, encoding='utf-8-sig')
            print(f"\nâœ… CSVæ–‡ä»¶å·²ä¿å­˜: {csv_file}")
        except Exception as e:
            print(f"âŒ ä¿å­˜CSVå¤±è´¥: {e}")
        
        # ä¿å­˜JSON
        json_file = "é‡æ–°çˆ¬å–å®Œæ•´ä¸‰çœæ•°æ®ä¸­å¿ƒåæ ‡.json"
        try:
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(self.all_results, f, ensure_ascii=False, indent=2)
            print(f"âœ… JSONæ–‡ä»¶å·²ä¿å­˜: {json_file}")
        except Exception as e:
            print(f"âŒ ä¿å­˜JSONå¤±è´¥: {e}")
        
        # ç”ŸæˆæŠ¥å‘Š
        self.generate_final_report(province_stats)
    
    def generate_final_report(self, province_stats):
        """ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"""
        report_file = "é‡æ–°çˆ¬å–æ•°æ®ä¸­å¿ƒæŠ¥å‘Š.txt"
        
        try:
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write("é‡æ–°çˆ¬å–å®Œæ•´ä¸‰çœæ•°æ®ä¸­å¿ƒæŠ¥å‘Š\n")
                f.write("=" * 70 + "\n\n")
                
                f.write(f"çˆ¬å–æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"æ€»æ•°æ®ä¸­å¿ƒæ•°é‡: {len(self.all_results)}\n\n")
                
                # æ•°æ®æºç»Ÿè®¡
                source_stats = {}
                for result in self.all_results:
                    source = result['source']
                    source_stats[source] = source_stats.get(source, 0) + 1
                
                f.write("æ•°æ®æºåˆ†å¸ƒ:\n")
                f.write("-" * 30 + "\n")
                for source, count in source_stats.items():
                    f.write(f"{source}: {count} ä¸ªæ•°æ®ä¸­å¿ƒ\n")
                
                f.write(f"\nå„çœä»½åˆ†å¸ƒ:\n")
                f.write("-" * 20 + "\n")
                for province, count in province_stats.items():
                    f.write(f"{province}: {count} ä¸ªæ•°æ®ä¸­å¿ƒ\n")
                
                # è¯¦ç»†åˆ—è¡¨
                province_data = {}
                for result in self.all_results:
                    province = result['province']
                    if province not in province_data:
                        province_data[province] = []
                    province_data[province].append(result)
                
                f.write(f"\nè¯¦ç»†åˆ—è¡¨:\n")
                f.write("-" * 20 + "\n")
                
                for province, data in province_data.items():
                    f.write(f"\n{province} ({len(data)} ä¸ª):\n")
                    for i, dc in enumerate(data, 1):
                        f.write(f"  {i:2d}. {dc['name']}\n")
                        f.write(f"      åæ ‡: ({dc['latitude']:.6f}, {dc['longitude']:.6f})\n")
                        f.write(f"      æ¥æº: {dc['source']}\n\n")
            
            print(f"âœ… æœ€ç»ˆæŠ¥å‘Šå·²ä¿å­˜: {report_file}")
            
        except Exception as e:
            print(f"âŒ ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ é‡æ–°çˆ¬å–ä¸‰çœæ•°æ®ä¸­å¿ƒå®Œæ•´ä¿¡æ¯")
    print("ğŸ” ç¡®ä¿è·å–æ‰€æœ‰é—æ¼çš„æ•°æ®")
    
    # é¦–å…ˆå¯¹æ¯”åˆ†æ
    has_missing = compare_results()
    
    if has_missing:
        print("\nâš ï¸ å‘ç°é—æ¼æ•°æ®ï¼Œéœ€è¦é‡æ–°çˆ¬å–")
    else:
        print("\nâœ… æœªå‘ç°é—æ¼ï¼Œä½†ä»è¿›è¡Œé‡æ–°çˆ¬å–ä»¥ç¡®ä¿å®Œæ•´æ€§")
    
    # é‡æ–°çˆ¬å–
    crawler = FinalCompleteCrawler()
    
    try:
        results = crawler.crawl_all_sources()
        
        if results:
            crawler.save_final_results()
            
            print(f"\nğŸ‰ é‡æ–°çˆ¬å–ä»»åŠ¡å®Œæˆï¼")
            print(f"âœ… æˆåŠŸè·å– {len(results)} ä¸ªæ•°æ®ä¸­å¿ƒ")
            print(f"âœ… ç¡®ä¿åŒ…å«æ‰€æœ‰ sichuanã€si-chuan-sheng ç­‰å˜ä½“æ•°æ®")
            print(f"âœ… æ•°æ®å·²ä¿å­˜ä¸ºé‡æ–°çˆ¬å–ç‰ˆæœ¬")
            
            print(f"\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
            print(f"  - é‡æ–°çˆ¬å–å®Œæ•´ä¸‰çœæ•°æ®ä¸­å¿ƒåæ ‡.csv")
            print(f"  - é‡æ–°çˆ¬å–å®Œæ•´ä¸‰çœæ•°æ®ä¸­å¿ƒåæ ‡.json")
            print(f"  - é‡æ–°çˆ¬å–æ•°æ®ä¸­å¿ƒæŠ¥å‘Š.txt")
        else:
            print("âŒ é‡æ–°çˆ¬å–æœªè·å–åˆ°ä»»ä½•æ•°æ®")
            
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­ä»»åŠ¡")
    except Exception as e:
        print(f"âŒ é‡æ–°çˆ¬å–è¿‡ç¨‹ä¸­å‡ºé”™: {e}")

if __name__ == "__main__":
    main()
