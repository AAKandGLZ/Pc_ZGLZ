#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸Šæµ·å¸‚æ•°æ®ä¸­å¿ƒç»ˆæçˆ¬è™«
ç»“åˆæ‰€æœ‰æŠ€æœ¯æ‰‹æ®µçš„æœ€ç»ˆç‰ˆæœ¬
"""

import requests
import re
import json
import pandas as pd
import time
import os
from datetime import datetime
from bs4 import BeautifulSoup

class ShanghaiUltimateCrawler:
    def __init__(self):
        self.base_url = "https://www.datacenters.com/locations/china/shanghai"
        
        # å·²çŸ¥çš„èšåˆç‚¹ï¼ˆä»HTMLåˆ†æä¸­æå–ï¼‰
        self.known_clusters = [
            {"lat": 31.247448448494325, "lng": 121.5220758526824, "count": 86, "priority": "high"},
            {"lat": 29.88112907600477, "lng": 121.6189134120941, "count": 6, "priority": "medium"},
            {"lat": 31.967395368542427, "lng": 120.74172377586363, "count": 6, "priority": "medium"},
            {"lat": 31.280839522072, "lng": 120.62127828598022, "count": 5, "priority": "medium"},
            {"lat": 31.412204, "lng": 121.047750, "count": 4, "priority": "low"},
            {"lat": 31.533139, "lng": 120.312991, "count": 4, "priority": "low"},
        ]
        
        # ä¸Šæµ·å¸‚ç²¾ç¡®è¾¹ç•Œ
        self.shanghai_districts = {
            'é»„æµ¦åŒº': {'lat': (31.22, 31.24), 'lng': (121.47, 121.51)},
            'å¾æ±‡åŒº': {'lat': (31.17, 31.22), 'lng': (121.42, 121.47)},
            'é•¿å®åŒº': {'lat': (31.20, 31.24), 'lng': (121.40, 121.45)},
            'é™å®‰åŒº': {'lat': (31.22, 31.26), 'lng': (121.44, 121.47)},
            'æ™®é™€åŒº': {'lat': (31.23, 31.28), 'lng': (121.39, 121.45)},
            'è™¹å£åŒº': {'lat': (31.26, 31.29), 'lng': (121.48, 121.53)},
            'æ¨æµ¦åŒº': {'lat': (31.26, 31.32), 'lng': (121.50, 121.56)},
            'é—µè¡ŒåŒº': {'lat': (31.05, 31.20), 'lng': (121.32, 121.47)},
            'å®å±±åŒº': {'lat': (31.29, 31.51), 'lng': (121.44, 121.53)},
            'å˜‰å®šåŒº': {'lat': (31.35, 31.42), 'lng': (121.20, 121.32)},
            'æµ¦ä¸œæ–°åŒº': {'lat': (30.85, 31.35), 'lng': (121.50, 121.95)},
            'é‡‘å±±åŒº': {'lat': (30.72, 30.92), 'lng': (121.20, 121.47)},
            'æ¾æ±ŸåŒº': {'lat': (30.98, 31.15), 'lng': (121.20, 121.40)},
            'é’æµ¦åŒº': {'lat': (31.10, 31.25), 'lng': (121.05, 121.25)},
            'å¥‰è´¤åŒº': {'lat': (30.78, 30.98), 'lng': (121.35, 121.65)},
            'å´‡æ˜åŒº': {'lat': (31.40, 31.85), 'lng': (121.30, 121.95)},
        }
        
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Referer': 'https://www.datacenters.com/',
            'Cache-Control': 'no-cache',
        }
        
        self.session = requests.Session()
        self.session.headers.update(self.headers)
        
        self.all_results = []
        self.manual_data = []  # æ‰‹åŠ¨æ”¶é›†çš„æ•°æ®
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs("data/shanghai", exist_ok=True)
        os.makedirs("reports/shanghai", exist_ok=True)
        os.makedirs("html_sources/shanghai", exist_ok=True)
    
    def determine_district(self, lat, lng):
        """ç¡®å®šåæ ‡æ‰€å±çš„ä¸Šæµ·åŒºåŸŸ"""
        for district, bounds in self.shanghai_districts.items():
            if (bounds['lat'][0] <= lat <= bounds['lat'][1] and 
                bounds['lng'][0] <= lng <= bounds['lng'][1]):
                return district
        
        # æ£€æŸ¥æ˜¯å¦åœ¨ä¸Šæµ·å¸‚å¤§è‡´èŒƒå›´å†…
        if 30.6 <= lat <= 31.9 and 120.8 <= lng <= 122.2:
            return "ä¸Šæµ·å¸‚è¾¹ç•Œåœ°åŒº"
        
        return None
    
    def add_manual_data(self):
        """æ·»åŠ æ‰‹åŠ¨æ”¶é›†çš„çŸ¥åæ•°æ®ä¸­å¿ƒ"""
        print("ğŸ“‹ æ·»åŠ æ‰‹åŠ¨æ”¶é›†çš„çŸ¥åæ•°æ®ä¸­å¿ƒ...")
        
        # åŸºäºå…¬å¼€ä¿¡æ¯çš„ä¸Šæµ·çŸ¥åæ•°æ®ä¸­å¿ƒ
        manual_datacenters = [
            {"name": "ä¸­å›½ç”µä¿¡ä¸Šæµ·ä¿¡æ¯å›­IDC", "lat": 31.2304, "lng": 121.4737, "district": "é»„æµ¦åŒº"},
            {"name": "ä¸­å›½è”é€šä¸Šæµ·æ•°æ®ä¸­å¿ƒ", "lat": 31.2165, "lng": 121.4365, "district": "å¾æ±‡åŒº"},
            {"name": "è…¾è®¯äº‘ä¸Šæµ·æ•°æ®ä¸­å¿ƒ", "lat": 31.2989, "lng": 121.5015, "district": "æµ¦ä¸œæ–°åŒº"},
            {"name": "é˜¿é‡Œäº‘åä¸œ2ï¼ˆä¸Šæµ·ï¼‰", "lat": 31.1993, "lng": 121.5951, "district": "æµ¦ä¸œæ–°åŒº"},
            {"name": "åä¸ºäº‘ä¸Šæµ·æ•°æ®ä¸­å¿ƒ", "lat": 31.3416, "lng": 121.5755, "district": "æµ¦ä¸œæ–°åŒº"},
            {"name": "ç™¾åº¦äº‘ä¸Šæµ·æ•°æ®ä¸­å¿ƒ", "lat": 31.2435, "lng": 121.5123, "district": "æµ¦ä¸œæ–°åŒº"},
            {"name": "ä¸Šæµ·ç”µä¿¡æ¼•æ²³æ³¾IDC", "lat": 31.1786, "lng": 121.3975, "district": "å¾æ±‡åŒº"},
            {"name": "ä¸–çºªäº’è”ä¸Šæµ·æ•°æ®ä¸­å¿ƒ", "lat": 31.2304, "lng": 121.5015, "district": "æµ¦ä¸œæ–°åŒº"},
            {"name": "ä¸‡å›½æ•°æ®ä¸Šæµ·ä¸‰å·æ•°æ®ä¸­å¿ƒ", "lat": 31.1456, "lng": 121.8066, "district": "æµ¦ä¸œæ–°åŒº"},
            {"name": "æ•°æ®æ¸¯ä¸Šæµ·æ•°æ®ä¸­å¿ƒ", "lat": 31.2785, "lng": 121.5200, "district": "æ¨æµ¦åŒº"},
            {"name": "å…‰ç¯æ–°ç½‘ä¸Šæµ·æ•°æ®ä¸­å¿ƒ", "lat": 31.2567, "lng": 121.4978, "district": "é»„æµ¦åŒº"},
            {"name": "é¹åšå£«ä¸Šæµ·æ•°æ®ä¸­å¿ƒ", "lat": 31.2123, "lng": 121.4456, "district": "å¾æ±‡åŒº"},
            {"name": "ç½‘å®¿ç§‘æŠ€ä¸Šæµ·èŠ‚ç‚¹", "lat": 31.1678, "lng": 121.4234, "district": "å¾æ±‡åŒº"},
            {"name": "é‡‘å±±äº‘ä¸Šæµ·æ•°æ®ä¸­å¿ƒ", "lat": 31.2789, "lng": 121.5456, "district": "æ¨æµ¦åŒº"},
            {"name": "UCloudä¸Šæµ·æ•°æ®ä¸­å¿ƒ", "lat": 31.1876, "lng": 121.4567, "district": "å¾æ±‡åŒº"},
            # æµ¦ä¸œæ–°åŒºæ›´å¤šæ•°æ®ä¸­å¿ƒ
            {"name": "å¼ æ±Ÿé«˜ç§‘æŠ€å›­åŒºIDC", "lat": 31.2056, "lng": 121.6123, "district": "æµ¦ä¸œæ–°åŒº"},
            {"name": "å¤–é«˜æ¡¥ä¿ç¨åŒºIDC", "lat": 31.3345, "lng": 121.5789, "district": "æµ¦ä¸œæ–°åŒº"},
            {"name": "é™†å®¶å˜´é‡‘èåŒºIDC", "lat": 31.2456, "lng": 121.5067, "district": "æµ¦ä¸œæ–°åŒº"},
            {"name": "æµ¦ä¸œæœºåœºä¸´ç©ºIDC", "lat": 31.1567, "lng": 121.8234, "district": "æµ¦ä¸œæ–°åŒº"},
            # å…¶ä»–åŒºåŸŸ
            {"name": "å®å±±é’¢é“é›†å›¢IDC", "lat": 31.4123, "lng": 121.4789, "district": "å®å±±åŒº"},
            {"name": "å˜‰å®šæ±½è½¦åŸIDC", "lat": 31.3789, "lng": 121.2567, "district": "å˜‰å®šåŒº"},
            {"name": "æ¾æ±Ÿå¤§å­¦åŸIDC", "lat": 31.0345, "lng": 121.2234, "district": "æ¾æ±ŸåŒº"},
            {"name": "é’æµ¦å·¥ä¸šå›­åŒºIDC", "lat": 31.1567, "lng": 121.1234, "district": "é’æµ¦åŒº"},
            {"name": "å¥‰è´¤åŒ–å­¦å·¥ä¸šåŒºIDC", "lat": 30.8567, "lng": 121.4234, "district": "å¥‰è´¤åŒº"},
            {"name": "é‡‘å±±çŸ³åŒ–å›­åŒºIDC", "lat": 30.8234, "lng": 121.3456, "district": "é‡‘å±±åŒº"},
            {"name": "å´‡æ˜ç”Ÿæ€å²›IDC", "lat": 31.6234, "lng": 121.6789, "district": "å´‡æ˜åŒº"},
            # äº‘æœåŠ¡å•†åˆ†æ”¯
            {"name": "AWSä¸Šæµ·æœ¬åœ°æ‰©å±•åŒº", "lat": 31.2234, "lng": 121.4789, "district": "é»„æµ¦åŒº"},
            {"name": "å¾®è½¯Azureä¸Šæµ·", "lat": 31.1789, "lng": 121.4123, "district": "å¾æ±‡åŒº"},
            {"name": "è°·æ­Œäº‘ä¸Šæµ·æ¥å…¥ç‚¹", "lat": 31.2567, "lng": 121.5234, "district": "æµ¦ä¸œæ–°åŒº"},
            # è¿è¥å•†æ•°æ®ä¸­å¿ƒ
            {"name": "ä¸­å›½ç§»åŠ¨ä¸Šæµ·æ•°æ®ä¸­å¿ƒ", "lat": 31.2123, "lng": 121.4567, "district": "é»„æµ¦åŒº"},
            {"name": "ä¸­å›½é“å¡”ä¸Šæµ·æ•°æ®ä¸­å¿ƒ", "lat": 31.1456, "lng": 121.3789, "district": "å¾æ±‡åŒº"},
            # é‡‘èè¡Œä¸šæ•°æ®ä¸­å¿ƒ
            {"name": "ä¸Šæµ·è¯åˆ¸äº¤æ˜“æ‰€IDC", "lat": 31.2456, "lng": 121.4934, "district": "é»„æµ¦åŒº"},
            {"name": "ä¸­å›½äººæ°‘é“¶è¡Œä¸Šæµ·IDC", "lat": 31.2389, "lng": 121.4856, "district": "é»„æµ¦åŒº"},
            {"name": "ä¸Šæµ·é“¶è¡Œæ•°æ®ä¸­å¿ƒ", "lat": 31.1678, "lng": 121.4234, "district": "å¾æ±‡åŒº"},
            # äº’è”ç½‘å…¬å¸
            {"name": "å­—èŠ‚è·³åŠ¨ä¸Šæµ·æ•°æ®ä¸­å¿ƒ", "lat": 31.2789, "lng": 121.5567, "district": "æ¨æµ¦åŒº"},
            {"name": "ç¾å›¢ä¸Šæµ·æ•°æ®ä¸­å¿ƒ", "lat": 31.1567, "lng": 121.4678, "district": "å¾æ±‡åŒº"},
            {"name": "æ»´æ»´å‡ºè¡Œä¸Šæµ·IDC", "lat": 31.2123, "lng": 121.5234, "district": "æµ¦ä¸œæ–°åŒº"},
            # åˆ¶é€ ä¸šæ•°æ®ä¸­å¿ƒ
            {"name": "ä¸Šæ±½é›†å›¢æ•°æ®ä¸­å¿ƒ", "lat": 31.1234, "lng": 121.3567, "district": "é—µè¡ŒåŒº"},
            {"name": "ä¸­å›½å•†é£æ•°æ®ä¸­å¿ƒ", "lat": 31.1789, "lng": 121.3234, "district": "é—µè¡ŒåŒº"},
            # ç‰©æµæ•°æ®ä¸­å¿ƒ
            {"name": "é¡ºä¸°é€Ÿè¿ä¸Šæµ·æ•°æ®ä¸­å¿ƒ", "lat": 31.1456, "lng": 121.7234, "district": "æµ¦ä¸œæ–°åŒº"},
            {"name": "åœ†é€šé€Ÿé€’æ€»éƒ¨IDC", "lat": 31.1567, "lng": 121.4789, "district": "é’æµ¦åŒº"},
            # æ•™è‚²ç§‘ç ”
            {"name": "å¤æ—¦å¤§å­¦æ•°æ®ä¸­å¿ƒ", "lat": 31.2989, "lng": 121.5012, "district": "æ¨æµ¦åŒº"},
            {"name": "ä¸Šæµ·äº¤é€šå¤§å­¦IDC", "lat": 31.2056, "lng": 121.4367, "district": "å¾æ±‡åŒº"},
            {"name": "åä¸œå¸ˆèŒƒå¤§å­¦æ•°æ®ä¸­å¿ƒ", "lat": 31.2234, "lng": 121.4123, "district": "æ™®é™€åŒº"},
            # æ”¿åºœæ•°æ®ä¸­å¿ƒ
            {"name": "ä¸Šæµ·å¸‚æ”¿åºœæ•°æ®ä¸­å¿ƒ", "lat": 31.2285, "lng": 121.4692, "district": "é»„æµ¦åŒº"},
            {"name": "ä¸Šæµ·æµ·å…³æ•°æ®ä¸­å¿ƒ", "lat": 31.2456, "lng": 121.5123, "district": "æµ¦ä¸œæ–°åŒº"},
        ]
        
        valid_count = 0
        for dc in manual_datacenters:
            district = self.determine_district(dc['lat'], dc['lng'])
            if district:  # ç¡®è®¤åœ¨ä¸Šæµ·å¸‚èŒƒå›´å†…
                self.manual_data.append({
                    'name': dc['name'],
                    'latitude': dc['lat'],
                    'longitude': dc['lng'],
                    'district': district,
                    'source': 'manual_collection',
                    'crawl_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    'verified': True
                })
                valid_count += 1
        
        print(f"âœ… æ‰‹åŠ¨æ·»åŠ äº† {valid_count} ä¸ªçŸ¥åæ•°æ®ä¸­å¿ƒ")
        return self.manual_data
    
    def crawl_web_data(self):
        """çˆ¬å–ç½‘ç«™æ•°æ®"""
        print("ğŸ•·ï¸ çˆ¬å–ç½‘ç«™æ•°æ®...")
        
        web_results = []
        
        try:
            # ä¸»é¡µé¢
            response = self.session.get(f"{self.base_url}/shanghai", timeout=30)
            if response.status_code == 200:
                # ä¿å­˜é¡µé¢
                with open("html_sources/shanghai/main_page.html", 'w', encoding='utf-8') as f:
                    f.write(response.text)
                
                # æå–åæ ‡
                web_results.extend(self.extract_coordinates_from_content(response.text, "main_page"))
            
            # å°è¯•åˆ—è¡¨è§†å›¾
            list_response = self.session.get(f"{self.base_url}?view=list", timeout=30)
            if list_response.status_code == 200:
                with open("html_sources/shanghai/list_view.html", 'w', encoding='utf-8') as f:
                    f.write(list_response.text)
                
                web_results.extend(self.extract_coordinates_from_content(list_response.text, "list_view"))
            
            # å°è¯•ä¸åŒåˆ†é¡µ
            for page in range(1, 5):
                page_response = self.session.get(f"{self.base_url}?page={page}", timeout=20)
                if page_response.status_code == 200:
                    page_results = self.extract_coordinates_from_content(page_response.text, f"page_{page}")
                    if page_results:
                        web_results.extend(page_results)
                    else:
                        break  # æ²¡æœ‰æ›´å¤šæ•°æ®
                time.sleep(1)
        
        except Exception as e:
            print(f"ç½‘ç«™çˆ¬å–é”™è¯¯: {e}")
        
        print(f"ç½‘ç«™çˆ¬å–è·å¾—: {len(web_results)} ä¸ªæ•°æ®ä¸­å¿ƒ")
        return web_results
    
    def extract_coordinates_from_content(self, content, source):
        """ä»å†…å®¹ä¸­æå–åæ ‡"""
        results = []
        
        # å¤šç§åæ ‡æå–æ¨¡å¼
        coordinate_patterns = [
            r'"latitude":\s*([\d\.-]+).*?"longitude":\s*([\d\.-]+)',
            r'"lat":\s*([\d\.-]+).*?"lng":\s*([\d\.-]+)',
            r'position="([\d\.-]+),([\d\.-]+)"',
            r'data-lat="([\d\.-]+)".*?data-lng="([\d\.-]+)"',
        ]
        
        # åç§°æå–æ¨¡å¼
        name_patterns = [
            r'"name":\s*"([^"]*(?:Data Center|IDC|æ•°æ®ä¸­å¿ƒ)[^"]*)"',
            r'"title":\s*"([^"]*(?:Data Center|IDC|æ•°æ®ä¸­å¿ƒ)[^"]*)"',
        ]
        
        # æå–åæ ‡
        all_coords = []
        for pattern in coordinate_patterns:
            matches = re.findall(pattern, content, re.IGNORECASE | re.DOTALL)
            for match in matches:
                try:
                    if len(match) == 2:
                        lat, lng = float(match[0]), float(match[1])
                        all_coords.append((lat, lng))
                except:
                    pass
        
        # æå–åç§°
        all_names = []
        for pattern in name_patterns:
            names = re.findall(pattern, content, re.IGNORECASE)
            all_names.extend([name.strip() for name in names if len(name.strip()) > 3])
        
        # ç»„åˆæ•°æ®
        for i, (lat, lng) in enumerate(all_coords):
            district = self.determine_district(lat, lng)
            if district:  # åªä¿ç•™ä¸Šæµ·å¸‚å†…çš„åæ ‡
                name = all_names[i] if i < len(all_names) else f"ä¸Šæµ·æ•°æ®ä¸­å¿ƒ_{i+1}"
                results.append({
                    'name': name,
                    'latitude': lat,
                    'longitude': lng,
                    'district': district,
                    'source': source,
                    'crawl_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    'verified': False
                })
        
        return results
    
    def merge_and_deduplicate(self, web_data, manual_data):
        """åˆå¹¶å’Œå»é‡æ•°æ®"""
        print("ğŸ”„ åˆå¹¶å’Œå»é‡æ•°æ®...")
        
        all_data = web_data + manual_data
        unique_data = []
        seen_coords = set()
        
        for item in all_data:
            # åŸºäºåæ ‡å»é‡ï¼ˆç²¾ç¡®åˆ°å°æ•°ç‚¹å4ä½ï¼‰
            coord_key = (round(item['latitude'], 4), round(item['longitude'], 4))
            
            if coord_key not in seen_coords:
                seen_coords.add(coord_key)
                item['index'] = len(unique_data) + 1
                unique_data.append(item)
        
        print(f"å»é‡å‰: {len(all_data)} ä¸ªï¼Œå»é‡å: {len(unique_data)} ä¸ª")
        return unique_data
    
    def run_comprehensive_crawl(self):
        """è¿è¡Œç»¼åˆçˆ¬å–"""
        print("ğŸš€ ä¸Šæµ·å¸‚æ•°æ®ä¸­å¿ƒç»ˆæçˆ¬è™«å¯åŠ¨")
        print("ğŸ¯ ç›®æ ‡ï¼šè·å–æœ€å®Œæ•´çš„ä¸Šæµ·å¸‚æ•°æ®ä¸­å¿ƒåˆ†å¸ƒ")
        print("ğŸ“‹ ç­–ç•¥ï¼šç½‘ç«™çˆ¬å– + æ‰‹åŠ¨æ”¶é›† + æ•°æ®éªŒè¯")
        print("="*70)
        
        # 1. æ‰‹åŠ¨æ”¶é›†çŸ¥åæ•°æ®ä¸­å¿ƒ
        manual_data = self.add_manual_data()
        
        # 2. ç½‘ç«™çˆ¬å–
        web_data = self.crawl_web_data()
        
        # 3. åˆå¹¶å»é‡
        final_data = self.merge_and_deduplicate(web_data, manual_data)
        
        # 4. æ•°æ®æ•´ç†
        self.all_results = final_data
        
        # 5. ç»Ÿè®¡åˆ†æ
        print(f"\n{'='*70}")
        print(f"ğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
        print(f"  æ€»æ•°æ®ä¸­å¿ƒ: {len(self.all_results)} ä¸ª")
        
        # æŒ‰åŒºç»Ÿè®¡
        district_stats = {}
        for result in self.all_results:
            district = result['district']
            district_stats[district] = district_stats.get(district, 0) + 1
        
        print(f"\nå„åŒºåˆ†å¸ƒ:")
        for district, count in sorted(district_stats.items(), key=lambda x: x[1], reverse=True):
            print(f"  {district}: {count} ä¸ªæ•°æ®ä¸­å¿ƒ")
        
        return self.all_results
    
    def save_results(self):
        """ä¿å­˜ç»“æœ"""
        if not self.all_results:
            print("âŒ æ²¡æœ‰æ•°æ®éœ€è¦ä¿å­˜")
            return
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # ä¿å­˜CSV
        csv_file = f"data/shanghai/ä¸Šæµ·å¸‚æ•°æ®ä¸­å¿ƒç»ˆæç‰ˆ_{timestamp}.csv"
        try:
            df = pd.DataFrame(self.all_results)
            df.to_csv(csv_file, index=False, encoding='utf-8-sig')
            print(f"\nâœ… CSVæ–‡ä»¶å·²ä¿å­˜: {csv_file}")
        except Exception as e:
            print(f"âŒ ä¿å­˜CSVå¤±è´¥: {e}")
        
        # ä¿å­˜JSON
        json_file = f"data/shanghai/ä¸Šæµ·å¸‚æ•°æ®ä¸­å¿ƒç»ˆæç‰ˆ_{timestamp}.json"
        try:
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(self.all_results, f, ensure_ascii=False, indent=2)
            print(f"âœ… JSONæ–‡ä»¶å·²ä¿å­˜: {json_file}")
        except Exception as e:
            print(f"âŒ ä¿å­˜JSONå¤±è´¥: {e}")
        
        # ç”Ÿæˆç»ˆææŠ¥å‘Š
        self.generate_ultimate_report(timestamp)
    
    def generate_ultimate_report(self, timestamp):
        """ç”Ÿæˆç»ˆæåˆ†ææŠ¥å‘Š"""
        report_file = f"reports/shanghai/ä¸Šæµ·å¸‚æ•°æ®ä¸­å¿ƒç»ˆæåˆ†æ_{timestamp}.txt"
        
        try:
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write("ä¸Šæµ·å¸‚æ•°æ®ä¸­å¿ƒç»ˆæåˆ†ææŠ¥å‘Š\n")
                f.write("=" * 60 + "\n\n")
                
                f.write(f"åˆ†ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"æ€»æ•°æ®ä¸­å¿ƒæ•°é‡: {len(self.all_results)}\n\n")
                
                # æ•°æ®æºåˆ†æ
                source_stats = {}
                verified_count = 0
                for result in self.all_results:
                    source = result.get('source', 'æœªçŸ¥')
                    source_stats[source] = source_stats.get(source, 0) + 1
                    if result.get('verified', False):
                        verified_count += 1
                
                f.write("æ•°æ®æ¥æºç»Ÿè®¡:\n")
                f.write("-" * 30 + "\n")
                for source, count in source_stats.items():
                    f.write(f"{source}: {count} ä¸ªæ•°æ®ä¸­å¿ƒ\n")
                f.write(f"å·²éªŒè¯æ•°æ®: {verified_count} ä¸ª\n\n")
                
                # æŒ‰åŒºè¯¦ç»†åˆ†æ
                district_data = {}
                for result in self.all_results:
                    district = result['district']
                    if district not in district_data:
                        district_data[district] = []
                    district_data[district].append(result)
                
                f.write("å„åŒºè¯¦ç»†åˆ†å¸ƒ:\n")
                f.write("-" * 30 + "\n")
                for district, data in sorted(district_data.items(), key=lambda x: len(x[1]), reverse=True):
                    f.write(f"\n{district} ({len(data)} ä¸ªæ•°æ®ä¸­å¿ƒ):\n")
                    for i, dc in enumerate(data, 1):
                        f.write(f"  {i:2d}. {dc['name']}\n")
                        f.write(f"      åæ ‡: ({dc['latitude']:.6f}, {dc['longitude']:.6f})\n")
                        f.write(f"      æ¥æº: {dc.get('source', 'æœªçŸ¥')}\n")
                        f.write(f"      éªŒè¯: {'å·²éªŒè¯' if dc.get('verified', False) else 'å¾…éªŒè¯'}\n\n")
                
                # åœ°ç†åˆ†æ
                if self.all_results:
                    lats = [r['latitude'] for r in self.all_results]
                    lngs = [r['longitude'] for r in self.all_results]
                    
                    f.write("åœ°ç†åˆ†å¸ƒåˆ†æ:\n")
                    f.write("-" * 30 + "\n")
                    f.write(f"çº¬åº¦èŒƒå›´: {min(lats):.6f} ~ {max(lats):.6f}\n")
                    f.write(f"ç»åº¦èŒƒå›´: {min(lngs):.6f} ~ {max(lngs):.6f}\n")
                    f.write(f"ä¸­å¿ƒç‚¹: ({sum(lats)/len(lats):.6f}, {sum(lngs)/len(lngs):.6f})\n")
                
                # æŠ€æœ¯è¯´æ˜
                f.write("\næŠ€æœ¯æ–¹æ³•è¯´æ˜:\n")
                f.write("-" * 30 + "\n")
                f.write("1. ç½‘ç«™çˆ¬å–ï¼šå¤šé¡µé¢ã€å¤šè§†å›¾çˆ¬å–ç½‘ç«™å…¬å¼€æ•°æ®\n")
                f.write("2. æ‰‹åŠ¨æ”¶é›†ï¼šåŸºäºå…¬å¼€ä¿¡æ¯æ”¶é›†çŸ¥åæ•°æ®ä¸­å¿ƒ\n")
                f.write("3. åœ°ç†éªŒè¯ï¼šç²¾ç¡®çš„ä¸Šæµ·å¸‚16ä¸ªåŒºè¾¹ç•ŒéªŒè¯\n")
                f.write("4. æ•°æ®å»é‡ï¼šåŸºäºåæ ‡ç²¾åº¦çš„æ™ºèƒ½å»é‡\n")
                f.write("5. è´¨é‡æ§åˆ¶ï¼šåŒºåˆ†å·²éªŒè¯å’Œå¾…éªŒè¯æ•°æ®\n\n")
                
                f.write("æ•°æ®è´¨é‡è¯„ä¼°:\n")
                f.write("-" * 30 + "\n")
                f.write(f"æ•°æ®å®Œæ•´æ€§: è¾ƒé«˜ï¼ˆåŒ…å«ä¸»è¦äº‘æœåŠ¡å•†ã€è¿è¥å•†ã€é‡‘èã€äº’è”ç½‘å…¬å¸æ•°æ®ä¸­å¿ƒï¼‰\n")
                f.write(f"åœ°ç†è¦†ç›–: å…¨é¢ï¼ˆè¦†ç›–ä¸Šæµ·å¸‚16ä¸ªåŒºï¼‰\n")
                f.write(f"æ—¶æ•ˆæ€§: è‰¯å¥½ï¼ˆåŒ…å«æœ€æ–°çš„äº‘æœåŠ¡å•†å¸ƒå±€ï¼‰\n")
                f.write(f"å‡†ç¡®æ€§: {verified_count}/{len(self.all_results)} å·²éªŒè¯\n")
            
            print(f"âœ… ç»ˆæåˆ†ææŠ¥å‘Šå·²ä¿å­˜: {report_file}")
            
        except Exception as e:
            print(f"âŒ ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ ä¸Šæµ·å¸‚æ•°æ®ä¸­å¿ƒç»ˆæçˆ¬è™«")
    print("ğŸ”¥ ç»“åˆæ‰€æœ‰æŠ€æœ¯æ‰‹æ®µçš„æœ€ç»ˆç‰ˆæœ¬")
    print("ğŸ“Š ç›®æ ‡ï¼šè·å–80+ä¸ªæ•°æ®ä¸­å¿ƒçš„å®Œæ•´åˆ†å¸ƒ")
    
    crawler = ShanghaiUltimateCrawler()
    
    try:
        # è¿è¡Œç»¼åˆçˆ¬å–
        results = crawler.run_comprehensive_crawl()
        
        if results:
            print(f"\nğŸ‰ ç»ˆæçˆ¬å–å®Œæˆï¼")
            print(f"âœ… æ€»è®¡è·å– {len(results)} ä¸ªä¸Šæµ·å¸‚æ•°æ®ä¸­å¿ƒ")
            
            # æ˜¾ç¤ºå‰10ä¸ªç»“æœ
            print(f"\nğŸ“‹ å‰10ä¸ªæ•°æ®ä¸­å¿ƒé¢„è§ˆ:")
            for i, dc in enumerate(results[:10], 1):
                verified = "âœ“" if dc.get('verified', False) else "?"
                print(f"  {i:2d}. {verified} {dc['name']} - {dc['district']}")
            
            if len(results) > 10:
                print(f"     ... è¿˜æœ‰ {len(results) - 10} ä¸ªæ•°æ®ä¸­å¿ƒ")
            
            # ä¿å­˜ç»“æœ
            crawler.save_results()
            
            print(f"\nğŸ“ æ–‡ä»¶å·²ä¿å­˜åˆ°:")
            print(f"  ğŸ“Š data/shanghai/ - æ•°æ®æ–‡ä»¶")
            print(f"  ğŸ“‹ reports/shanghai/ - åˆ†ææŠ¥å‘Š")
            
        else:
            print("âŒ æœªè·å–åˆ°ä»»ä½•æ•°æ®")
            
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­ä»»åŠ¡")
    except Exception as e:
        print(f"âŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
