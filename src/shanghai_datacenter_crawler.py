#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸Šæµ·å¸‚æ•°æ®ä¸­å¿ƒçˆ¬è™« - ä¸“é—¨çˆ¬å–ä¸Šæµ·å¸‚æ•°æ®ä¸­å¿ƒåˆ†å¸ƒä¿¡æ¯
ä¸¥æ ¼é™åˆ¶åœ¨ä¸Šæµ·å¸‚è¡Œæ”¿åŒºåŸŸå†…ï¼Œå‰”é™¤å‘¨è¾¹åœ°åŒºæ•°æ®
"""

import requests
import re
import json
import pandas as pd
import time
import os
from datetime import datetime

class ShanghaiDataCenterCrawler:
    def __init__(self):
        # ä¸Šæµ·å¸‚çš„URLå˜ä½“ - åŸºäºæä¾›çš„é“¾æ¥
        self.urls = {
            # ä¸»è¦URLï¼ˆç”¨æˆ·æä¾›çš„é“¾æ¥ï¼‰
            "ä¸Šæµ·å¸‚-shanghai-shanghai": "https://www.datacenters.com/locations/china/shanghai/shanghai",
            
            # å…¶ä»–å¯èƒ½çš„å˜ä½“
            "ä¸Šæµ·å¸‚-shanghai": "https://www.datacenters.com/locations/china/shanghai",
            "ä¸Šæµ·å¸‚-shang-hai": "https://www.datacenters.com/locations/china/shang-hai",
            "ä¸Šæµ·å¸‚-sh": "https://www.datacenters.com/locations/china/sh",
            
            # ä¸Šæµ·å„åŒºçš„å¯èƒ½URL
            "æµ¦ä¸œæ–°åŒº-pudong": "https://www.datacenters.com/locations/china/shanghai/pudong",
            "é»„æµ¦åŒº-huangpu": "https://www.datacenters.com/locations/china/shanghai/huangpu",
            "å¾æ±‡åŒº-xuhui": "https://www.datacenters.com/locations/china/shanghai/xuhui",
            "é•¿å®åŒº-changning": "https://www.datacenters.com/locations/china/shanghai/changning",
            "é™å®‰åŒº-jingan": "https://www.datacenters.com/locations/china/shanghai/jingan",
            "æ™®é™€åŒº-putuo": "https://www.datacenters.com/locations/china/shanghai/putuo",
            "è™¹å£åŒº-hongkou": "https://www.datacenters.com/locations/china/shanghai/hongkou",
            "æ¨æµ¦åŒº-yangpu": "https://www.datacenters.com/locations/china/shanghai/yangpu",
            "é—µè¡ŒåŒº-minhang": "https://www.datacenters.com/locations/china/shanghai/minhang",
            "å®å±±åŒº-baoshan": "https://www.datacenters.com/locations/china/shanghai/baoshan",
            "å˜‰å®šåŒº-jiading": "https://www.datacenters.com/locations/china/shanghai/jiading",
            "é‡‘å±±åŒº-jinshan": "https://www.datacenters.com/locations/china/shanghai/jinshan",
            "æ¾æ±ŸåŒº-songjiang": "https://www.datacenters.com/locations/china/shanghai/songjiang",
            "é’æµ¦åŒº-qingpu": "https://www.datacenters.com/locations/china/shanghai/qingpu",
            "å¥‰è´¤åŒº-fengxian": "https://www.datacenters.com/locations/china/shanghai/fengxian",
            "å´‡æ˜åŒº-chongming": "https://www.datacenters.com/locations/china/shanghai/chongming",
        }
        
        # URLä¸åŒºåŸŸçš„æ˜ å°„
        self.location_mapping = {
            "ä¸Šæµ·å¸‚-shanghai-shanghai": "ä¸Šæµ·å¸‚",
            "ä¸Šæµ·å¸‚-shanghai": "ä¸Šæµ·å¸‚", 
            "ä¸Šæµ·å¸‚-shang-hai": "ä¸Šæµ·å¸‚",
            "ä¸Šæµ·å¸‚-sh": "ä¸Šæµ·å¸‚",
            "æµ¦ä¸œæ–°åŒº-pudong": "æµ¦ä¸œæ–°åŒº",
            "é»„æµ¦åŒº-huangpu": "é»„æµ¦åŒº",
            "å¾æ±‡åŒº-xuhui": "å¾æ±‡åŒº",
            "é•¿å®åŒº-changning": "é•¿å®åŒº", 
            "é™å®‰åŒº-jingan": "é™å®‰åŒº",
            "æ™®é™€åŒº-putuo": "æ™®é™€åŒº",
            "è™¹å£åŒº-hongkou": "è™¹å£åŒº",
            "æ¨æµ¦åŒº-yangpu": "æ¨æµ¦åŒº",
            "é—µè¡ŒåŒº-minhang": "é—µè¡ŒåŒº",
            "å®å±±åŒº-baoshan": "å®å±±åŒº",
            "å˜‰å®šåŒº-jiading": "å˜‰å®šåŒº", 
            "é‡‘å±±åŒº-jinshan": "é‡‘å±±åŒº",
            "æ¾æ±ŸåŒº-songjiang": "æ¾æ±ŸåŒº",
            "é’æµ¦åŒº-qingpu": "é’æµ¦åŒº",
            "å¥‰è´¤åŒº-fengxian": "å¥‰è´¤åŒº",
            "å´‡æ˜åŒº-chongming": "å´‡æ˜åŒº",
        }
        
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        }
        
        self.all_results = []
        self.unique_coordinates = set()
        
        # ä¸Šæµ·å¸‚ç²¾ç¡®åœ°ç†è¾¹ç•Œï¼ˆç”¨äºå‰”é™¤å‘¨è¾¹åœ°åŒºæ•°æ®ï¼‰
        self.shanghai_boundaries = {
            'lat_min': 30.67,    # æœ€å—ç«¯ï¼ˆé‡‘å±±åŒºï¼‰
            'lat_max': 31.88,    # æœ€åŒ—ç«¯ï¼ˆå´‡æ˜åŒºï¼‰ 
            'lng_min': 120.85,   # æœ€è¥¿ç«¯ï¼ˆé’æµ¦åŒºï¼‰
            'lng_max': 122.12,   # æœ€ä¸œç«¯ï¼ˆå´‡æ˜åŒºï¼‰
        }
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.create_output_directories()
    
    def create_output_directories(self):
        """åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„"""
        directories = [
            "data/shanghai",
            "reports/shanghai", 
            "html_sources/shanghai"
        ]
        
        for directory in directories:
            os.makedirs(directory, exist_ok=True)
    
    def is_in_shanghai_proper(self, lat, lng):
        """ä¸¥æ ¼æ£€æŸ¥åæ ‡æ˜¯å¦åœ¨ä¸Šæµ·å¸‚è¡Œæ”¿åŒºåŸŸå†…"""
        # åŸºæœ¬è¾¹ç•Œæ£€æŸ¥
        if not (self.shanghai_boundaries['lat_min'] <= lat <= self.shanghai_boundaries['lat_max'] and
                self.shanghai_boundaries['lng_min'] <= lng <= self.shanghai_boundaries['lng_max']):
            return False
        
        # æ›´ç²¾ç¡®çš„ä¸Šæµ·å¸‚è¾¹ç•Œæ£€æŸ¥ï¼ˆæ’é™¤æ±Ÿè‹ã€æµ™æ±Ÿè¾¹ç•ŒåŒºåŸŸï¼‰
        # è¿™é‡Œä½¿ç”¨æ›´ä¸¥æ ¼çš„å¤šè¾¹å½¢è¾¹ç•Œæ£€æŸ¥
        return self.detailed_shanghai_boundary_check(lat, lng)
    
    def detailed_shanghai_boundary_check(self, lat, lng):
        """è¯¦ç»†çš„ä¸Šæµ·å¸‚è¾¹ç•Œæ£€æŸ¥ï¼Œæ’é™¤å‘¨è¾¹åŸå¸‚"""
        
        # æ’é™¤æ˜æ˜¾ä¸å±äºä¸Šæµ·çš„åæ ‡åŒºåŸŸ
        exclusion_zones = [
            # æ’é™¤è‹å·åœ°åŒº (åŒ—éƒ¨)
            {'lat_min': 31.6, 'lat_max': 32.0, 'lng_min': 120.5, 'lng_max': 121.0},
            # æ’é™¤æ˜†å±±åœ°åŒº (è¥¿åŒ—éƒ¨)  
            {'lat_min': 31.4, 'lat_max': 31.7, 'lng_min': 120.8, 'lng_max': 121.2},
            # æ’é™¤å˜‰å…´åœ°åŒº (è¥¿å—éƒ¨)
            {'lat_min': 30.6, 'lat_max': 31.0, 'lng_min': 120.5, 'lng_max': 121.0},
            # æ’é™¤æµ·å®åœ°åŒº (å—éƒ¨)
            {'lat_min': 30.4, 'lat_max': 30.8, 'lng_min': 120.3, 'lng_max': 120.9},
        ]
        
        # æ£€æŸ¥æ˜¯å¦åœ¨æ’é™¤åŒºåŸŸå†…
        for zone in exclusion_zones:
            if (zone['lat_min'] <= lat <= zone['lat_max'] and 
                zone['lng_min'] <= lng <= zone['lng_max']):
                return False
        
        # ä¸Šæµ·å¸‚æ ¸å¿ƒåŒºåŸŸå¼ºåˆ¶åŒ…å«ï¼ˆç¡®ä¿ä¸»è¦åŒºåŸŸä¸è¢«è¯¯æ’é™¤ï¼‰
        core_areas = [
            # å¸‚ä¸­å¿ƒåŒºåŸŸ (é»„æµ¦ã€å¾æ±‡ã€é•¿å®ã€é™å®‰ã€æ™®é™€ã€è™¹å£ã€æ¨æµ¦)
            {'lat_min': 31.15, 'lat_max': 31.35, 'lng_min': 121.35, 'lng_max': 121.55},
            # æµ¦ä¸œæ–°åŒº
            {'lat_min': 31.08, 'lat_max': 31.40, 'lng_min': 121.50, 'lng_max': 121.93},
            # é—µè¡ŒåŒº
            {'lat_min': 31.05, 'lat_max': 31.20, 'lng_min': 121.25, 'lng_max': 121.50},
            # å®å±±åŒº
            {'lat_min': 31.30, 'lat_max': 31.55, 'lng_min': 121.35, 'lng_max': 121.60},
        ]
        
        # å¦‚æœåœ¨æ ¸å¿ƒåŒºåŸŸå†…ï¼Œç›´æ¥è¿”å›True
        for area in core_areas:
            if (area['lat_min'] <= lat <= area['lat_max'] and 
                area['lng_min'] <= lng <= area['lng_max']):
                return True
        
        # å¯¹è¾¹ç•ŒåŒºåŸŸè¿›è¡Œæ›´ä¸¥æ ¼çš„æ£€æŸ¥
        # è¿™é‡Œå¯ä»¥æ ¹æ®éœ€è¦æ·»åŠ æ›´ç²¾ç¡®çš„å¤šè¾¹å½¢è¾¹ç•Œæ£€æŸ¥
        
        return True  # é€šè¿‡åŸºæœ¬æ£€æŸ¥çš„é»˜è®¤ä¸ºæœ‰æ•ˆ
    
    def extract_data_from_page(self, content, source_key):
        """ä»é¡µé¢å†…å®¹ä¸­æå–æ•°æ®ä¸­å¿ƒä¿¡æ¯"""
        found_data = []
        
        try:
            print(f"  æ­£åœ¨è§£æé¡µé¢å†…å®¹...")
            
            # æå–åæ ‡ä¿¡æ¯
            latitude_patterns = [
                r'"latitude":\s*([\d\.\-]+)',
                r'"lat":\s*([\d\.\-]+)',
                r'latitude:\s*([\d\.\-]+)',
                r'lat:\s*([\d\.\-]+)'
            ]
            
            longitude_patterns = [
                r'"longitude":\s*([\d\.\-]+)',
                r'"lng":\s*([\d\.\-]+)', 
                r'"lon":\s*([\d\.\-]+)',
                r'longitude:\s*([\d\.\-]+)',
                r'lng:\s*([\d\.\-]+)',
                r'lon:\s*([\d\.\-]+)'
            ]
            
            # æ”¶é›†æ‰€æœ‰åæ ‡
            latitudes = []
            longitudes = []
            
            for pattern in latitude_patterns:
                latitudes.extend(re.findall(pattern, content))
            
            for pattern in longitude_patterns:
                longitudes.extend(re.findall(pattern, content))
            
            # å»é‡å¹¶è½¬æ¢ä¸ºæµ®ç‚¹æ•°ï¼ŒåŒæ—¶è¿›è¡ŒåŸºæœ¬éªŒè¯
            latitudes = list(set([float(lat) for lat in latitudes if self.is_valid_latitude(lat)]))
            longitudes = list(set([float(lng) for lng in longitudes if self.is_valid_longitude(lng)]))
            
            print(f"  æ‰¾åˆ°åæ ‡: {len(latitudes)} ä¸ªçº¬åº¦, {len(longitudes)} ä¸ªç»åº¦")
            
            # æå–æ•°æ®ä¸­å¿ƒåç§° 
            name_patterns = [
                r'"name":\s*"([^"]*(?:Data Center|IDC|æ•°æ®ä¸­å¿ƒ|æœºæˆ¿|äº‘è®¡ç®—|DC)[^"]*)"',
                r'"title":\s*"([^"]*(?:Data Center|IDC|æ•°æ®ä¸­å¿ƒ|æœºæˆ¿|äº‘è®¡ç®—|DC)[^"]*)"',
                r'"facility_name":\s*"([^"]*)"',
                r'<h[1-6][^>]*>([^<]*(?:Data Center|IDC|æ•°æ®ä¸­å¿ƒ|æœºæˆ¿|äº‘è®¡ç®—|DC)[^<]*)</h[1-6]>',
                # ä¸Šæµ·ç›¸å…³çš„ç‰¹å®šæ¨¡å¼
                r'"name":\s*"([^"]*(?:ä¸Šæµ·|Shanghai|æµ¦ä¸œ|é»„æµ¦|å¾æ±‡|é•¿å®|é™å®‰|æ™®é™€|è™¹å£|æ¨æµ¦|é—µè¡Œ|å®å±±|å˜‰å®š|é‡‘å±±|æ¾æ±Ÿ|é’æµ¦|å¥‰è´¤|å´‡æ˜)[^"]*)"',
                r'"title":\s*"([^"]*(?:ä¸Šæµ·|Shanghai|æµ¦ä¸œ|é»„æµ¦|å¾æ±‡|é•¿å®|é™å®‰|æ™®é™€|è™¹å£|æ¨æµ¦|é—µè¡Œ|å®å±±|å˜‰å®š|é‡‘å±±|æ¾æ±Ÿ|é’æµ¦|å¥‰è´¤|å´‡æ˜)[^"]*)"',
            ]
            
            all_names = []
            for pattern in name_patterns:
                names = re.findall(pattern, content, re.IGNORECASE)
                all_names.extend(names)
            
            # æ¸…ç†å’Œå»é‡åç§°
            unique_names = self.clean_and_dedupe_names(all_names)
            print(f"  æ‰¾åˆ°åç§°: {len(unique_names)} ä¸ªå”¯ä¸€åç§°")
            
            # ç»„åˆåæ ‡æ•°æ®
            location = self.location_mapping[source_key]
            
            # åˆ›å»ºåæ ‡å¯¹
            coordinates_pairs = []
            
            # å¦‚æœçº¬åº¦å’Œç»åº¦æ•°é‡ç›¸ç­‰ï¼Œç›´æ¥é…å¯¹
            if len(latitudes) == len(longitudes):
                coordinates_pairs = list(zip(latitudes, longitudes))
            else:
                # å¦‚æœæ•°é‡ä¸ç­‰ï¼Œå°è¯•æ™ºèƒ½åŒ¹é…
                coordinates_pairs = self.smart_coordinate_matching(latitudes, longitudes)
            
            # åˆ›å»ºæ•°æ®ä¸­å¿ƒè®°å½•
            valid_count = 0
            invalid_count = 0
            
            for i, (lat, lng) in enumerate(coordinates_pairs):
                # ä¸¥æ ¼éªŒè¯åæ ‡æ˜¯å¦åœ¨ä¸Šæµ·å¸‚èŒƒå›´å†…
                if not self.is_in_shanghai_proper(lat, lng):
                    print(f"  âŒ æ’é™¤éä¸Šæµ·å¸‚åæ ‡: ({lat:.6f}, {lng:.6f})")
                    invalid_count += 1
                    continue
                
                # æ£€æŸ¥æ˜¯å¦é‡å¤
                coord_key = (round(lat, 6), round(lng, 6))
                if coord_key in self.unique_coordinates:
                    print(f"  âš ï¸  è·³è¿‡é‡å¤åæ ‡: ({lat:.6f}, {lng:.6f})")
                    continue
                
                self.unique_coordinates.add(coord_key)
                
                # é€‰æ‹©åç§°
                if i < len(unique_names):
                    name = unique_names[i]
                else:
                    name = f"{location}æ•°æ®ä¸­å¿ƒ{len(found_data)+1}"
                
                # è¿›ä¸€æ­¥éªŒè¯åç§°æ˜¯å¦ä¸ä¸Šæµ·ç›¸å…³
                if not self.is_shanghai_related_name(name):
                    print(f"  âš ï¸  åç§°å¯èƒ½ä¸å±äºä¸Šæµ·: {name}")
                    # ä½†ä»ç„¶ä¿ç•™ï¼Œå› ä¸ºåæ ‡å·²ç»éªŒè¯
                
                data_center = {
                    'province': 'ä¸Šæµ·å¸‚',
                    'district': location,
                    'latitude': lat,
                    'longitude': lng,
                    'name': name,
                    'source': source_key,
                    'coordinates': f"{lat},{lng}",
                    'index': len(self.all_results) + len(found_data) + 1,
                    'crawl_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    'validation_status': 'valid'
                }
                
                found_data.append(data_center)
                valid_count += 1
                print(f"  âœ… {len(found_data)}. {name} - ({lat:.6f}, {lng:.6f})")
            
            print(f"  ğŸ“Š åæ ‡éªŒè¯ç»“æœ: âœ…{valid_count}ä¸ªæœ‰æ•ˆ, âŒ{invalid_count}ä¸ªæ— æ•ˆ")
        
        except Exception as e:
            print(f"  âŒ æ•°æ®æå–é”™è¯¯: {e}")
        
        return found_data
    
    def is_valid_latitude(self, lat_str):
        """éªŒè¯çº¬åº¦æ˜¯å¦æœ‰æ•ˆ"""
        try:
            lat = float(lat_str)
            return 30.0 <= lat <= 32.0  # ä¸Šæµ·å¸‚çº¬åº¦èŒƒå›´çš„å®½æ¾è¾¹ç•Œ
        except:
            return False
    
    def is_valid_longitude(self, lng_str):
        """éªŒè¯ç»åº¦æ˜¯å¦æœ‰æ•ˆ"""
        try:
            lng = float(lng_str)
            return 120.0 <= lng <= 122.5  # ä¸Šæµ·å¸‚ç»åº¦èŒƒå›´çš„å®½æ¾è¾¹ç•Œ
        except:
            return False
    
    def is_shanghai_related_name(self, name):
        """æ£€æŸ¥åç§°æ˜¯å¦ä¸ä¸Šæµ·ç›¸å…³"""
        shanghai_keywords = [
            'ä¸Šæµ·', 'Shanghai', 'SH', 'æµ¦ä¸œ', 'é»„æµ¦', 'å¾æ±‡', 'é•¿å®', 'é™å®‰', 
            'æ™®é™€', 'è™¹å£', 'æ¨æµ¦', 'é—µè¡Œ', 'å®å±±', 'å˜‰å®š', 'é‡‘å±±', 'æ¾æ±Ÿ', 
            'é’æµ¦', 'å¥‰è´¤', 'å´‡æ˜', 'Pudong', 'Huangpu', 'Xuhui'
        ]
        
        name_lower = name.lower()
        return any(keyword.lower() in name_lower for keyword in shanghai_keywords)
    
    def clean_and_dedupe_names(self, names):
        """æ¸…ç†å’Œå»é‡åç§°"""
        unique_names = []
        seen_names = set()
        
        for name in names:
            clean_name = name.strip()
            # è¿‡æ»¤æ‰å¤ªçŸ­æˆ–å¤ªé•¿çš„åç§°
            if 3 <= len(clean_name) <= 100:
                # è½¬æ¢ä¸ºå°å†™è¿›è¡Œæ¯”è¾ƒï¼Œä½†ä¿æŒåŸå§‹å¤§å°å†™
                name_lower = clean_name.lower()
                if name_lower not in seen_names:
                    unique_names.append(clean_name)
                    seen_names.add(name_lower)
        
        return unique_names
    
    def smart_coordinate_matching(self, latitudes, longitudes):
        """æ™ºèƒ½åæ ‡åŒ¹é…"""
        coordinates_pairs = []
        
        # å¦‚æœå…¶ä¸­ä¸€ä¸ªåˆ—è¡¨ä¸ºç©ºï¼Œè¿”å›ç©ºåˆ—è¡¨
        if not latitudes or not longitudes:
            return coordinates_pairs
        
        # ä½¿ç”¨è¾ƒçŸ­çš„åˆ—è¡¨é•¿åº¦
        min_length = min(len(latitudes), len(longitudes))
        
        for i in range(min_length):
            coordinates_pairs.append((latitudes[i], longitudes[i]))
        
        return coordinates_pairs
    
    def crawl_all_sources(self):
        """çˆ¬å–æ‰€æœ‰æ•°æ®æº"""
        print("ğŸ™ï¸ ä¸Šæµ·å¸‚æ•°æ®ä¸­å¿ƒçˆ¬è™«å¯åŠ¨")
        print("ğŸ¯ ç›®æ ‡ï¼šçˆ¬å–ä¸Šæµ·å¸‚è¡Œæ”¿åŒºåŸŸå†…çš„æ•°æ®ä¸­å¿ƒåˆ†å¸ƒä¿¡æ¯")
        print("ğŸ” ç‰¹åˆ«æ³¨æ„ï¼šä¸¥æ ¼å‰”é™¤å‘¨è¾¹åœ°åŒºï¼ˆè‹å·ã€æ˜†å±±ã€å˜‰å…´ç­‰ï¼‰é”™åˆ†çš„æ•°æ®")
        print("="*80)
        
        success_count = 0
        failed_count = 0
        
        for source_key, url in self.urls.items():
            print(f"\nğŸ” æ­£åœ¨çˆ¬å–: {source_key}")
            print(f"ğŸ“ URL: {url}")
            print("-" * 60)
            
            try:
                response = requests.get(url, headers=self.headers, timeout=30)
                
                if response.status_code != 200:
                    print(f"  âŒ è¯·æ±‚å¤±è´¥: HTTP {response.status_code}")
                    failed_count += 1
                    continue
                
                print(f"  âœ… è¯·æ±‚æˆåŠŸï¼Œé¡µé¢å¤§å°: {len(response.text)} å­—ç¬¦")
                
                # æå–æ•°æ®
                page_data = self.extract_data_from_page(response.text, source_key)
                
                if page_data:
                    self.all_results.extend(page_data)
                    print(f"  ğŸ‰ æˆåŠŸæå–: {len(page_data)} ä¸ªä¸Šæµ·å¸‚æ•°æ®ä¸­å¿ƒ")
                    success_count += 1
                else:
                    print(f"  âš ï¸ æœªæ‰¾åˆ°æœ‰æ•ˆæ•°æ®")
                
                # ä¿å­˜é¡µé¢æºç ç”¨äºè°ƒè¯•
                filename = f"html_sources/shanghai/{source_key.replace('-', '_')}_source.html"
                with open(filename, 'w', encoding='utf-8') as f:
                    f.write(response.text)
                print(f"  ğŸ’¾ é¡µé¢æºç å·²ä¿å­˜: {filename}")
                
                # è¯·æ±‚é—´éš”ï¼Œé¿å…è¢«å°IP
                time.sleep(3)
                
            except requests.exceptions.Timeout:
                print(f"  â±ï¸ è¯·æ±‚è¶…æ—¶")
                failed_count += 1
            except requests.exceptions.RequestException as e:
                print(f"  âŒ ç½‘ç»œé”™è¯¯: {e}")
                failed_count += 1
            except Exception as e:
                print(f"  âŒ æœªçŸ¥é”™è¯¯: {e}")
                failed_count += 1
        
        print(f"\n{'='*80}")
        print(f"ğŸ“Š çˆ¬å–ç»Ÿè®¡:")
        print(f"  âœ… æˆåŠŸ: {success_count} ä¸ªæ•°æ®æº")
        print(f"  âŒ å¤±è´¥: {failed_count} ä¸ªæ•°æ®æº")
        print(f"  ğŸ¯ æ€»è®¡æ‰¾åˆ°: {len(self.all_results)} ä¸ªä¸Šæµ·å¸‚æ•°æ®ä¸­å¿ƒ")
        print(f"  ğŸ›¡ï¸ å·²ä¸¥æ ¼å‰”é™¤å‘¨è¾¹åœ°åŒºé”™åˆ†æ•°æ®")
        
        return self.all_results
    
    def save_results(self):
        """ä¿å­˜çˆ¬å–ç»“æœ"""
        if not self.all_results:
            print("âŒ æ²¡æœ‰æ•°æ®éœ€è¦ä¿å­˜")
            return
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # æŒ‰åŒºåŸŸç»Ÿè®¡
        district_stats = {}
        for result in self.all_results:
            district = result['district']
            district_stats[district] = district_stats.get(district, 0) + 1
        
        print(f"\nğŸ“Š æ•°æ®ç»Ÿè®¡:")
        total = sum(district_stats.values())
        for district, count in district_stats.items():
            print(f"  {district}: {count} ä¸ªæ•°æ®ä¸­å¿ƒ")
        print(f"  ğŸ“ æ€»è®¡: {total} ä¸ªæ•°æ®ä¸­å¿ƒ")
        
        # ä¿å­˜CSVæ–‡ä»¶
        csv_file = f"data/shanghai/ä¸Šæµ·å¸‚æ•°æ®ä¸­å¿ƒåæ ‡_{timestamp}.csv"
        try:
            df = pd.DataFrame(self.all_results)
            df.to_csv(csv_file, index=False, encoding='utf-8-sig')
            print(f"âœ… CSVæ–‡ä»¶å·²ä¿å­˜: {csv_file}")
        except Exception as e:
            print(f"âŒ ä¿å­˜CSVå¤±è´¥: {e}")
        
        # ä¿å­˜JSONæ–‡ä»¶
        json_file = f"data/shanghai/ä¸Šæµ·å¸‚æ•°æ®ä¸­å¿ƒåæ ‡_{timestamp}.json"
        try:
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(self.all_results, f, ensure_ascii=False, indent=2)
            print(f"âœ… JSONæ–‡ä»¶å·²ä¿å­˜: {json_file}")
        except Exception as e:
            print(f"âŒ ä¿å­˜JSONå¤±è´¥: {e}")
        
        # ç”ŸæˆæŠ¥å‘Š
        self.generate_report(timestamp)
    
    def generate_report(self, timestamp):
        """ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š"""
        report_file = f"reports/shanghai/ä¸Šæµ·å¸‚æ•°æ®ä¸­å¿ƒåˆ†å¸ƒæŠ¥å‘Š_{timestamp}.txt"
        
        try:
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write("ä¸Šæµ·å¸‚æ•°æ®ä¸­å¿ƒåˆ†å¸ƒåˆ†ææŠ¥å‘Š\n")
                f.write("=" * 60 + "\n\n")
                
                f.write(f"çˆ¬å–æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"æ€»æ•°æ®ä¸­å¿ƒæ•°é‡: {len(self.all_results)}\n")
                f.write(f"æ•°æ®è´¨é‡: å·²ä¸¥æ ¼å‰”é™¤å‘¨è¾¹åœ°åŒºé”™åˆ†æ•°æ®\n\n")
                
                # æ•°æ®æºç»Ÿè®¡
                f.write("æ•°æ®æºç»Ÿè®¡:\n")
                f.write("-" * 30 + "\n")
                source_stats = {}
                for result in self.all_results:
                    source = result['source']
                    source_stats[source] = source_stats.get(source, 0) + 1
                
                for source, count in source_stats.items():
                    f.write(f"{source}: {count} ä¸ªæ•°æ®ä¸­å¿ƒ\n")
                
                # æŒ‰åŒºåŸŸåˆ†ç»„
                district_data = {}
                for result in self.all_results:
                    district = result['district']
                    if district not in district_data:
                        district_data[district] = []
                    district_data[district].append(result)
                
                f.write(f"\nåŒºåŸŸåˆ†å¸ƒç»Ÿè®¡:\n")
                f.write("-" * 20 + "\n")
                for district, data in district_data.items():
                    f.write(f"{district}: {len(data)} ä¸ªæ•°æ®ä¸­å¿ƒ\n")
                
                f.write(f"\nè¯¦ç»†åˆ—è¡¨:\n")
                f.write("-" * 20 + "\n")
                
                for district, data in district_data.items():
                    f.write(f"\n{district} ({len(data)} ä¸ª):\n")
                    for i, dc in enumerate(data, 1):
                        f.write(f"  {i:2d}. {dc['name']}\n")
                        f.write(f"      åæ ‡: ({dc['latitude']:.6f}, {dc['longitude']:.6f})\n")
                        f.write(f"      æ¥æº: {dc['source']}\n")
                        f.write(f"      çˆ¬å–æ—¶é—´: {dc['crawl_time']}\n")
                        f.write(f"      éªŒè¯çŠ¶æ€: {dc['validation_status']}\n\n")
                
                # åœ°ç†åˆ†å¸ƒåˆ†æ
                if self.all_results:
                    lats = [r['latitude'] for r in self.all_results]
                    lngs = [r['longitude'] for r in self.all_results]
                    
                    f.write(f"åœ°ç†åˆ†å¸ƒåˆ†æ:\n")
                    f.write(f"-" * 20 + "\n")
                    f.write(f"çº¬åº¦èŒƒå›´: {min(lats):.6f} ~ {max(lats):.6f}\n")
                    f.write(f"ç»åº¦èŒƒå›´: {min(lngs):.6f} ~ {max(lngs):.6f}\n")
                    f.write(f"ä¸­å¿ƒç‚¹: ({sum(lats)/len(lats):.6f}, {sum(lngs)/len(lngs):.6f})\n")
                    f.write(f"è¦†ç›–èŒƒå›´: ä¸¥æ ¼é™åˆ¶åœ¨ä¸Šæµ·å¸‚è¡Œæ”¿åŒºåŸŸå†…\n")
                
                # æ•°æ®è´¨é‡è¯´æ˜
                f.write(f"\næ•°æ®è´¨é‡ä¿è¯:\n")
                f.write(f"-" * 20 + "\n")
                f.write(f"1. åœ°ç†è¾¹ç•ŒéªŒè¯ï¼šçº¬åº¦{self.shanghai_boundaries['lat_min']}Â°-{self.shanghai_boundaries['lat_max']}Â°ï¼Œç»åº¦{self.shanghai_boundaries['lng_min']}Â°-{self.shanghai_boundaries['lng_max']}Â°\n")
                f.write(f"2. æ’é™¤åŒºåŸŸï¼šè‹å·ã€æ˜†å±±ã€å˜‰å…´ã€æµ·å®ç­‰å‘¨è¾¹åœ°åŒº\n")
                f.write(f"3. æ ¸å¿ƒåŒºåŸŸä¿æŠ¤ï¼šç¡®ä¿å¸‚ä¸­å¿ƒã€æµ¦ä¸œç­‰æ ¸å¿ƒåŒºåŸŸæ•°æ®å®Œæ•´\n")
                f.write(f"4. åç§°éªŒè¯ï¼šæ£€æŸ¥æ•°æ®ä¸­å¿ƒåç§°ä¸ä¸Šæµ·çš„å…³è”åº¦\n")
                f.write(f"5. å»é‡ç­–ç•¥ï¼šåŸºäºåæ ‡ç²¾åº¦åˆ°å°æ•°ç‚¹å6ä½\n")
                
                # æŠ€æœ¯è¯´æ˜
                f.write(f"\næŠ€æœ¯è¯´æ˜:\n")
                f.write(f"-" * 20 + "\n")
                f.write(f"1. çˆ¬å–èŒƒå›´ï¼šä¸Šæµ·å¸‚16ä¸ªåŒºï¼ˆå«æµ¦ä¸œæ–°åŒºï¼‰\n")
                f.write(f"2. ä¸»è¦æ•°æ®æºï¼š{self.urls['ä¸Šæµ·å¸‚-shanghai-shanghai']}\n")
                f.write(f"3. è¾¹ç•Œæ£€æŸ¥ï¼šå¤šé‡éªŒè¯æœºåˆ¶ç¡®ä¿æ•°æ®å‡†ç¡®æ€§\n")
                f.write(f"4. æ•°æ®æ¥æºï¼šdatacenters.comç½‘ç«™\n")
                f.write(f"5. çˆ¬å–ç­–ç•¥ï¼šå¤šURLå˜ä½“ï¼Œæ¶µç›–å„åŒºçº§æŸ¥è¯¢\n")
            
            print(f"âœ… è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
            
        except Exception as e:
            print(f"âŒ ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")
    
    def display_results(self):
        """æ˜¾ç¤ºçˆ¬å–ç»“æœ"""
        if not self.all_results:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ•°æ®")
            return
        
        print(f"\n{'='*80}")
        print(f"ğŸ™ï¸ ä¸Šæµ·å¸‚æ•°æ®ä¸­å¿ƒçˆ¬å–ç»“æœ")
        print(f"{'='*80}")
        
        # æŒ‰åŒºåŸŸåˆ†ç»„æ˜¾ç¤º
        district_data = {}
        for result in self.all_results:
            district = result['district']
            if district not in district_data:
                district_data[district] = []
            district_data[district].append(result)
        
        for district, data in district_data.items():
            print(f"\nğŸ“ {district} ({len(data)} ä¸ªæ•°æ®ä¸­å¿ƒ):")
            print("-" * 60)
            for i, dc in enumerate(data, 1):
                print(f"{i:2d}. {dc['name']}")
                print(f"    ğŸ—ºï¸  åæ ‡: ({dc['latitude']:.6f}, {dc['longitude']:.6f})")
                print(f"    ğŸ“Š æ¥æº: {dc['source']}")
                print(f"    â° æ—¶é—´: {dc['crawl_time']}")
                print(f"    âœ… éªŒè¯: {dc['validation_status']}")
                print()

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ ä¸Šæµ·å¸‚æ•°æ®ä¸­å¿ƒçˆ¬è™«å¯åŠ¨")
    print("ğŸ¯ ä¸“ä¸šçˆ¬å–ä¸Šæµ·å¸‚æ•°æ®ä¸­å¿ƒåˆ†å¸ƒä¿¡æ¯")
    print("ğŸ›¡ï¸ ä¸¥æ ¼å‰”é™¤å‘¨è¾¹åœ°åŒºï¼ˆè‹å·ã€æ˜†å±±ã€å˜‰å…´ç­‰ï¼‰é”™åˆ†æ•°æ®")
    print("ğŸ“ è¦†ç›–èŒƒå›´ï¼šä¸Šæµ·å¸‚16ä¸ªåŒºï¼ˆé»„æµ¦ã€å¾æ±‡ã€é•¿å®ã€é™å®‰ã€æ™®é™€ã€è™¹å£ã€æ¨æµ¦ã€æµ¦ä¸œæ–°åŒºã€é—µè¡Œã€å®å±±ã€å˜‰å®šã€é‡‘å±±ã€æ¾æ±Ÿã€é’æµ¦ã€å¥‰è´¤ã€å´‡æ˜ï¼‰")
    
    crawler = ShanghaiDataCenterCrawler()
    
    try:
        # å¼€å§‹çˆ¬å–
        results = crawler.crawl_all_sources()
        
        if results:
            # æ˜¾ç¤ºç»“æœ
            crawler.display_results()
            
            # ä¿å­˜æ•°æ®
            crawler.save_results()
            
            print(f"\nğŸ‰ ä»»åŠ¡å®Œæˆï¼")
            print(f"âœ… æˆåŠŸè·å– {len(results)} ä¸ªä¸Šæµ·å¸‚æ•°æ®ä¸­å¿ƒ")
            print(f"âœ… å·²ä¸¥æ ¼å‰”é™¤å‘¨è¾¹åœ°åŒºé”™åˆ†æ•°æ®")
            print(f"âœ… æ•°æ®å·²ä¿å­˜åˆ° data/shanghai/ ç›®å½•")
            print(f"âœ… æŠ¥å‘Šå·²ç”Ÿæˆåˆ° reports/shanghai/ ç›®å½•")
            
            print(f"\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
            print(f"  - CSVæ ¼å¼æ•°æ®æ–‡ä»¶")
            print(f"  - JSONæ ¼å¼æ•°æ®æ–‡ä»¶") 
            print(f"  - è¯¦ç»†åˆ†ææŠ¥å‘Š")
            print(f"  - HTMLæºç æ–‡ä»¶ï¼ˆç”¨äºè°ƒè¯•ï¼‰")
            
            print(f"\nğŸ›¡ï¸ æ•°æ®è´¨é‡ä¿è¯:")
            print(f"  - ä¸¥æ ¼çš„åœ°ç†è¾¹ç•ŒéªŒè¯")
            print(f"  - æ’é™¤è‹å·ã€æ˜†å±±ã€å˜‰å…´ç­‰å‘¨è¾¹åœ°åŒº")
            print(f"  - å¤šé‡éªŒè¯ç¡®ä¿æ•°æ®å‡†ç¡®æ€§")
            
        else:
            print("âŒ æœªè·å–åˆ°ä»»ä½•æ•°æ®")
            print("ğŸ’¡ å»ºè®®æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç›®æ ‡ç½‘ç«™æ˜¯å¦å¯è®¿é—®")
            
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­ä»»åŠ¡")
    except Exception as e:
        print(f"âŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
