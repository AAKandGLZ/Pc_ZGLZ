#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
JavaScriptåŠ¨æ€ç¿»é¡µçˆ¬è™«
ä¸“é—¨å¤„ç†åœ¨åŒä¸€URLå†…é€šè¿‡JavaScriptåŠ¨æ€åˆ‡æ¢é¡µé¢æ•°æ®çš„ç½‘ç«™
"""

import requests
import json
import time
import os
import re
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from bs4 import BeautifulSoup

class JavaScriptPaginationCrawler:
    def __init__(self):
        self.base_url = "https://www.datacenters.com/locations/china/shanghai"
          # è®¾ç½®Chromeé€‰é¡¹
        self.chrome_options = Options()
        # self.chrome_options.add_argument('--headless')  # ç¦ç”¨æ— å¤´æ¨¡å¼ï¼Œä¾¿äºè°ƒè¯•
        self.chrome_options.add_argument('--no-sandbox')
        self.chrome_options.add_argument('--disable-dev-shm-usage')
        self.chrome_options.add_argument('--disable-gpu')
        self.chrome_options.add_argument('--window-size=1920,1080')
        self.chrome_options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
        
        self.driver = None
        self.all_datacenters = []
        self.page_data = {}
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs("data/shanghai", exist_ok=True)
        os.makedirs("html_sources/shanghai", exist_ok=True)
    
    def setup_driver(self):
        """åˆå§‹åŒ–WebDriver"""
        try:
            self.driver = webdriver.Chrome(options=self.chrome_options)
            self.driver.implicitly_wait(10)
            print("âœ… WebDriveråˆå§‹åŒ–æˆåŠŸ")
            return True
        except Exception as e:
            print(f"âŒ WebDriveråˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    def analyze_pagination_structure(self):
        """åˆ†æé¡µé¢çš„JavaScriptç¿»é¡µç»“æ„"""
        print("ğŸ” åˆ†æJavaScriptç¿»é¡µç»“æ„...")
        
        try:
            # åŠ è½½ä¸»é¡µé¢
            self.driver.get(self.base_url)
            time.sleep(5)  # ç­‰å¾…é¡µé¢å®Œå…¨åŠ è½½
            
            # ä¿å­˜åˆå§‹é¡µé¢æºç 
            with open("html_sources/shanghai/js_initial_page.html", 'w', encoding='utf-8') as f:
                f.write(self.driver.page_source)
            
            # æŸ¥æ‰¾åˆ†é¡µç›¸å…³å…ƒç´ 
            pagination_info = self.find_pagination_elements()
            
            # åˆ†æJavaScriptä¸­çš„åˆ†é¡µé€»è¾‘
            js_pagination_info = self.analyze_javascript_pagination()
            
            return {
                'pagination_elements': pagination_info,
                'javascript_info': js_pagination_info
            }
            
        except Exception as e:
            print(f"âŒ åˆ†æç¿»é¡µç»“æ„å¤±è´¥: {e}")
            return None
    
    def find_pagination_elements(self):
        """æŸ¥æ‰¾åˆ†é¡µç›¸å…³çš„DOMå…ƒç´ """
        pagination_info = {
            'pagination_container': None,
            'page_buttons': [],
            'next_button': None,
            'previous_button': None,
            'page_info': None,
            'total_pages': 0
        }
        
        # å¸¸è§çš„åˆ†é¡µå…ƒç´ é€‰æ‹©å™¨
        pagination_selectors = [
            '.pagination',
            '.pager',
            '.page-navigation',
            '.paginate',
            '[class*="pagination"]',
            '[class*="pager"]',
            '[id*="pagination"]',
            '[id*="pager"]'
        ]
        
        for selector in pagination_selectors:
            try:
                elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                if elements:
                    pagination_info['pagination_container'] = selector
                    print(f"  æ‰¾åˆ°åˆ†é¡µå®¹å™¨: {selector}")
                    break
            except:
                continue
        
        # æŸ¥æ‰¾é¡µé¢æŒ‰é’®
        page_button_selectors = [
            'a[onclick*="page"]',
            'button[onclick*="page"]',
            '[data-page]',
            '.page-number',
            '.page-btn',
            'a[href*="page"]',
            'button[data-target*="page"]'
        ]
        
        for selector in page_button_selectors:
            try:
                buttons = self.driver.find_elements(By.CSS_SELECTOR, selector)
                if buttons:
                    pagination_info['page_buttons'].extend(buttons)
                    print(f"  æ‰¾åˆ°é¡µé¢æŒ‰é’®: {len(buttons)} ä¸ª ({selector})")
            except:
                continue
        
        # æŸ¥æ‰¾ä¸‹ä¸€é¡µ/ä¸Šä¸€é¡µæŒ‰é’®
        nav_selectors = {
            'next': ['[onclick*="next"]', 'button:contains("Next")', '.next-page', '[data-action="next"]'],
            'previous': ['[onclick*="prev"]', 'button:contains("Previous")', '.prev-page', '[data-action="prev"]']
        }
        
        for nav_type, selectors in nav_selectors.items():
            for selector in selectors:
                try:
                    element = self.driver.find_element(By.CSS_SELECTOR, selector)
                    if element:
                        pagination_info[f'{nav_type}_button'] = element
                        print(f"  æ‰¾åˆ°{nav_type}æŒ‰é’®: {selector}")
                        break
                except:
                    continue
        
        # å°è¯•è·å–æ€»é¡µæ•°
        total_page_patterns = [
            r'(?:å…±|total|of)\s*(\d+)\s*(?:é¡µ|pages?)',
            r'(\d+)\s*é¡µ',
            r'page\s*\d+\s*of\s*(\d+)',
        ]
        
        page_source = self.driver.page_source
        for pattern in total_page_patterns:
            matches = re.findall(pattern, page_source, re.IGNORECASE)
            if matches:
                try:
                    pagination_info['total_pages'] = int(matches[0])
                    print(f"  æ£€æµ‹åˆ°æ€»é¡µæ•°: {pagination_info['total_pages']}")
                    break
                except:
                    continue
        
        return pagination_info
    
    def analyze_javascript_pagination(self):
        """åˆ†æJavaScriptä¸­çš„åˆ†é¡µé€»è¾‘"""
        js_info = {
            'pagination_functions': [],
            'ajax_endpoints': [],
            'page_variables': [],
            'event_handlers': []
        }
        
        try:
            # è·å–é¡µé¢ä¸­çš„æ‰€æœ‰scriptæ ‡ç­¾
            scripts = self.driver.find_elements(By.TAG_NAME, 'script')
            
            for script in scripts:
                script_content = script.get_attribute('innerHTML') or ''
                
                # æŸ¥æ‰¾åˆ†é¡µç›¸å…³å‡½æ•°
                function_patterns = [
                    r'function\s+(\w*page\w*)\s*\(',
                    r'(\w*page\w*)\s*:\s*function',
                    r'function\s+(\w*load\w*)\s*\(',
                    r'(\w*navigate\w*)\s*:\s*function'
                ]
                
                for pattern in function_patterns:
                    matches = re.findall(pattern, script_content, re.IGNORECASE)
                    js_info['pagination_functions'].extend(matches)
                
                # æŸ¥æ‰¾AJAXç«¯ç‚¹
                ajax_patterns = [
                    r'url\s*:\s*["\']([^"\']*(?:page|data|load)[^"\']*)["\']',
                    r'fetch\s*\(\s*["\']([^"\']+)["\']',
                    r'\.get\s*\(\s*["\']([^"\']+)["\']',
                    r'\.post\s*\(\s*["\']([^"\']+)["\']'
                ]
                
                for pattern in ajax_patterns:
                    matches = re.findall(pattern, script_content, re.IGNORECASE)
                    js_info['ajax_endpoints'].extend(matches)
                
                # æŸ¥æ‰¾é¡µé¢å˜é‡
                var_patterns = [
                    r'(?:var|let|const)\s+(\w*page\w*)\s*=',
                    r'(?:var|let|const)\s+(\w*current\w*)\s*=',
                    r'(?:var|let|const)\s+(\w*total\w*)\s*='
                ]
                
                for pattern in var_patterns:
                    matches = re.findall(pattern, script_content, re.IGNORECASE)
                    js_info['page_variables'].extend(matches)
            
            # å»é‡
            for key in js_info:
                if isinstance(js_info[key], list):
                    js_info[key] = list(set(js_info[key]))
            
            print(f"  JavaScriptåˆ†é¡µå‡½æ•°: {js_info['pagination_functions']}")
            print(f"  AJAXç«¯ç‚¹: {js_info['ajax_endpoints']}")
            print(f"  é¡µé¢å˜é‡: {js_info['page_variables']}")            
        except Exception as e:
            print(f"  JavaScriptåˆ†æå‡ºé”™: {e}")
        
        return js_info
    
    def detect_total_pages(self):
        """æ£€æµ‹æ€»é¡µæ•° - é€šè¿‡æŸ¥æ‰¾é¡µé¢ä¸Šçš„é¡µç æŒ‰é’®"""
        print("ğŸ”¢ æ£€æµ‹æ€»é¡µæ•°...")
        
        total_pages = 0
        
        try:
            # ç­‰å¾…é¡µé¢å®Œå…¨åŠ è½½
            time.sleep(3)
            
            # æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½çš„é¡µç æŒ‰é’®
            pagination_selectors = [
                # é€šç”¨åˆ†é¡µé€‰æ‹©å™¨
                ".pagination a",
                ".pagination button", 
                ".pager a",
                ".pager button",
                ".page-numbers a",
                ".page-numbers button",
                # æ›´å…·ä½“çš„é€‰æ‹©å™¨
                "a[class*='page']",
                "button[class*='page']",
                "span[class*='page']",
                # æ•°å­—æŒ‰é’®
                "a[href*='page']",
                "button[data-page]",
                "a[data-page]",
            ]
            
            page_numbers = set()
            
            for selector in pagination_selectors:
                try:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    for elem in elements:
                        # è·å–æŒ‰é’®æ–‡æœ¬
                        text = elem.text.strip()
                        # è·å–data-pageå±æ€§
                        data_page = elem.get_attribute('data-page')
                        
                        # æ£€æŸ¥æ–‡æœ¬æ˜¯å¦ä¸ºæ•°å­—
                        if text.isdigit():
                            page_numbers.add(int(text))
                            print(f"  æ‰¾åˆ°é¡µç æŒ‰é’®: {text} (æ–‡æœ¬)")
                        
                        # æ£€æŸ¥data-pageå±æ€§
                        if data_page and data_page.isdigit():
                            page_numbers.add(int(data_page))
                            print(f"  æ‰¾åˆ°é¡µç æŒ‰é’®: {data_page} (å±æ€§)")
                        
                        # ä»hrefä¸­æå–é¡µç 
                        href = elem.get_attribute('href')
                        if href:
                            page_match = re.search(r'page[=\-_](\d+)', href, re.IGNORECASE)
                            if page_match:
                                page_numbers.add(int(page_match.group(1)))
                                print(f"  ä»hrefæ‰¾åˆ°é¡µç : {page_match.group(1)}")
                                
                except Exception as e:
                    continue
            
            if page_numbers:
                total_pages = max(page_numbers)
                print(f"  ä»é¡µç æŒ‰é’®æ£€æµ‹åˆ°æ€»é¡µæ•°: {total_pages}")
            else:
                # æ‰‹åŠ¨æŸ¥æ‰¾æ•°å­—æŒ‰é’® (1, 2, 3 ç­‰)
                print("  å°è¯•æ‰‹åŠ¨æŸ¥æ‰¾æ•°å­—æŒ‰é’®...")
                for i in range(1, 11):  # æŸ¥æ‰¾1-10é¡µ
                    try:
                        # å°è¯•å¤šç§æ–¹å¼æŸ¥æ‰¾æ•°å­—æŒ‰é’®
                        xpath_selectors = [
                            f"//a[text()='{i}']",
                            f"//button[text()='{i}']", 
                            f"//span[text()='{i}']",
                            f"//a[contains(@class, 'page') and text()='{i}']",
                            f"//button[contains(@class, 'page') and text()='{i}']",
                            f"//*[contains(@class, 'pagination')]//*[text()='{i}']"
                        ]
                        
                        for xpath in xpath_selectors:
                            try:
                                elem = self.driver.find_element(By.XPATH, xpath)
                                if elem.is_displayed():
                                    page_numbers.add(i)
                                    print(f"  æ‰‹åŠ¨æ‰¾åˆ°é¡µç æŒ‰é’®: {i}")
                                    break
                            except:
                                continue
                    except:
                        continue
                
                if page_numbers:
                    total_pages = max(page_numbers)
                    print(f"  æ‰‹åŠ¨æ£€æµ‹åˆ°æ€»é¡µæ•°: {total_pages}")
            
            # å¦‚æœè¿˜æ˜¯æ‰¾ä¸åˆ°ï¼Œæ£€æŸ¥é¡µé¢æºç ä¸­çš„åˆ†é¡µä¿¡æ¯
            if total_pages == 0:
                print("  æ£€æŸ¥é¡µé¢æºç ä¸­çš„åˆ†é¡µä¿¡æ¯...")
                page_source = self.driver.page_source
                
                # åœ¨æºç ä¸­æŸ¥æ‰¾åˆ†é¡µç›¸å…³ä¿¡æ¯
                patterns = [
                    r'totalPages["\']?\s*:\s*(\d+)',
                    r'pageCount["\']?\s*:\s*(\d+)', 
                    r'total["\']?\s*:\s*(\d+)',
                    r'å…±\s*(\d+)\s*é¡µ',
                    r'Page\s+\d+\s+of\s+(\d+)',
                    r'ç¬¬\s*\d+\s*é¡µ\s*/\s*(\d+)',
                    r'"page"\s*:\s*\d+[^}]*"total"\s*:\s*(\d+)',
                ]
                
                for pattern in patterns:
                    matches = re.findall(pattern, page_source, re.IGNORECASE)
                    if matches:
                        try:
                            total_pages = int(matches[0])
                            print(f"  ä»æºç æ£€æµ‹åˆ°æ€»é¡µæ•°: {total_pages}")
                            break
                        except:
                            continue
            
        except Exception as e:
            print(f"  æ£€æµ‹é¡µæ•°æ—¶å‡ºé”™: {e}")
        
        # å¦‚æœè¿˜æ˜¯æ£€æµ‹ä¸åˆ°ï¼Œæ ¹æ®ä¹‹å‰åˆ†æé»˜è®¤è®¾ä¸º2é¡µ
        if total_pages == 0:
            total_pages = 2
            print(f"  ä½¿ç”¨é»˜è®¤å€¼: {total_pages} é¡µ (åŸºäºä¹‹å‰åˆ†æ)")
        
        return total_pages
    
    def click_page_button(self, page_number):
        """æ¨¡æ‹Ÿç‚¹å‡»é¡µç æŒ‰é’®"""
        print(f"ğŸ–±ï¸ å°è¯•ç‚¹å‡»ç¬¬ {page_number} é¡µæŒ‰é’®...")
        
        # å¤šç§æ–¹å¼æŸ¥æ‰¾é¡µç æŒ‰é’®
        button_selectors = [
            # é€šè¿‡æ–‡æœ¬å†…å®¹æŸ¥æ‰¾
            f"//a[text()='{page_number}']",
            f"//button[text()='{page_number}']",
            f"//span[text()='{page_number}']",
            
            # é€šè¿‡classå’Œæ–‡æœ¬ç»„åˆæŸ¥æ‰¾
            f"//a[contains(@class, 'page') and text()='{page_number}']",
            f"//button[contains(@class, 'page') and text()='{page_number}']",
            f"//*[contains(@class, 'pagination')]//*[text()='{page_number}']",
            
            # é€šè¿‡dataå±æ€§æŸ¥æ‰¾
            f"//a[@data-page='{page_number}']",
            f"//button[@data-page='{page_number}']",
            f"//*[@data-page='{page_number}']",
            
            # é€šè¿‡hrefå±æ€§æŸ¥æ‰¾
            f"//a[contains(@href, 'page={page_number}')]",
            f"//a[contains(@href, 'page-{page_number}')]",
            f"//a[contains(@href, 'p{page_number}')]",
        ]
        
        # å°è¯•æ¯ç§é€‰æ‹©å™¨
        for selector in button_selectors:
            try:
                print(f"  å°è¯•é€‰æ‹©å™¨: {selector}")
                button = self.driver.find_element(By.XPATH, selector)
                
                if button and button.is_displayed():
                    print(f"  æ‰¾åˆ°å¯è§æŒ‰é’®: {button.text} / {button.get_attribute('outerHTML')[:100]}...")
                    
                    # æ»šåŠ¨åˆ°æŒ‰é’®ä½ç½®
                    self.driver.execute_script("arguments[0].scrollIntoView(true);", button)
                    time.sleep(1)
                    
                    # å°è¯•ç‚¹å‡»
                    try:
                        button.click()
                        print(f"  âœ… æˆåŠŸç‚¹å‡»ç¬¬ {page_number} é¡µæŒ‰é’®")
                        time.sleep(3)  # ç­‰å¾…é¡µé¢åŠ è½½
                        return True
                    except Exception as click_error:
                        print(f"  ç‚¹å‡»å¤±è´¥ï¼Œå°è¯•JavaScriptç‚¹å‡»: {click_error}")
                        try:
                            self.driver.execute_script("arguments[0].click();", button)
                            print(f"  âœ… JavaScriptç‚¹å‡»æˆåŠŸ")
                            time.sleep(3)
                            return True
                        except Exception as js_error:
                            print(f"  JavaScriptç‚¹å‡»ä¹Ÿå¤±è´¥: {js_error}")
                            continue
                            
            except Exception as e:
                print(f"  é€‰æ‹©å™¨ {selector} å¤±è´¥: {e}")
                continue
        
        print(f"  âŒ æœªèƒ½æ‰¾åˆ°æˆ–ç‚¹å‡»ç¬¬ {page_number} é¡µæŒ‰é’®")
        return False
    
    def extract_page_data(self, page_num):
        """æå–å½“å‰é¡µé¢çš„æ•°æ®"""
        print(f"  ğŸ“„ æå–ç¬¬ {page_num} é¡µæ•°æ®...")
        
        page_datacenters = []
        
        try:
            # ç­‰å¾…é¡µé¢å†…å®¹åŠ è½½
            time.sleep(3)
            
            # ä¿å­˜é¡µé¢æºç 
            with open(f"html_sources/shanghai/js_page_{page_num}.html", 'w', encoding='utf-8') as f:
                f.write(self.driver.page_source)
            
            # æå–æ–¹æ³•1: ä»JavaScriptå˜é‡ä¸­æå–
            script_data = self.extract_from_javascript(page_num)
            if script_data:
                page_datacenters.extend(script_data)
            
            # æå–æ–¹æ³•2: ä»DOMå…ƒç´ ä¸­æå–
            dom_data = self.extract_from_dom(page_num)
            if dom_data:
                page_datacenters.extend(dom_data)
            
            # æå–æ–¹æ³•3: ä»ç½‘ç»œè¯·æ±‚ä¸­æå–ï¼ˆç›‘å¬AJAXï¼‰
            network_data = self.extract_from_network(page_num)
            if network_data:
                page_datacenters.extend(network_data)
            
            print(f"    ç¬¬ {page_num} é¡µè·å–åˆ° {len(page_datacenters)} ä¸ªæ•°æ®ä¸­å¿ƒ")
            
        except Exception as e:
            print(f"    ç¬¬ {page_num} é¡µæ•°æ®æå–å¤±è´¥: {e}")
        
        return page_datacenters
    
    def extract_from_javascript(self, page_num):
        """ä»JavaScriptå˜é‡ä¸­æå–æ•°æ®"""
        datacenters = []
        
        try:
            # æ‰§è¡ŒJavaScriptè·å–é¡µé¢æ•°æ®
            js_commands = [
                "return window.datacenters || [];",
                "return window.locations || [];", 
                "return window.facilities || [];",
                "return window.markers || [];",
                "return window.mapData || [];",
            ]
            
            for cmd in js_commands:
                try:
                    result = self.driver.execute_script(cmd)
                    if result and isinstance(result, list):
                        for item in result:
                            if isinstance(item, dict) and 'latitude' in item and 'longitude' in item:
                                dc = {
                                    'name': item.get('name', item.get('title', f'æ•°æ®ä¸­å¿ƒ_{len(datacenters)+1}')),
                                    'latitude': float(item['latitude']),
                                    'longitude': float(item['longitude']),
                                    'location': 'ä¸Šæµ·å¸‚',
                                    'source_page': page_num,
                                    'extraction_method': 'JavaScript',
                                    'raw_data': item
                                }
                                
                                # éªŒè¯åæ ‡æ˜¯å¦åœ¨ä¸Šæµ·èŒƒå›´å†…
                                if 30.6 <= dc['latitude'] <= 31.9 and 120.8 <= dc['longitude'] <= 122.2:
                                    datacenters.append(dc)
                        
                        if result:
                            break  # æ‰¾åˆ°æ•°æ®å°±åœæ­¢
                except:
                    continue
            
        except Exception as e:
            print(f"      JavaScriptæå–å¤±è´¥: {e}")
        
        return datacenters
    
    def extract_from_dom(self, page_num):
        """ä»DOMå…ƒç´ ä¸­æå–æ•°æ®"""
        datacenters = []
        
        try:
            # æŸ¥æ‰¾åŒ…å«åæ ‡ä¿¡æ¯çš„å…ƒç´ 
            coord_selectors = [
                '[data-lat]',
                '[data-latitude]',
                '.marker[data-coordinates]',
                '.datacenter-item',
                '.location-item'
            ]
            
            for selector in coord_selectors:
                try:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    for elem in elements:
                        try:
                            lat = elem.get_attribute('data-lat') or elem.get_attribute('data-latitude')
                            lng = elem.get_attribute('data-lng') or elem.get_attribute('data-longitude')
                            
                            if lat and lng:
                                lat, lng = float(lat), float(lng)
                                  name = (elem.get_attribute('title') or 
                                       elem.get_attribute('data-name') or
                                       elem.text.strip() or
                                       f"æ•°æ®ä¸­å¿ƒ_{len(datacenters)+1}")
                                
                                if 30.6 <= lat <= 31.9 and 120.8 <= lng <= 122.2:
                                    datacenters.append({
                                        'name': name,
                                        'latitude': lat,
                                        'longitude': lng,
                                        'location': 'ä¸Šæµ·å¸‚',
                                        'source_page': page_num,
                                        'extraction_method': 'DOM',
                                        'raw_data': {
                                            'element_tag': elem.tag_name,
                                            'attributes': {attr: elem.get_attribute(attr) for attr in ['data-lat', 'data-lng', 'title', 'data-name'] if elem.get_attribute(attr)}
                                        }
                                    })
                        except:
                            continue
                except:
                    continue
            
        except Exception as e:
            print(f"      DOMæå–å¤±è´¥: {e}")
        
        return datacenters
    
    def extract_from_network(self, page_num):
        """ä»ç½‘ç»œè¯·æ±‚ä¸­æå–æ•°æ®ï¼ˆå°è¯•è·å–AJAXå“åº”ï¼‰"""
        datacenters = []
        
        try:
            # è¿™é‡Œå¯ä»¥æ·»åŠ ç½‘ç»œç›‘å¬é€»è¾‘
            # ç”±äºSeleniumçš„é™åˆ¶ï¼Œæˆ‘ä»¬ä¸»è¦ä¾é å‰ä¸¤ç§æ–¹æ³•
            pass
        except Exception as e:
            print(f"      ç½‘ç»œæå–å¤±è´¥: {e}")
        
        return datacenters
    
    def navigate_to_page(self, page_num):
        """å¯¼èˆªåˆ°æŒ‡å®šé¡µé¢ - ä½¿ç”¨çœŸå®æŒ‰é’®ç‚¹å‡»"""
        print(f"  ğŸ”„ å¯¼èˆªåˆ°ç¬¬ {page_num} é¡µ...")
        
        # ä½¿ç”¨ä¸“é—¨çš„æŒ‰é’®ç‚¹å‡»æ–¹æ³•
        return self.click_page_button(page_num)
    
    def crawl_all_pages(self):
        """çˆ¬å–æ‰€æœ‰é¡µé¢"""
        print("ğŸš€ å¼€å§‹JavaScriptåŠ¨æ€ç¿»é¡µçˆ¬è™«")
        print("ğŸ¯ ç›®æ ‡ï¼šè·å–æ‰€æœ‰é¡µé¢çš„æ•°æ®ä¸­å¿ƒä¿¡æ¯")
        print("="*70)
        
        if not self.setup_driver():
            return []
        
        try:
            # 1. åˆ†æç¿»é¡µç»“æ„
            structure = self.analyze_pagination_structure()
            
            # 2. æ£€æµ‹æ€»é¡µæ•°
            total_pages = self.detect_total_pages()
            print(f"ğŸ“Š æ£€æµ‹åˆ°æ€»é¡µæ•°: {total_pages}")
            
            # 3. é€é¡µçˆ¬å–æ•°æ®
            all_datacenters = []
            
            for page_num in range(1, total_pages + 1):
                print(f"\nğŸ“„ å¤„ç†ç¬¬ {page_num} é¡µ ({page_num}/{total_pages})")
                
                # å¯¼èˆªåˆ°é¡µé¢
                if page_num == 1:
                    # ç¬¬ä¸€é¡µå·²ç»åŠ è½½
                    pass
                else:
                    success = self.navigate_to_page(page_num)
                    if not success:
                        print(f"    æ— æ³•å¯¼èˆªåˆ°ç¬¬ {page_num} é¡µï¼Œè·³è¿‡")
                        continue
                
                # æå–é¡µé¢æ•°æ®
                page_data = self.extract_page_data(page_num)
                if page_data:
                    all_datacenters.extend(page_data)
                    print(f"    âœ… ç¬¬ {page_num} é¡µè·å– {len(page_data)} ä¸ªæ•°æ®ä¸­å¿ƒ")
                else:
                    print(f"    âŒ ç¬¬ {page_num} é¡µæœªè·å–åˆ°æ•°æ®")
                
                # ä¿å­˜é¡µé¢æ•°æ®
                self.page_data[f'page_{page_num}'] = page_data
                
                time.sleep(2)  # é¡µé¢é—´å»¶è¿Ÿ
            
            # 4. å»é‡å¤„ç†
            unique_datacenters = self.deduplicate_datacenters(all_datacenters)
            
            print(f"\n{'='*70}")
            print(f"ğŸ“Š çˆ¬å–å®Œæˆç»Ÿè®¡:")
            print(f"  æ€»é¡µæ•°: {total_pages}")
            print(f"  åŸå§‹æ•°æ®: {len(all_datacenters)} ä¸ª")
            print(f"  å»é‡åæ•°æ®: {len(unique_datacenters)} ä¸ª")
            
            # æŒ‰é¡µç»Ÿè®¡
            for page_num in range(1, total_pages + 1):
                page_count = len(self.page_data.get(f'page_{page_num}', []))
                print(f"  ç¬¬ {page_num} é¡µ: {page_count} ä¸ªæ•°æ®ä¸­å¿ƒ")
            
            return unique_datacenters
            
        except Exception as e:
            print(f"âŒ çˆ¬å–è¿‡ç¨‹å‡ºé”™: {e}")
            return []
        
        finally:
            if self.driver:
                self.driver.quit()
    
    def deduplicate_datacenters(self, datacenters):
        """å»é‡æ•°æ®ä¸­å¿ƒ"""
        print(f"ğŸ”„ æ•°æ®å»é‡å¤„ç†...")
        
        unique_datacenters = []
        seen_coords = set()
        
        for dc in datacenters:
            # åŸºäºåæ ‡å»é‡ï¼ˆç²¾ç¡®åˆ°å°æ•°ç‚¹å5ä½ï¼‰
            coord_key = (round(dc['latitude'], 5), round(dc['longitude'], 5))
            
            if coord_key not in seen_coords:
                seen_coords.add(coord_key)
                unique_datacenters.append(dc)
        
        print(f"  å»é‡å‰: {len(datacenters)} ä¸ª")
        print(f"  å»é‡å: {len(unique_datacenters)} ä¸ª")
        
        return unique_datacenters
    
    def save_results(self, datacenters):
        """ä¿å­˜ç»“æœ"""
        if not datacenters:
            print("âŒ æ²¡æœ‰æ•°æ®éœ€è¦ä¿å­˜")
            return
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # ä¿å­˜JSONæ•°æ®
        json_file = f"data/shanghai/ä¸Šæµ·æ•°æ®ä¸­å¿ƒJSç¿»é¡µ_{timestamp}.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(datacenters, f, ensure_ascii=False, indent=2)
        print(f"âœ… JSONæ–‡ä»¶å·²ä¿å­˜: {json_file}")
        
        # ä¿å­˜åˆ†é¡µè¯¦æƒ…
        page_detail_file = f"data/shanghai/ç¿»é¡µè¯¦æƒ…_{timestamp}.json"
        with open(page_detail_file, 'w', encoding='utf-8') as f:
            json.dump(self.page_data, f, ensure_ascii=False, indent=2)
        print(f"âœ… åˆ†é¡µè¯¦æƒ…å·²ä¿å­˜: {page_detail_file}")
        
        # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
        self.generate_detailed_report(datacenters, timestamp)
    
    def generate_detailed_report(self, datacenters, timestamp):
        """ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š"""
        report_file = f"data/shanghai/JSç¿»é¡µçˆ¬å–æŠ¥å‘Š_{timestamp}.txt"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("ä¸Šæµ·æ•°æ®ä¸­å¿ƒJavaScriptç¿»é¡µçˆ¬å–æŠ¥å‘Š\n")
            f.write("="*60 + "\n\n")
            
            f.write(f"çˆ¬å–æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"çˆ¬å–æ–¹æ³•: JavaScriptåŠ¨æ€ç¿»é¡µ\n")
            f.write(f"æ€»æ•°æ®ä¸­å¿ƒ: {len(datacenters)} ä¸ª\n")
            f.write(f"ç›®æ ‡å®Œæˆåº¦: {len(datacenters)}/54 ({len(datacenters)/54*100:.1f}%)\n\n")
            
            # æŒ‰é¡µç»Ÿè®¡
            f.write("åˆ†é¡µç»Ÿè®¡:\n")
            f.write("-"*30 + "\n")
            for page_num, page_data in self.page_data.items():
                f.write(f"{page_num}: {len(page_data)} ä¸ªæ•°æ®ä¸­å¿ƒ\n")
            f.write("\n")
            
            # æŒ‰æå–æ–¹æ³•ç»Ÿè®¡
            method_stats = {}
            for dc in datacenters:
                method = dc.get('extraction_method', 'æœªçŸ¥')
                method_stats[method] = method_stats.get(method, 0) + 1
            
            f.write("æå–æ–¹æ³•ç»Ÿè®¡:\n")
            f.write("-"*30 + "\n")
            for method, count in method_stats.items():
                f.write(f"{method}: {count} ä¸ª\n")
            f.write("\n")
            
            # è¯¦ç»†æ•°æ®åˆ—è¡¨
            f.write("æ•°æ®ä¸­å¿ƒè¯¦ç»†åˆ—è¡¨:\n")
            f.write("-"*30 + "\n")
            for i, dc in enumerate(datacenters, 1):
                f.write(f"{i:2d}. {dc['name']}\n")
                f.write(f"    åæ ‡: ({dc['latitude']:.6f}, {dc['longitude']:.6f})\n")
                f.write(f"    æ¥æºé¡µ: ç¬¬{dc['source_page']}é¡µ\n")
                f.write(f"    æå–æ–¹æ³•: {dc['extraction_method']}\n\n")
        
        print(f"âœ… è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_file}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ ä¸Šæµ·æ•°æ®ä¸­å¿ƒJavaScriptåŠ¨æ€ç¿»é¡µçˆ¬è™«")
    print("ğŸ”„ ä¸“é—¨å¤„ç†åŒä¸€URLå†…çš„JavaScriptç¿»é¡µ")
    print("ğŸ“„ é¢„æœŸï¼šç¬¬1é¡µ40ä¸ªï¼Œç¬¬2é¡µ14ä¸ªï¼Œå…±54ä¸ªæ•°æ®ä¸­å¿ƒ")
    
    crawler = JavaScriptPaginationCrawler()
    
    try:
        # è¿è¡Œçˆ¬è™«
        results = crawler.crawl_all_pages()
        
        if results:
            print(f"\nğŸ‰ çˆ¬å–å®Œæˆï¼")
            print(f"âœ… è·å–åˆ° {len(results)} ä¸ªä¸Šæµ·æ•°æ®ä¸­å¿ƒ")
            
            # æ˜¾ç¤ºå‰10ä¸ªç»“æœ
            print(f"\nğŸ“‹ å‰10ä¸ªæ•°æ®ä¸­å¿ƒ:")
            for i, dc in enumerate(results[:10], 1):
                print(f"  {i:2d}. {dc['name']} (ç¬¬{dc['source_page']}é¡µ)")
            
            if len(results) > 10:
                print(f"     ... è¿˜æœ‰ {len(results) - 10} ä¸ª")
            
            # ä¿å­˜ç»“æœ
            crawler.save_results(results)
            
            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ç›®æ ‡
            if len(results) >= 54:
                print(f"\nğŸ¯ ç›®æ ‡è¾¾æˆï¼è·å–åˆ° {len(results)} ä¸ªæ•°æ®ä¸­å¿ƒ (ç›®æ ‡54ä¸ª)")
            else:
                print(f"\nâš ï¸ è·ç¦»ç›®æ ‡è¿˜å·® {54 - len(results)} ä¸ªæ•°æ®ä¸­å¿ƒ")
            
        else:
            print("âŒ æœªè·å–åˆ°ä»»ä½•æ•°æ®")
            
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­çˆ¬å–")
    except Exception as e:
        print(f"âŒ çˆ¬å–è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
