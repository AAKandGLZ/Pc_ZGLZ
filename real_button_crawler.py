#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
çœŸå®é¡µç æŒ‰é’®ç‚¹å‡»çˆ¬è™«
ä¸“é—¨å¤„ç†é€šè¿‡SeleniumçœŸå®ç‚¹å‡»é¡µé¢ä¸Šçš„é¡µç æŒ‰é’®è¿›è¡Œç¿»é¡µ
ç›®æ ‡ï¼šè·å–ä¸Šæµ·æ•°æ®ä¸­å¿ƒæ‰€æœ‰é¡µé¢æ•°æ®ï¼ˆé¢„æœŸ54ä¸ªï¼‰
"""

import requests
import json
import time
import os
import re
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from bs4 import BeautifulSoup

class RealButtonCrawler:
    def __init__(self):
        self.base_url = "https://www.datacenters.com/locations/china/shanghai"
        
        # è®¾ç½®Chromeé€‰é¡¹
        self.chrome_options = Options()
        # æ³¨é‡Šæ‰æ— å¤´æ¨¡å¼ï¼Œæ–¹ä¾¿è°ƒè¯•
        # self.chrome_options.add_argument('--headless')
        self.chrome_options.add_argument('--no-sandbox')
        self.chrome_options.add_argument('--disable-dev-shm-usage')
        self.chrome_options.add_argument('--disable-gpu')
        self.chrome_options.add_argument('--window-size=1920,1080')
        self.chrome_options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
        
        # æ·»åŠ SSLå’Œç½‘ç»œç›¸å…³é…ç½®
        self.chrome_options.add_argument('--ignore-certificate-errors')
        self.chrome_options.add_argument('--ignore-ssl-errors')
        self.chrome_options.add_argument('--allow-running-insecure-content')
        self.chrome_options.add_argument('--disable-web-security')
        self.chrome_options.add_argument('--disable-features=VizDisplayCompositor')
        
        self.driver = None
        self.all_datacenters = []
        self.page_data = {}
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs("data/shanghai", exist_ok=True)
        os.makedirs("html_sources/shanghai", exist_ok=True)
    
    def setup_driver(self):
        """åˆå§‹åŒ–WebDriver"""
        try:
            self.driver = webdriver.Chrome(options=self.chrome_options)
            self.driver.implicitly_wait(10)
            print("âœ… WebDriveråˆå§‹åŒ–æˆåŠŸ")
            return True
        except Exception as e:
            print(f"âŒ WebDriveråˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    def load_initial_page(self):
        """åŠ è½½åˆå§‹é¡µé¢"""
        print("ğŸŒ åŠ è½½åˆå§‹é¡µé¢...")
        try:
            self.driver.get(self.base_url)
            time.sleep(5)  # ç­‰å¾…é¡µé¢å®Œå…¨åŠ è½½
            
            # ä¿å­˜åˆå§‹é¡µé¢æºç 
            with open("html_sources/shanghai/real_initial_page.html", 'w', encoding='utf-8') as f:
                f.write(self.driver.page_source)
            
            print("âœ… åˆå§‹é¡µé¢åŠ è½½æˆåŠŸ")
            return True
        except Exception as e:
            print(f"âŒ åˆå§‹é¡µé¢åŠ è½½å¤±è´¥: {e}")
            return False
    
    def find_page_buttons(self):
        """æŸ¥æ‰¾é¡µé¢ä¸Šæ‰€æœ‰çš„é¡µç æŒ‰é’®"""
        print("ğŸ” æŸ¥æ‰¾é¡µç æŒ‰é’®...")
        
        page_buttons = {}
        button_selectors = [
            # é€šç”¨åˆ†é¡µé€‰æ‹©å™¨
            ".pagination a",
            ".pagination button", 
            ".pager a",
            ".pager button",
            ".page-numbers a",
            ".page-numbers button",
            # æ›´å…·ä½“çš„é€‰æ‹©å™¨
            "a[class*='page']",
            "button[class*='page']",
            "span[class*='page']",
            # æ•°å­—æŒ‰é’®
            "a[href*='page']",
            "button[data-page]",
            "a[data-page]",
        ]
        
        for selector in button_selectors:
            try:
                elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                for elem in elements:
                    # è·å–æŒ‰é’®æ–‡æœ¬
                    text = elem.text.strip()
                    # è·å–data-pageå±æ€§
                    data_page = elem.get_attribute('data-page')
                    
                    # æ£€æŸ¥æ–‡æœ¬æ˜¯å¦ä¸ºæ•°å­—
                    if text.isdigit():
                        page_num = int(text)
                        page_buttons[page_num] = elem
                        print(f"  æ‰¾åˆ°é¡µç æŒ‰é’® {page_num}: {text} (é€‰æ‹©å™¨: {selector})")
                    
                    # æ£€æŸ¥data-pageå±æ€§
                    elif data_page and data_page.isdigit():
                        page_num = int(data_page)
                        page_buttons[page_num] = elem
                        print(f"  æ‰¾åˆ°é¡µç æŒ‰é’® {page_num}: data-page={data_page} (é€‰æ‹©å™¨: {selector})")
                        
            except Exception as e:
                continue
        
        # æ‰‹åŠ¨æŸ¥æ‰¾æ•°å­—æŒ‰é’® (1, 2, 3 ç­‰)
        if not page_buttons:
            print("  å°è¯•æ‰‹åŠ¨æŸ¥æ‰¾æ•°å­—æŒ‰é’®...")
            for i in range(1, 11):  # æŸ¥æ‰¾1-10é¡µ
                xpath_selectors = [
                    f"//a[text()='{i}']",
                    f"//button[text()='{i}']", 
                    f"//span[text()='{i}']",
                    f"//a[contains(@class, 'page') and text()='{i}']",
                    f"//button[contains(@class, 'page') and text()='{i}']",
                    f"//*[contains(@class, 'pagination')]//*[text()='{i}']",
                    f"//*[contains(@class, 'pager')]//*[text()='{i}']"
                ]
                
                for xpath in xpath_selectors:
                    try:
                        elem = self.driver.find_element(By.XPATH, xpath)
                        if elem.is_displayed():
                            page_buttons[i] = elem
                            print(f"  æ‰‹åŠ¨æ‰¾åˆ°é¡µç æŒ‰é’® {i}: {elem.text} (xpath: {xpath})")
                            break
                    except:
                        continue
        
        print(f"ğŸ”¢ æ€»å…±æ‰¾åˆ° {len(page_buttons)} ä¸ªé¡µç æŒ‰é’®: {list(page_buttons.keys())}")
        return page_buttons
    
    def click_page_button(self, page_number, page_buttons):
        """ç‚¹å‡»æŒ‡å®šé¡µç æŒ‰é’®"""
        print(f"ğŸ–±ï¸ ç‚¹å‡»ç¬¬ {page_number} é¡µæŒ‰é’®...")
        
        # å¦‚æœåœ¨å·²æ‰¾åˆ°çš„æŒ‰é’®ä¸­
        if page_number in page_buttons:
            button = page_buttons[page_number]
            try:
                # æ»šåŠ¨åˆ°æŒ‰é’®ä½ç½®
                self.driver.execute_script("arguments[0].scrollIntoView(true);", button)
                time.sleep(1)
                
                # å°è¯•æ™®é€šç‚¹å‡»
                button.click()
                print(f"  âœ… æˆåŠŸç‚¹å‡»ç¬¬ {page_number} é¡µæŒ‰é’®")
                time.sleep(3)  # ç­‰å¾…é¡µé¢åŠ è½½
                return True
                
            except Exception as click_error:
                print(f"  æ™®é€šç‚¹å‡»å¤±è´¥ï¼Œå°è¯•JavaScriptç‚¹å‡»: {click_error}")
                try:
                    self.driver.execute_script("arguments[0].click();", button)
                    print(f"  âœ… JavaScriptç‚¹å‡»æˆåŠŸ")
                    time.sleep(3)
                    return True
                except Exception as js_error:
                    print(f"  JavaScriptç‚¹å‡»ä¹Ÿå¤±è´¥: {js_error}")
        
        # å¦‚æœåœ¨å·²æ‰¾åˆ°çš„æŒ‰é’®ä¸­æ²¡æœ‰ï¼Œå°è¯•å®æ—¶æŸ¥æ‰¾
        print(f"  åœ¨é¢„å­˜æŒ‰é’®ä¸­æœªæ‰¾åˆ°ç¬¬ {page_number} é¡µï¼Œå°è¯•å®æ—¶æŸ¥æ‰¾...")
        xpath_selectors = [
            f"//a[text()='{page_number}']",
            f"//button[text()='{page_number}']",
            f"//span[text()='{page_number}']",
            f"//a[contains(@class, 'page') and text()='{page_number}']",
            f"//button[contains(@class, 'page') and text()='{page_number}']",
            f"//*[contains(@class, 'pagination')]//*[text()='{page_number}']",
            f"//a[@data-page='{page_number}']",
            f"//button[@data-page='{page_number}']"
        ]
        
        for xpath in xpath_selectors:
            try:
                button = self.driver.find_element(By.XPATH, xpath)
                if button.is_displayed():
                    # æ»šåŠ¨åˆ°æŒ‰é’®ä½ç½®
                    self.driver.execute_script("arguments[0].scrollIntoView(true);", button)
                    time.sleep(1)
                    
                    # å°è¯•ç‚¹å‡»
                    try:
                        button.click()
                        print(f"  âœ… å®æ—¶æ‰¾åˆ°å¹¶ç‚¹å‡»ç¬¬ {page_number} é¡µæŒ‰é’®")
                        time.sleep(3)
                        return True
                    except:
                        try:
                            self.driver.execute_script("arguments[0].click();", button)
                            print(f"  âœ… å®æ—¶æ‰¾åˆ°å¹¶JavaScriptç‚¹å‡»ç¬¬ {page_number} é¡µæŒ‰é’®")
                            time.sleep(3)
                            return True
                        except:
                            continue
            except:
                continue
        
        print(f"  âŒ æœªèƒ½ç‚¹å‡»ç¬¬ {page_number} é¡µæŒ‰é’®")
        return False
    
    def extract_page_data(self, page_num):
        """æå–å½“å‰é¡µé¢çš„æ•°æ®"""
        print(f"  ğŸ“„ æå–ç¬¬ {page_num} é¡µæ•°æ®...")
        
        page_datacenters = []
        
        try:
            # ç­‰å¾…é¡µé¢å†…å®¹åŠ è½½
            time.sleep(3)
            
            # ä¿å­˜é¡µé¢æºç 
            with open(f"html_sources/shanghai/real_page_{page_num}.html", 'w', encoding='utf-8') as f:
                f.write(self.driver.page_source)
            
            # ä»JavaScriptå˜é‡ä¸­æå–æ•°æ®
            js_commands = [
                "return window.datacenters || [];",
                "return window.locations || [];", 
                "return window.facilities || [];",
                "return window.markers || [];",
                "return window.mapData || [];",
                "return window.sites || [];",
            ]
            
            for cmd in js_commands:
                try:
                    result = self.driver.execute_script(cmd)
                    if result and isinstance(result, list):
                        for item in result:
                            if isinstance(item, dict) and 'latitude' in item and 'longitude' in item:
                                dc = {
                                    'name': item.get('name', item.get('title', f'æ•°æ®ä¸­å¿ƒ_{len(page_datacenters)+1}')),
                                    'latitude': float(item['latitude']),
                                    'longitude': float(item['longitude']),
                                    'location': 'ä¸Šæµ·å¸‚',
                                    'source_page': page_num,
                                    'extraction_method': 'JavaScript',
                                    'raw_data': item
                                }
                                
                                # éªŒè¯åæ ‡æ˜¯å¦åœ¨ä¸Šæµ·èŒƒå›´å†…
                                if 30.6 <= dc['latitude'] <= 31.9 and 120.8 <= dc['longitude'] <= 122.2:
                                    page_datacenters.append(dc)
                        
                        if result:
                            print(f"    ä» {cmd} è·å–åˆ° {len([x for x in result if isinstance(x, dict) and 'latitude' in x])} ä¸ªåæ ‡æ•°æ®")
                            break
                except:
                    continue
            
            # ä»DOMå…ƒç´ ä¸­æå–æ•°æ®
            coord_selectors = [
                '[data-lat]',
                '[data-latitude]',
                '.marker[data-coordinates]',
                '.datacenter-item',
                '.location-item'
            ]
            
            for selector in coord_selectors:
                try:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    for elem in elements:
                        try:
                            lat = elem.get_attribute('data-lat') or elem.get_attribute('data-latitude')
                            lng = elem.get_attribute('data-lng') or elem.get_attribute('data-longitude')
                            
                            if lat and lng:
                                lat, lng = float(lat), float(lng)
                                
                                name = (elem.get_attribute('title') or 
                                       elem.get_attribute('data-name') or
                                       elem.text.strip() or
                                       f"æ•°æ®ä¸­å¿ƒ_{len(page_datacenters)+1}")
                                
                                if 30.6 <= lat <= 31.9 and 120.8 <= lng <= 122.2:
                                    page_datacenters.append({
                                        'name': name,
                                        'latitude': lat,
                                        'longitude': lng,
                                        'location': 'ä¸Šæµ·å¸‚',
                                        'source_page': page_num,
                                        'extraction_method': 'DOM',
                                        'raw_data': {
                                            'element_tag': elem.tag_name,
                                            'attributes': {attr: elem.get_attribute(attr) for attr in ['data-lat', 'data-lng', 'title', 'data-name'] if elem.get_attribute(attr)}
                                        }
                                    })
                        except:
                            continue
                except:
                    continue
            
            print(f"    ç¬¬ {page_num} é¡µè·å–åˆ° {len(page_datacenters)} ä¸ªæ•°æ®ä¸­å¿ƒ")
            
        except Exception as e:
            print(f"    ç¬¬ {page_num} é¡µæ•°æ®æå–å¤±è´¥: {e}")
        
        return page_datacenters
    
    def run_crawler(self):
        """è¿è¡Œçˆ¬è™«ä¸»ç¨‹åº"""
        print("ğŸš€ å¼€å§‹çœŸå®é¡µç æŒ‰é’®ç‚¹å‡»çˆ¬è™«")
        print("ğŸ¯ ç›®æ ‡ï¼šé€šè¿‡ç‚¹å‡»é¡µé¢æŒ‰é’®è·å–æ‰€æœ‰æ•°æ®")
        print("ğŸ“„ é¢„æœŸï¼šç¬¬1é¡µ40ä¸ªï¼Œç¬¬2é¡µ14ä¸ªï¼Œå…±54ä¸ªæ•°æ®ä¸­å¿ƒ")
        print("="*70)
        
        if not self.setup_driver():
            return []
        
        try:
            # 1. åŠ è½½åˆå§‹é¡µé¢
            if not self.load_initial_page():
                return []
            
            # 2. æŸ¥æ‰¾æ‰€æœ‰é¡µç æŒ‰é’®
            page_buttons = self.find_page_buttons()
            
            if not page_buttons:
                print("âŒ æœªæ‰¾åˆ°ä»»ä½•é¡µç æŒ‰é’®ï¼Œå°è¯•è·å–ç¬¬ä¸€é¡µæ•°æ®")
                total_pages = 1
            else:
                total_pages = max(page_buttons.keys())
                print(f"ğŸ“Š æ£€æµ‹åˆ°æ€»é¡µæ•°: {total_pages}")
            
            # 3. é€é¡µçˆ¬å–æ•°æ®
            all_datacenters = []
            
            for page_num in range(1, total_pages + 1):
                print(f"\nğŸ“„ å¤„ç†ç¬¬ {page_num} é¡µ ({page_num}/{total_pages})")
                
                # å¦‚æœä¸æ˜¯ç¬¬ä¸€é¡µï¼Œéœ€è¦ç‚¹å‡»é¡µç æŒ‰é’®
                if page_num > 1:
                    success = self.click_page_button(page_num, page_buttons)
                    if not success:
                        print(f"    æ— æ³•ç‚¹å‡»ç¬¬ {page_num} é¡µæŒ‰é’®ï¼Œè·³è¿‡")
                        continue
                
                # æå–å½“å‰é¡µé¢æ•°æ®
                page_data = self.extract_page_data(page_num)
                if page_data:
                    all_datacenters.extend(page_data)
                    print(f"    âœ… ç¬¬ {page_num} é¡µè·å– {len(page_data)} ä¸ªæ•°æ®ä¸­å¿ƒ")
                else:
                    print(f"    âŒ ç¬¬ {page_num} é¡µæœªè·å–åˆ°æ•°æ®")
                
                # ä¿å­˜é¡µé¢æ•°æ®
                self.page_data[f'page_{page_num}'] = page_data
                
                time.sleep(2)  # é¡µé¢é—´å»¶è¿Ÿ
            
            # 4. æ•°æ®å»é‡
            unique_datacenters = self.deduplicate_datacenters(all_datacenters)
            
            print(f"\n{'='*70}")
            print(f"ğŸ“Š çˆ¬å–å®Œæˆç»Ÿè®¡:")
            print(f"  æ€»é¡µæ•°: {total_pages}")
            print(f"  åŸå§‹æ•°æ®: {len(all_datacenters)} ä¸ª")
            print(f"  å»é‡åæ•°æ®: {len(unique_datacenters)} ä¸ª")
            
            # æŒ‰é¡µç»Ÿè®¡
            for page_num in range(1, total_pages + 1):
                page_count = len(self.page_data.get(f'page_{page_num}', []))
                print(f"  ç¬¬ {page_num} é¡µ: {page_count} ä¸ªæ•°æ®ä¸­å¿ƒ")
            
            return unique_datacenters
            
        except Exception as e:
            print(f"âŒ çˆ¬å–è¿‡ç¨‹å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            return []
        
        finally:
            if self.driver:
                self.driver.quit()
    
    def deduplicate_datacenters(self, datacenters):
        """å»é‡æ•°æ®ä¸­å¿ƒ"""
        print(f"ğŸ”„ æ•°æ®å»é‡å¤„ç†...")
        
        unique_datacenters = []
        seen_coords = set()
        
        for dc in datacenters:
            # åŸºäºåæ ‡å»é‡ï¼ˆç²¾ç¡®åˆ°å°æ•°ç‚¹å5ä½ï¼‰
            coord_key = (round(dc['latitude'], 5), round(dc['longitude'], 5))
            
            if coord_key not in seen_coords:
                seen_coords.add(coord_key)
                unique_datacenters.append(dc)
        
        print(f"  å»é‡å‰: {len(datacenters)} ä¸ª")
        print(f"  å»é‡å: {len(unique_datacenters)} ä¸ª")
        
        return unique_datacenters
    
    def save_results(self, datacenters):
        """ä¿å­˜ç»“æœ"""
        if not datacenters:
            print("âŒ æ²¡æœ‰æ•°æ®éœ€è¦ä¿å­˜")
            return
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # ä¿å­˜JSONæ•°æ®
        json_file = f"data/shanghai/ä¸Šæµ·æ•°æ®ä¸­å¿ƒçœŸå®æŒ‰é’®ç‚¹å‡»_{timestamp}.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(datacenters, f, ensure_ascii=False, indent=2)
        print(f"âœ… JSONæ–‡ä»¶å·²ä¿å­˜: {json_file}")
        
        # ä¿å­˜CSVæ•°æ®
        csv_file = f"data/shanghai/ä¸Šæµ·æ•°æ®ä¸­å¿ƒçœŸå®æŒ‰é’®ç‚¹å‡»_{timestamp}.csv"
        with open(csv_file, 'w', encoding='utf-8', newline='') as f:
            f.write("åºå·,åç§°,çº¬åº¦,ç»åº¦,ä½ç½®,æ¥æºé¡µ,æå–æ–¹æ³•\n")
            for i, dc in enumerate(datacenters, 1):
                f.write(f"{i},{dc['name']},{dc['latitude']},{dc['longitude']},{dc['location']},ç¬¬{dc['source_page']}é¡µ,{dc['extraction_method']}\n")
        print(f"âœ… CSVæ–‡ä»¶å·²ä¿å­˜: {csv_file}")
        
        # ä¿å­˜åˆ†é¡µè¯¦æƒ…
        page_detail_file = f"data/shanghai/çœŸå®æŒ‰é’®ç¿»é¡µè¯¦æƒ…_{timestamp}.json"
        with open(page_detail_file, 'w', encoding='utf-8') as f:
            json.dump(self.page_data, f, ensure_ascii=False, indent=2)
        print(f"âœ… åˆ†é¡µè¯¦æƒ…å·²ä¿å­˜: {page_detail_file}")
        
        # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
        self.generate_detailed_report(datacenters, timestamp)
    
    def generate_detailed_report(self, datacenters, timestamp):
        """ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š"""
        report_file = f"data/shanghai/çœŸå®æŒ‰é’®ç‚¹å‡»æŠ¥å‘Š_{timestamp}.txt"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("ä¸Šæµ·æ•°æ®ä¸­å¿ƒçœŸå®é¡µç æŒ‰é’®ç‚¹å‡»çˆ¬å–æŠ¥å‘Š\n")
            f.write("="*60 + "\n\n")
            
            f.write(f"çˆ¬å–æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"çˆ¬å–æ–¹æ³•: SeleniumçœŸå®æŒ‰é’®ç‚¹å‡»\n")
            f.write(f"æ€»æ•°æ®ä¸­å¿ƒ: {len(datacenters)} ä¸ª\n")
            f.write(f"ç›®æ ‡å®Œæˆåº¦: {len(datacenters)}/54 ({len(datacenters)/54*100:.1f}%)\n\n")
            
            # æŒ‰é¡µç»Ÿè®¡
            f.write("åˆ†é¡µç»Ÿè®¡:\n")
            f.write("-"*30 + "\n")
            for page_num, page_data in self.page_data.items():
                f.write(f"{page_num}: {len(page_data)} ä¸ªæ•°æ®ä¸­å¿ƒ\n")
            f.write("\n")
            
            # æŒ‰æå–æ–¹æ³•ç»Ÿè®¡
            method_stats = {}
            for dc in datacenters:
                method = dc.get('extraction_method', 'æœªçŸ¥')
                method_stats[method] = method_stats.get(method, 0) + 1
            
            f.write("æå–æ–¹æ³•ç»Ÿè®¡:\n")
            f.write("-"*30 + "\n")
            for method, count in method_stats.items():
                f.write(f"{method}: {count} ä¸ª\n")
            f.write("\n")
            
            # è¯¦ç»†æ•°æ®åˆ—è¡¨
            f.write("æ•°æ®ä¸­å¿ƒè¯¦ç»†åˆ—è¡¨:\n")
            f.write("-"*30 + "\n")
            for i, dc in enumerate(datacenters, 1):
                f.write(f"{i:2d}. {dc['name']}\n")
                f.write(f"    åæ ‡: ({dc['latitude']:.6f}, {dc['longitude']:.6f})\n")
                f.write(f"    æ¥æºé¡µ: ç¬¬{dc['source_page']}é¡µ\n")
                f.write(f"    æå–æ–¹æ³•: {dc['extraction_method']}\n\n")
        
        print(f"âœ… è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_file}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ ä¸Šæµ·æ•°æ®ä¸­å¿ƒçœŸå®é¡µç æŒ‰é’®ç‚¹å‡»çˆ¬è™«")
    print("ğŸ–±ï¸ ä¸“é—¨é€šè¿‡Seleniumæ¨¡æ‹ŸçœŸå®ç‚¹å‡»é¡µé¢æŒ‰é’®è¿›è¡Œç¿»é¡µ")
    print("ğŸ“„ é¢„æœŸï¼šç¬¬1é¡µ40ä¸ªï¼Œç¬¬2é¡µ14ä¸ªï¼Œå…±54ä¸ªæ•°æ®ä¸­å¿ƒ")
    
    crawler = RealButtonCrawler()
    
    try:
        # è¿è¡Œçˆ¬è™«
        results = crawler.run_crawler()
        
        if results:
            print(f"\nğŸ‰ çˆ¬å–å®Œæˆï¼")
            print(f"âœ… è·å–åˆ° {len(results)} ä¸ªä¸Šæµ·æ•°æ®ä¸­å¿ƒ")
            
            # æ˜¾ç¤ºå‰10ä¸ªç»“æœ
            print(f"\nğŸ“‹ å‰10ä¸ªæ•°æ®ä¸­å¿ƒ:")
            for i, dc in enumerate(results[:10], 1):
                print(f"  {i:2d}. {dc['name']} (ç¬¬{dc['source_page']}é¡µ)")
            
            if len(results) > 10:
                print(f"     ... è¿˜æœ‰ {len(results) - 10} ä¸ª")
            
            # ä¿å­˜ç»“æœ
            crawler.save_results(results)
            
            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ç›®æ ‡
            if len(results) >= 54:
                print(f"\nğŸ¯ ç›®æ ‡è¾¾æˆï¼è·å–åˆ° {len(results)} ä¸ªæ•°æ®ä¸­å¿ƒ (ç›®æ ‡54ä¸ª)")
            else:
                print(f"\nâš ï¸ è·ç¦»ç›®æ ‡è¿˜å·® {54 - len(results)} ä¸ªæ•°æ®ä¸­å¿ƒ")
                print("ğŸ’¡ å»ºè®®ï¼šæ£€æŸ¥é¡µé¢æŒ‰é’®æ˜¯å¦æ­£ç¡®è¯†åˆ«å’Œç‚¹å‡»")
            
        else:
            print("âŒ æœªè·å–åˆ°ä»»ä½•æ•°æ®")
            print("ğŸ’¡ å»ºè®®ï¼šæ£€æŸ¥é¡µé¢ç»“æ„æˆ–ç½‘ç»œè¿æ¥")
            
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­çˆ¬å–")
    except Exception as e:
        print(f"âŒ çˆ¬å–è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
