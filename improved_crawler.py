#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸Šæµ·æ•°æ®ä¸­å¿ƒçœŸå®æŒ‰é’®ç‚¹å‡»çˆ¬è™« - æ”¹è¿›ç‰ˆ
åŸºäºæµ‹è¯•æˆåŠŸçš„æŒ‰é’®ç‚¹å‡»æŠ€æœ¯ï¼Œåº”ç”¨åˆ°çœŸå®ç½‘ç«™
å¢åŠ äº†ç½‘ç»œè¿æ¥é‡è¯•å’Œé”™è¯¯å¤„ç†
"""

import time
import os
import json
import requests
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.common.exceptions import TimeoutException, WebDriverException

class ShanghaiDatacenterCrawler:
    def __init__(self):
        self.base_url = "https://www.datacenters.com/locations/china/shanghai"
        
        # è®¾ç½®Chromeé€‰é¡¹
        self.chrome_options = Options()
        # ä¸ä½¿ç”¨æ— å¤´æ¨¡å¼ï¼Œä¾¿äºè°ƒè¯•ç½‘ç»œé—®é¢˜
        # self.chrome_options.add_argument('--headless')
        self.chrome_options.add_argument('--no-sandbox')
        self.chrome_options.add_argument('--disable-dev-shm-usage')
        self.chrome_options.add_argument('--disable-gpu')
        self.chrome_options.add_argument('--window-size=1920,1080')
        self.chrome_options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
        
        # ç½‘ç»œç›¸å…³é…ç½®
        self.chrome_options.add_argument('--ignore-certificate-errors')
        self.chrome_options.add_argument('--ignore-ssl-errors')
        self.chrome_options.add_argument('--allow-running-insecure-content')
        self.chrome_options.add_argument('--disable-web-security')
        self.chrome_options.add_argument('--disable-features=VizDisplayCompositor')
        # å¢åŠ è¶…æ—¶æ—¶é—´
        self.chrome_options.add_argument('--timeout=30')
        self.chrome_options.add_argument('--page-load-strategy=eager')
        
        self.driver = None
        self.all_datacenters = []
        self.page_data = {}
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs("data/shanghai", exist_ok=True)
        os.makedirs("html_sources/shanghai", exist_ok=True)
    
    def test_network_connection(self):
        """æµ‹è¯•ç½‘ç»œè¿æ¥"""
        print("ğŸŒ æµ‹è¯•ç½‘ç»œè¿æ¥...")
        
        test_urls = [
            "https://www.google.com",
            "https://www.baidu.com", 
            "https://httpbin.org/get",
            self.base_url
        ]
        
        for url in test_urls:
            try:
                response = requests.get(url, timeout=10, verify=False)
                print(f"  âœ… {url} - çŠ¶æ€ç : {response.status_code}")
                if url == self.base_url:
                    return True
            except Exception as e:
                print(f"  âŒ {url} - é”™è¯¯: {e}")
        
        return False
    
    def setup_driver(self):
        """åˆå§‹åŒ–WebDriver"""
        try:
            self.driver = webdriver.Chrome(options=self.chrome_options)
            self.driver.set_page_load_timeout(30)
            self.driver.implicitly_wait(10)
            print("âœ… WebDriveråˆå§‹åŒ–æˆåŠŸ")
            return True
        except Exception as e:
            print(f"âŒ WebDriveråˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    def load_page_with_retry(self, max_retries=3):
        """å¸¦é‡è¯•çš„é¡µé¢åŠ è½½"""
        print(f"ğŸŒ åŠ è½½ç›®æ ‡é¡µé¢ (æœ€å¤šé‡è¯•{max_retries}æ¬¡)...")
        
        for attempt in range(max_retries):
            try:
                print(f"  å°è¯• {attempt + 1}/{max_retries}: {self.base_url}")
                self.driver.get(self.base_url)
                
                # ç­‰å¾…é¡µé¢åŠ è½½
                WebDriverWait(self.driver, 15).until(
                    EC.presence_of_element_located((By.TAG_NAME, "body"))
                )
                
                # ä¿å­˜é¡µé¢æºç 
                with open("html_sources/shanghai/improved_initial_page.html", 'w', encoding='utf-8') as f:
                    f.write(self.driver.page_source)
                
                print("  âœ… é¡µé¢åŠ è½½æˆåŠŸ")
                return True
                
            except TimeoutException:
                print(f"  â° ç¬¬{attempt + 1}æ¬¡å°è¯•è¶…æ—¶")
                if attempt < max_retries - 1:
                    time.sleep(5)  # ç­‰å¾…5ç§’åé‡è¯•
                    
            except Exception as e:
                print(f"  âŒ ç¬¬{attempt + 1}æ¬¡å°è¯•å¤±è´¥: {e}")
                if attempt < max_retries - 1:
                    time.sleep(5)
        
        print("âŒ æ‰€æœ‰å°è¯•éƒ½å¤±è´¥äº†")
        return False
    
    def analyze_page_structure(self):
        """åˆ†æé¡µé¢ç»“æ„"""
        print("ğŸ” åˆ†æé¡µé¢ç»“æ„...")
        
        try:
            # åˆ†æé¡µé¢æ€»ä½“ç»“æ„
            title = self.driver.title
            print(f"  é¡µé¢æ ‡é¢˜: {title}")
            
            # æŸ¥æ‰¾å¯èƒ½çš„åˆ†é¡µå…ƒç´ 
            pagination_selectors = [
                ".pagination", ".pager", ".page-navigation", ".paginate",
                "[class*='pagination']", "[class*='pager']", 
                "[id*='pagination']", "[id*='pager']"
            ]
            
            pagination_found = False
            for selector in pagination_selectors:
                try:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    if elements:
                        print(f"  æ‰¾åˆ°åˆ†é¡µå®¹å™¨: {selector} ({len(elements)}ä¸ª)")
                        pagination_found = True
                except:
                    continue
            
            if not pagination_found:
                print("  âš ï¸ æœªæ‰¾åˆ°æ˜æ˜¾çš„åˆ†é¡µå®¹å™¨")
            
            # æŸ¥æ‰¾æ•°æ®å®¹å™¨
            data_selectors = [
                "[data-lat]", "[data-latitude]", ".marker", ".location",
                ".datacenter", ".facility", ".site"
            ]
            
            data_found = False
            for selector in data_selectors:
                try:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    if elements:
                        print(f"  æ‰¾åˆ°æ•°æ®å…ƒç´ : {selector} ({len(elements)}ä¸ª)")
                        data_found = True
                except:
                    continue
            
            if not data_found:
                print("  âš ï¸ æœªæ‰¾åˆ°æ˜æ˜¾çš„æ•°æ®å…ƒç´ ")
            
            # æ£€æŸ¥JavaScriptå˜é‡
            js_vars_to_check = [
                "window.datacenters", "window.locations", "window.facilities",
                "window.markers", "window.mapData", "window.sites"
            ]
            
            for var in js_vars_to_check:
                try:
                    result = self.driver.execute_script(f"return {var};")
                    if result:
                        print(f"  æ‰¾åˆ°JSå˜é‡: {var} (ç±»å‹: {type(result)}, é•¿åº¦: {len(result) if isinstance(result, (list, dict)) else 'N/A'})")
                except:
                    continue
            
            return True
            
        except Exception as e:
            print(f"  é¡µé¢ç»“æ„åˆ†æå¤±è´¥: {e}")
            return False
    
    def find_page_buttons_advanced(self):
        """é«˜çº§é¡µç æŒ‰é’®æŸ¥æ‰¾"""
        print("ğŸ” é«˜çº§é¡µç æŒ‰é’®æŸ¥æ‰¾...")
        
        page_buttons = {}
        
        # æ–¹æ³•1: é€šè¿‡onclickå±æ€§æŸ¥æ‰¾
        try:
            buttons = self.driver.find_elements(By.CSS_SELECTOR, "[onclick*='page'], [onclick*='Page']")
            for btn in buttons:
                text = btn.text.strip()
                if text.isdigit():
                    page_num = int(text)
                    page_buttons[page_num] = btn
                    print(f"  æ–¹æ³•1 - æ‰¾åˆ°é¡µç æŒ‰é’® {page_num}: {btn.get_attribute('onclick')}")
        except Exception as e:
            print(f"  æ–¹æ³•1å¤±è´¥: {e}")
        
        # æ–¹æ³•2: é€šè¿‡hrefå±æ€§æŸ¥æ‰¾
        try:
            links = self.driver.find_elements(By.CSS_SELECTOR, "a[href*='page'], a[href*='Page']")
            for link in links:
                text = link.text.strip()
                if text.isdigit():
                    page_num = int(text)
                    if page_num not in page_buttons:
                        page_buttons[page_num] = link
                        print(f"  æ–¹æ³•2 - æ‰¾åˆ°é¡µç é“¾æ¥ {page_num}: {link.get_attribute('href')}")
        except Exception as e:
            print(f"  æ–¹æ³•2å¤±è´¥: {e}")
        
        # æ–¹æ³•3: é€šè¿‡dataå±æ€§æŸ¥æ‰¾
        try:
            elements = self.driver.find_elements(By.CSS_SELECTOR, "[data-page]")
            for elem in elements:
                data_page = elem.get_attribute('data-page')
                if data_page and data_page.isdigit():
                    page_num = int(data_page)
                    if page_num not in page_buttons:
                        page_buttons[page_num] = elem
                        print(f"  æ–¹æ³•3 - æ‰¾åˆ°é¡µç å…ƒç´  {page_num}: data-page={data_page}")
        except Exception as e:
            print(f"  æ–¹æ³•3å¤±è´¥: {e}")
        
        # æ–¹æ³•4: é€šè¿‡XPathæŸ¥æ‰¾æ•°å­—æŒ‰é’®
        for i in range(1, 11):  # æŸ¥æ‰¾1-10é¡µ
            xpath_selectors = [
                f"//a[text()='{i}']",
                f"//button[text()='{i}']",
                f"//span[text()='{i}']",
                f"//*[contains(@class, 'page') and text()='{i}']",
                f"//*[contains(@class, 'pagination')]//*[text()='{i}']"
            ]
            
            for xpath in xpath_selectors:
                try:
                    elem = self.driver.find_element(By.XPATH, xpath)
                    if elem.is_displayed() and i not in page_buttons:
                        page_buttons[i] = elem
                        print(f"  æ–¹æ³•4 - XPathæ‰¾åˆ°é¡µç  {i}: {xpath}")
                        break
                except:
                    continue
        
        print(f"ğŸ”¢ æ€»å…±æ‰¾åˆ° {len(page_buttons)} ä¸ªé¡µç æŒ‰é’®: {list(page_buttons.keys())}")
        return page_buttons
    
    def click_page_button_robust(self, page_number, page_buttons):
        """å¥å£®çš„é¡µç æŒ‰é’®ç‚¹å‡»"""
        print(f"ğŸ–±ï¸ ç‚¹å‡»ç¬¬ {page_number} é¡µæŒ‰é’®...")
        
        if page_number not in page_buttons:
            print(f"  âŒ æœªæ‰¾åˆ°ç¬¬ {page_number} é¡µæŒ‰é’®")
            return False
        
        button = page_buttons[page_number]
        
        try:
            # ç¡®ä¿æŒ‰é’®å¯è§
            self.driver.execute_script("arguments[0].scrollIntoView(true);", button)
            time.sleep(1)
            
            # æ£€æŸ¥æŒ‰é’®çŠ¶æ€
            if not button.is_displayed():
                print(f"  âŒ æŒ‰é’®ä¸å¯è§")
                return False
            
            if not button.is_enabled():
                print(f"  âŒ æŒ‰é’®ä¸å¯ç‚¹å‡»")
                return False
            
            # å°è¯•å¤šç§ç‚¹å‡»æ–¹å¼
            click_methods = [
                ("æ™®é€šç‚¹å‡»", lambda: button.click()),
                ("JavaScriptç‚¹å‡»", lambda: self.driver.execute_script("arguments[0].click();", button)),
                ("åŠ¨ä½œé“¾ç‚¹å‡»", lambda: webdriver.ActionChains(self.driver).click(button).perform())
            ]
            
            for method_name, method_func in click_methods:
                try:
                    method_func()
                    print(f"  âœ… {method_name}æˆåŠŸ")
                    time.sleep(3)  # ç­‰å¾…é¡µé¢å“åº”
                    return True
                except Exception as e:
                    print(f"  {method_name}å¤±è´¥: {e}")
                    continue
            
            print(f"  âŒ æ‰€æœ‰ç‚¹å‡»æ–¹æ³•éƒ½å¤±è´¥äº†")
            return False
            
        except Exception as e:
            print(f"  âŒ ç‚¹å‡»è¿‡ç¨‹å‡ºé”™: {e}")
            return False
    
    def extract_data_comprehensive(self, page_num):
        """ç»¼åˆæ•°æ®æå–"""
        print(f"  ğŸ“„ æå–ç¬¬ {page_num} é¡µæ•°æ®...")
        
        datacenters = []
        
        try:
            # ç­‰å¾…é¡µé¢ç¨³å®š
            time.sleep(3)
            
            # ä¿å­˜å½“å‰é¡µé¢æºç 
            with open(f"html_sources/shanghai/improved_page_{page_num}.html", 'w', encoding='utf-8') as f:
                f.write(self.driver.page_source)
            
            # æ–¹æ³•1: ä»JavaScriptå˜é‡æå–
            js_commands = [
                "return window.datacenters || [];",
                "return window.locations || [];", 
                "return window.facilities || [];",
                "return window.markers || [];",
                "return window.mapData || [];",
                "return window.sites || [];",
            ]
            
            for cmd in js_commands:
                try:
                    result = self.driver.execute_script(cmd)
                    if result and isinstance(result, list):
                        for item in result:
                            if isinstance(item, dict) and ('latitude' in item or 'lat' in item) and ('longitude' in item or 'lng' in item):
                                lat = item.get('latitude', item.get('lat'))
                                lng = item.get('longitude', item.get('lng'))
                                
                                if lat and lng:
                                    dc = {
                                        'name': item.get('name', item.get('title', f'æ•°æ®ä¸­å¿ƒ_{len(datacenters)+1}')),
                                        'latitude': float(lat),
                                        'longitude': float(lng),
                                        'location': 'ä¸Šæµ·å¸‚',
                                        'source_page': page_num,
                                        'extraction_method': 'JavaScript',
                                        'raw_data': item
                                    }
                                    
                                    # éªŒè¯åæ ‡æ˜¯å¦åœ¨ä¸Šæµ·èŒƒå›´å†…
                                    if 30.6 <= dc['latitude'] <= 31.9 and 120.8 <= dc['longitude'] <= 122.2:
                                        datacenters.append(dc)
                        
                        if result:
                            print(f"    ä» {cmd} è·å–åˆ° {len([x for x in result if isinstance(x, dict) and ('latitude' in x or 'lat' in x)])} ä¸ªåæ ‡æ•°æ®")
                            break
                except:
                    continue
            
            # æ–¹æ³•2: ä»DOMå…ƒç´ æå–
            coord_selectors = [
                '[data-lat][data-lng]',
                '[data-latitude][data-longitude]',
                '.marker[data-coordinates]',
                '.datacenter-item',
                '.location-item'
            ]
            
            for selector in coord_selectors:
                try:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    for elem in elements:
                        try:
                            lat = (elem.get_attribute('data-lat') or 
                                  elem.get_attribute('data-latitude'))
                            lng = (elem.get_attribute('data-lng') or 
                                  elem.get_attribute('data-longitude'))
                            
                            if lat and lng:
                                lat, lng = float(lat), float(lng)
                                
                                name = (elem.get_attribute('title') or 
                                       elem.get_attribute('data-name') or
                                       elem.text.strip() or
                                       f"æ•°æ®ä¸­å¿ƒ_{len(datacenters)+1}")
                                
                                if 30.6 <= lat <= 31.9 and 120.8 <= lng <= 122.2:
                                    datacenters.append({
                                        'name': name,
                                        'latitude': lat,
                                        'longitude': lng,
                                        'location': 'ä¸Šæµ·å¸‚',
                                        'source_page': page_num,
                                        'extraction_method': 'DOM',
                                        'raw_data': {
                                            'selector': selector,
                                            'attributes': {attr: elem.get_attribute(attr) for attr in ['data-lat', 'data-lng', 'title', 'data-name'] if elem.get_attribute(attr)}
                                        }
                                    })
                        except:
                            continue
                except:
                    continue
            
            print(f"    ç¬¬ {page_num} é¡µè·å–åˆ° {len(datacenters)} ä¸ªæ•°æ®ä¸­å¿ƒ")
            
        except Exception as e:
            print(f"    ç¬¬ {page_num} é¡µæ•°æ®æå–å¤±è´¥: {e}")
        
        return datacenters
    
    def run_crawler(self):
        """è¿è¡Œæ”¹è¿›ç‰ˆçˆ¬è™«"""
        print("ğŸš€ å¼€å§‹ä¸Šæµ·æ•°æ®ä¸­å¿ƒæ”¹è¿›ç‰ˆçˆ¬è™«")
        print("ğŸ¯ ç›®æ ‡ï¼šé€šè¿‡çœŸå®æŒ‰é’®ç‚¹å‡»è·å–æ‰€æœ‰é¡µé¢æ•°æ®")
        print("ğŸ“„ é¢„æœŸï¼šç¬¬1é¡µ40ä¸ªï¼Œç¬¬2é¡µ14ä¸ªï¼Œå…±54ä¸ªæ•°æ®ä¸­å¿ƒ")
        print("="*70)
        
        # 1. æµ‹è¯•ç½‘ç»œè¿æ¥
        if not self.test_network_connection():
            print("âŒ ç½‘ç»œè¿æ¥æµ‹è¯•å¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
            return []
        
        # 2. åˆå§‹åŒ–WebDriver
        if not self.setup_driver():
            return []
        
        try:
            # 3. åŠ è½½é¡µé¢
            if not self.load_page_with_retry():
                print("âŒ é¡µé¢åŠ è½½å¤±è´¥")
                return []
            
            # 4. åˆ†æé¡µé¢ç»“æ„
            self.analyze_page_structure()
            
            # 5. æŸ¥æ‰¾é¡µç æŒ‰é’®
            page_buttons = self.find_page_buttons_advanced()
            
            if not page_buttons:
                print("âš ï¸ æœªæ‰¾åˆ°é¡µç æŒ‰é’®ï¼Œå°è¯•è·å–ç¬¬ä¸€é¡µæ•°æ®")
                total_pages = 1
            else:
                total_pages = max(page_buttons.keys())
                print(f"ğŸ“Š æ£€æµ‹åˆ°æ€»é¡µæ•°: {total_pages}")
            
            # 6. é€é¡µçˆ¬å–æ•°æ®
            all_datacenters = []
            
            for page_num in range(1, total_pages + 1):
                print(f"\nğŸ“„ å¤„ç†ç¬¬ {page_num} é¡µ ({page_num}/{total_pages})")
                
                # å¦‚æœä¸æ˜¯ç¬¬ä¸€é¡µï¼Œéœ€è¦ç‚¹å‡»é¡µç æŒ‰é’®
                if page_num > 1:
                    success = self.click_page_button_robust(page_num, page_buttons)
                    if not success:
                        print(f"    æ— æ³•ç‚¹å‡»ç¬¬ {page_num} é¡µæŒ‰é’®ï¼Œè·³è¿‡")
                        continue
                
                # æå–å½“å‰é¡µé¢æ•°æ®
                page_data = self.extract_data_comprehensive(page_num)
                if page_data:
                    all_datacenters.extend(page_data)
                    print(f"    âœ… ç¬¬ {page_num} é¡µè·å– {len(page_data)} ä¸ªæ•°æ®ä¸­å¿ƒ")
                    
                    # æ˜¾ç¤ºéƒ¨åˆ†æ•°æ®
                    for i, dc in enumerate(page_data[:3], 1):
                        print(f"      {i}. {dc['name']} ({dc['latitude']:.6f}, {dc['longitude']:.6f})")
                    if len(page_data) > 3:
                        print(f"      ... è¿˜æœ‰ {len(page_data) - 3} ä¸ª")
                else:
                    print(f"    âŒ ç¬¬ {page_num} é¡µæœªè·å–åˆ°æ•°æ®")
                
                # ä¿å­˜é¡µé¢æ•°æ®
                self.page_data[f'page_{page_num}'] = page_data
                
                time.sleep(2)  # é¡µé¢é—´å»¶è¿Ÿ
            
            # 7. æ•°æ®å»é‡å’Œç»Ÿè®¡
            unique_datacenters = self.deduplicate_datacenters(all_datacenters)
            
            print(f"\n{'='*70}")
            print(f"ğŸ“Š çˆ¬å–å®Œæˆç»Ÿè®¡:")
            print(f"  æ€»é¡µæ•°: {total_pages}")
            print(f"  åŸå§‹æ•°æ®: {len(all_datacenters)} ä¸ª")
            print(f"  å»é‡åæ•°æ®: {len(unique_datacenters)} ä¸ª")
            
            # æŒ‰é¡µç»Ÿè®¡
            for page_num in range(1, total_pages + 1):
                page_count = len(self.page_data.get(f'page_{page_num}', []))
                print(f"  ç¬¬ {page_num} é¡µ: {page_count} ä¸ªæ•°æ®ä¸­å¿ƒ")
            
            return unique_datacenters
            
        except Exception as e:
            print(f"âŒ çˆ¬å–è¿‡ç¨‹å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            return []
        
        finally:
            print("\nâ¸ï¸ æµè§ˆå™¨å°†åœ¨5ç§’åå…³é—­...")
            time.sleep(5)
            if self.driver:
                self.driver.quit()
    
    def deduplicate_datacenters(self, datacenters):
        """å»é‡æ•°æ®ä¸­å¿ƒ"""
        print(f"ğŸ”„ æ•°æ®å»é‡å¤„ç†...")
        
        unique_datacenters = []
        seen_coords = set()
        
        for dc in datacenters:
            # åŸºäºåæ ‡å»é‡ï¼ˆç²¾ç¡®åˆ°å°æ•°ç‚¹å5ä½ï¼‰
            coord_key = (round(dc['latitude'], 5), round(dc['longitude'], 5))
            
            if coord_key not in seen_coords:
                seen_coords.add(coord_key)
                unique_datacenters.append(dc)
        
        print(f"  å»é‡å‰: {len(datacenters)} ä¸ª")
        print(f"  å»é‡å: {len(unique_datacenters)} ä¸ª")
        
        return unique_datacenters
    
    def save_results(self, datacenters):
        """ä¿å­˜ç»“æœ"""
        if not datacenters:
            print("âŒ æ²¡æœ‰æ•°æ®éœ€è¦ä¿å­˜")
            return
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # ä¿å­˜JSONæ•°æ®
        json_file = f"data/shanghai/ä¸Šæµ·æ•°æ®ä¸­å¿ƒæ”¹è¿›ç‰ˆ_{timestamp}.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(datacenters, f, ensure_ascii=False, indent=2)
        print(f"âœ… JSONæ–‡ä»¶å·²ä¿å­˜: {json_file}")
        
        # ä¿å­˜CSVæ•°æ®
        csv_file = f"data/shanghai/ä¸Šæµ·æ•°æ®ä¸­å¿ƒæ”¹è¿›ç‰ˆ_{timestamp}.csv"
        with open(csv_file, 'w', encoding='utf-8', newline='') as f:
            f.write("åºå·,åç§°,çº¬åº¦,ç»åº¦,ä½ç½®,æ¥æºé¡µ,æå–æ–¹æ³•\n")
            for i, dc in enumerate(datacenters, 1):
                f.write(f"{i},{dc['name']},{dc['latitude']},{dc['longitude']},{dc['location']},ç¬¬{dc['source_page']}é¡µ,{dc['extraction_method']}\n")
        print(f"âœ… CSVæ–‡ä»¶å·²ä¿å­˜: {csv_file}")
        
        # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
        self.generate_report(datacenters, timestamp)
    
    def generate_report(self, datacenters, timestamp):
        """ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š"""
        report_file = f"data/shanghai/æ”¹è¿›ç‰ˆçˆ¬å–æŠ¥å‘Š_{timestamp}.txt"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("ä¸Šæµ·æ•°æ®ä¸­å¿ƒæ”¹è¿›ç‰ˆçˆ¬å–æŠ¥å‘Š\n")
            f.write("="*60 + "\n\n")
            
            f.write(f"çˆ¬å–æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"çˆ¬å–æ–¹æ³•: Seleniumæ”¹è¿›ç‰ˆçœŸå®æŒ‰é’®ç‚¹å‡»\n")
            f.write(f"æ€»æ•°æ®ä¸­å¿ƒ: {len(datacenters)} ä¸ª\n")
            f.write(f"ç›®æ ‡å®Œæˆåº¦: {len(datacenters)}/54 ({len(datacenters)/54*100:.1f}%)\n\n")
            
            # è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
            # ... (ç±»ä¼¼ä¹‹å‰çš„æŠ¥å‘Šæ ¼å¼)
        
        print(f"âœ… è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_file}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ ä¸Šæµ·æ•°æ®ä¸­å¿ƒæ”¹è¿›ç‰ˆçœŸå®æŒ‰é’®ç‚¹å‡»çˆ¬è™«")
    print("ğŸ”§ åŸºäºæˆåŠŸçš„æµ‹è¯•ï¼Œåº”ç”¨åˆ°çœŸå®ç½‘ç«™")
    print("ğŸ“„ é¢„æœŸï¼šç¬¬1é¡µ40ä¸ªï¼Œç¬¬2é¡µ14ä¸ªï¼Œå…±54ä¸ªæ•°æ®ä¸­å¿ƒ")
    
    crawler = ShanghaiDatacenterCrawler()
    
    try:
        # è¿è¡Œçˆ¬è™«
        results = crawler.run_crawler()
        
        if results:
            print(f"\nğŸ‰ çˆ¬å–å®Œæˆï¼")
            print(f"âœ… è·å–åˆ° {len(results)} ä¸ªä¸Šæµ·æ•°æ®ä¸­å¿ƒ")
            
            # ä¿å­˜ç»“æœ
            crawler.save_results(results)
            
            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ç›®æ ‡
            if len(results) >= 54:
                print(f"\nğŸ¯ ç›®æ ‡è¾¾æˆï¼è·å–åˆ° {len(results)} ä¸ªæ•°æ®ä¸­å¿ƒ (ç›®æ ‡54ä¸ª)")
            else:
                print(f"\nâš ï¸ è·ç¦»ç›®æ ‡è¿˜å·® {54 - len(results)} ä¸ªæ•°æ®ä¸­å¿ƒ")
                print("ğŸ’¡ å»ºè®®ï¼šæ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–é¡µé¢ç»“æ„å˜åŒ–")
            
        else:
            print("âŒ æœªè·å–åˆ°ä»»ä½•æ•°æ®")
            print("ğŸ’¡ å»ºè®®ï¼šæ£€æŸ¥ç½‘ç»œè¿æ¥ã€é¡µé¢ç»“æ„æˆ–é˜²æŠ¤æªæ–½")
            
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­çˆ¬å–")
    except Exception as e:
        print(f"âŒ çˆ¬å–è¿‡ç¨‹ä¸­å‡ºé”™: {e}")

if __name__ == "__main__":
    main()
