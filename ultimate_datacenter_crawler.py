#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æœ€ç»ˆå®Œæ•´ç‰ˆæ•°æ®ä¸­å¿ƒçˆ¬è™« - åŒ…å«æ‰€æœ‰å‘çŽ°çš„URLå˜ä½“
"""

import requests
import re
import json
import pandas as pd
import time

class UltimateDataCenterCrawler:
    def __init__(self):
        # åŒ…å«æ‰€æœ‰å‘çŽ°çš„URLå˜ä½“
        self.urls = {
            # å››å·çœçš„æ‰€æœ‰å˜ä½“
            "å››å·çœ-sichuan-sheng": "https://www.datacenters.com/locations/china/sichuan-sheng",
            "å››å·çœ-si-chuan-sheng": "https://www.datacenters.com/locations/china/si-chuan-sheng",  # æ–°å‘çŽ°ï¼
            "å››å·çœ-sichuan": "https://www.datacenters.com/locations/china/sichuan",
            
            # äº‘å—çœ
            "äº‘å—çœ-yunnan-sheng": "https://www.datacenters.com/locations/china/yunnan-sheng", 
            "äº‘å—çœ-yunnan": "https://www.datacenters.com/locations/china/yunnan",
            
            # è´µå·žçœ
            "è´µå·žçœ-guizhou-sheng": "https://www.datacenters.com/locations/china/guizhou-sheng",
            "è´µå·žçœ-guizhou": "https://www.datacenters.com/locations/china/guizhou",
        }
        
        self.province_mapping = {
            "å››å·çœ-sichuan-sheng": "å››å·çœ",
            "å››å·çœ-si-chuan-sheng": "å››å·çœ",
            "å››å·çœ-sichuan": "å››å·çœ",
            "äº‘å—çœ-yunnan-sheng": "äº‘å—çœ",
            "äº‘å—çœ-yunnan": "äº‘å—çœ",
            "è´µå·žçœ-guizhou-sheng": "è´µå·žçœ",
            "è´µå·žçœ-guizhou": "è´µå·žçœ"
        }
        
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }
        
        self.all_results = []
        self.unique_coordinates = set()
    
    def extract_data_from_page(self, content, source_key):
        """ä»Žé¡µé¢å†…å®¹ä¸­æå–æ•°æ®"""
        found_data = []
        
        try:
            # æå–åæ ‡
            latitudes = re.findall(r'"latitude":\s*([\d\.\-]+)', content)
            longitudes = re.findall(r'"longitude":\s*([\d\.\-]+)', content)
            
            print(f"  åæ ‡: {len(latitudes)} ä¸ªçº¬åº¦, {len(longitudes)} ä¸ªç»åº¦")
            
            if len(latitudes) != len(longitudes):
                print(f"  è­¦å‘Š: çº¬åº¦å’Œç»åº¦æ•°é‡ä¸åŒ¹é…")
                return []
            
            # æå–æ•°æ®ä¸­å¿ƒåç§°
            name_patterns = [
                r'"name":\s*"([^"]*(?:Data Center|IDC|æ•°æ®ä¸­å¿ƒ)[^"]*)"',
                r'"title":\s*"([^"]*(?:Data Center|IDC|æ•°æ®ä¸­å¿ƒ)[^"]*)"',
                r'"name":\s*"([^"]*(?:' + self.province_mapping[source_key].replace('çœ', '') + '|Sichuan|Yunnan|Guizhou|Chengdu|CTU)[^"]*)"',
            ]
            
            all_names = []
            for pattern in name_patterns:
                names = re.findall(pattern, content, re.IGNORECASE)
                all_names.extend(names)
            
            # åŽ»é‡åç§°
            unique_names = []
            seen_names = set()
            for name in all_names:
                clean_name = name.strip()
                if clean_name not in seen_names and len(clean_name) > 3 and len(clean_name) < 100:
                    unique_names.append(clean_name)
                    seen_names.add(clean_name)
            
            print(f"  åç§°: æ‰¾åˆ° {len(unique_names)} ä¸ªå”¯ä¸€åç§°")
            
            # ç»„åˆæ•°æ®
            province = self.province_mapping[source_key]
            
            for i, (lat, lng) in enumerate(zip(latitudes, longitudes)):
                try:
                    lat_f = float(lat)
                    lng_f = float(lng)
                    
                    # éªŒè¯åæ ‡èŒƒå›´
                    if not (20 <= lat_f <= 35 and 95 <= lng_f <= 115):
                        continue
                    
                    # æ£€æŸ¥æ˜¯å¦é‡å¤
                    coord_key = (round(lat_f, 6), round(lng_f, 6))
                    if coord_key in self.unique_coordinates:
                        print(f"  è·³è¿‡é‡å¤åæ ‡: ({lat_f}, {lng_f})")
                        continue
                    
                    self.unique_coordinates.add(coord_key)
                    
                    # é€‰æ‹©åç§°
                    if i < len(unique_names):
                        name = unique_names[i]
                    else:
                        name = f"{province}æ•°æ®ä¸­å¿ƒ{i+1}"
                    
                    data_center = {
                        'province': province,
                        'latitude': lat_f,
                        'longitude': lng_f,
                        'name': name,
                        'source': source_key,
                        'coordinates': f"{lat_f},{lng_f}",
                        'index': len(self.all_results) + len(found_data) + 1
                    }
                    
                    found_data.append(data_center)
                    print(f"  {len(found_data)}. {name} - ({lat_f:.6f}, {lng_f:.6f})")
                    
                except ValueError:
                    continue
            
        except Exception as e:
            print(f"  æ•°æ®æå–é”™è¯¯: {e}")
        
        return found_data
    
    def crawl_all_sources(self):
        """çˆ¬å–æ‰€æœ‰æ•°æ®æº"""
        print("æœ€ç»ˆå®Œæ•´ç‰ˆæ•°æ®ä¸­å¿ƒçˆ¬è™«å¯åŠ¨")
        print("åŒ…å«æ‰€æœ‰å‘çŽ°çš„URLå˜ä½“ï¼Œç‰¹åˆ«æ˜¯æ–°å‘çŽ°çš„ si-chuan-sheng")
        print("="*70)
        
        for source_key, url in self.urls.items():
            print(f"\næ­£åœ¨çˆ¬å–: {source_key}")
            print(f"URL: {url}")
            print("-" * 50)
            
            try:
                response = requests.get(url, headers=self.headers, timeout=30)
                
                if response.status_code != 200:
                    print(f"  è¯·æ±‚å¤±è´¥: {response.status_code}")
                    continue
                
                print(f"  é¡µé¢å¤§å°: {len(response.text)} å­—ç¬¦")
                
                # æå–æ•°æ®
                page_data = self.extract_data_from_page(response.text, source_key)
                
                if page_data:
                    self.all_results.extend(page_data)
                    print(f"  âœ… æˆåŠŸæå–: {len(page_data)} ä¸ªæ•°æ®ä¸­å¿ƒ")
                else:
                    print(f"  âŒ æœªæ‰¾åˆ°æ•°æ®")
                
                # ä¿å­˜é¡µé¢æºç ç”¨äºŽè°ƒè¯•
                filename = f"{source_key.replace('-', '_')}_source.html"
                with open(filename, 'w', encoding='utf-8') as f:
                    f.write(response.text)
                
                # è¯·æ±‚é—´éš”
                time.sleep(2)
                
            except Exception as e:
                print(f"  âŒ çˆ¬å–å¤±è´¥: {e}")
        
        print(f"\n{'='*70}")
        print(f"ðŸŽ‰ çˆ¬å–å®Œæˆï¼æ€»è®¡æ‰¾åˆ° {len(self.all_results)} ä¸ªæ•°æ®ä¸­å¿ƒ")
        
        return self.all_results
    
    def save_ultimate_results(self):
        """ä¿å­˜æœ€ç»ˆå®Œæ•´ç»“æžœ"""
        if not self.all_results:
            print("æ²¡æœ‰æ•°æ®éœ€è¦ä¿å­˜")
            return
        
        # æŒ‰çœä»½ç»Ÿè®¡
        province_stats = {}
        for result in self.all_results:
            province = result['province']
            province_stats[province] = province_stats.get(province, 0) + 1
        
        print(f"\nðŸ“Š æœ€ç»ˆç»Ÿè®¡:")
        total = sum(province_stats.values())
        for province, count in province_stats.items():
            print(f"  {province}: {count} ä¸ªæ•°æ®ä¸­å¿ƒ")
        print(f"  æ€»è®¡: {total} ä¸ªæ•°æ®ä¸­å¿ƒ")
        
        # ä¿å­˜CSV
        csv_file = "æœ€ç»ˆå®Œæ•´ä¸‰çœæ•°æ®ä¸­å¿ƒåæ ‡.csv"
        try:
            df = pd.DataFrame(self.all_results)
            df.to_csv(csv_file, index=False, encoding='utf-8-sig')
            print(f"\nâœ… CSVæ–‡ä»¶å·²ä¿å­˜: {csv_file}")
        except Exception as e:
            print(f"âŒ ä¿å­˜CSVå¤±è´¥: {e}")
        
        # ä¿å­˜JSON
        json_file = "æœ€ç»ˆå®Œæ•´ä¸‰çœæ•°æ®ä¸­å¿ƒåæ ‡.json"
        try:
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(self.all_results, f, ensure_ascii=False, indent=2)
            print(f"âœ… JSONæ–‡ä»¶å·²ä¿å­˜: {json_file}")
        except Exception as e:
            print(f"âŒ ä¿å­˜JSONå¤±è´¥: {e}")
        
        # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        self.generate_ultimate_report()
    
    def generate_ultimate_report(self):
        """ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"""
        report_file = "æœ€ç»ˆå®Œæ•´æ•°æ®ä¸­å¿ƒæŠ¥å‘Š.txt"
        
        try:
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write("æœ€ç»ˆå®Œæ•´ä¸‰çœæ•°æ®ä¸­å¿ƒåˆ†å¸ƒæŠ¥å‘Š\n")
                f.write("=" * 60 + "\n\n")
                
                f.write(f"çˆ¬å–æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"æ€»æ•°æ®ä¸­å¿ƒæ•°é‡: {len(self.all_results)}\n\n")
                
                f.write("åŒ…å«çš„æ•°æ®æº:\n")
                f.write("-" * 30 + "\n")
                source_stats = {}
                for result in self.all_results:
                    source = result['source']
                    source_stats[source] = source_stats.get(source, 0) + 1
                
                for source, count in source_stats.items():
                    f.write(f"{source}: {count} ä¸ªæ•°æ®ä¸­å¿ƒ\n")
                
                # æŒ‰çœä»½åˆ†ç»„
                province_data = {}
                for result in self.all_results:
                    province = result['province']
                    if province not in province_data:
                        province_data[province] = []
                    province_data[province].append(result)
                
                f.write(f"\nå„çœä»½åˆ†å¸ƒ:\n")
                f.write("-" * 20 + "\n")
                for province, data in province_data.items():
                    f.write(f"{province}: {len(data)} ä¸ªæ•°æ®ä¸­å¿ƒ\n")
                
                f.write(f"\nè¯¦ç»†åˆ—è¡¨:\n")
                f.write("-" * 20 + "\n")
                
                for province, data in province_data.items():
                    f.write(f"\n{province} ({len(data)} ä¸ª):\n")
                    for i, dc in enumerate(data, 1):
                        f.write(f"  {i:2d}. {dc['name']}\n")
                        f.write(f"      åæ ‡: ({dc['latitude']:.6f}, {dc['longitude']:.6f})\n")
                        f.write(f"      æ¥æº: {dc['source']}\n\n")
                
                # æ–°å‘çŽ°çš„æ•°æ®
                f.write(f"ðŸ” æ–°å‘çŽ°çš„é‡è¦æ•°æ®æº:\n")
                f.write(f"si-chuan-sheng URL: å‘çŽ°äº†é¢å¤–çš„ {source_stats.get('å››å·çœ-si-chuan-sheng', 0)} ä¸ªæ•°æ®ä¸­å¿ƒ\n")
                f.write(f"è¿™ä¸ªURLä¹‹å‰è¢«é—æ¼ï¼ŒåŒ…å«é‡è¦çš„å››å·çœæ•°æ®ä¸­å¿ƒä¿¡æ¯\n\n")
                
                # åæ ‡èŒƒå›´åˆ†æž
                if self.all_results:
                    lats = [r['latitude'] for r in self.all_results]
                    lngs = [r['longitude'] for r in self.all_results]
                    
                    f.write(f"åæ ‡èŒƒå›´åˆ†æž:\n")
                    f.write(f"  çº¬åº¦èŒƒå›´: {min(lats):.6f} ~ {max(lats):.6f}\n")
                    f.write(f"  ç»åº¦èŒƒå›´: {min(lngs):.6f} ~ {max(lngs):.6f}\n")
            
            print(f"âœ… æœ€ç»ˆæŠ¥å‘Šå·²ä¿å­˜: {report_file}")
            
        except Exception as e:
            print(f"âŒ ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")
    
    def display_results(self):
        """æ˜¾ç¤ºç»“æžœ"""
        if not self.all_results:
            print("æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ•°æ®")
            return
        
        print(f"\n{'='*80}")
        print(f"ðŸŽ¯ æœ€ç»ˆå®Œæ•´çˆ¬å–ç»“æžœ")
        print(f"{'='*80}")
        
        # æŒ‰çœä»½åˆ†ç»„æ˜¾ç¤º
        province_data = {}
        for result in self.all_results:
            province = result['province']
            if province not in province_data:
                province_data[province] = []
            province_data[province].append(result)
        
        for province, data in province_data.items():
            print(f"\nðŸ“ {province} ({len(data)} ä¸ªæ•°æ®ä¸­å¿ƒ):")
            print("-" * 50)
            for i, dc in enumerate(data, 1):
                print(f"{i:2d}. {dc['name']}")
                print(f"    åæ ‡: ({dc['latitude']:.6f}, {dc['longitude']:.6f})")
                print(f"    æ¥æº: {dc['source']}")

def main():
    """ä¸»å‡½æ•°"""
    print("ðŸš€ å¯åŠ¨æœ€ç»ˆå®Œæ•´ç‰ˆæ•°æ®ä¸­å¿ƒçˆ¬è™«")
    print("ðŸ” åŒ…å«æ–°å‘çŽ°çš„ si-chuan-sheng URL")
    
    crawler = UltimateDataCenterCrawler()
    
    try:
        # çˆ¬å–æ‰€æœ‰æ•°æ®
        results = crawler.crawl_all_sources()
        
        if results:
            # æ˜¾ç¤ºç»“æžœ
            crawler.display_results()
            
            # ä¿å­˜æ•°æ®
            crawler.save_ultimate_results()
            
            print(f"\nðŸŽ‰ ä»»åŠ¡å®Œæˆï¼")
            print(f"âœ… æˆåŠŸèŽ·å– {len(results)} ä¸ªæ•°æ®ä¸­å¿ƒ")
            print(f"âœ… åŒ…å«æ–°å‘çŽ°çš„ si-chuan-sheng æ•°æ®æº")
            print(f"âœ… åŒ…å«æ‰€æœ‰ Sichuanã€Si Chuan Shengã€Guizhou æ•°æ®")
            print(f"âœ… æ•°æ®å·²ä¿å­˜ä¸ºæœ€ç»ˆå®Œæ•´ç‰ˆæœ¬")
            
            print(f"\nðŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
            print(f"  - æœ€ç»ˆå®Œæ•´ä¸‰çœæ•°æ®ä¸­å¿ƒåæ ‡.csv")
            print(f"  - æœ€ç»ˆå®Œæ•´ä¸‰çœæ•°æ®ä¸­å¿ƒåæ ‡.json")
            print(f"  - æœ€ç»ˆå®Œæ•´æ•°æ®ä¸­å¿ƒæŠ¥å‘Š.txt")
        else:
            print("âŒ æœªèŽ·å–åˆ°ä»»ä½•æ•°æ®")
            
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­ä»»åŠ¡")
    except Exception as e:
        print(f"âŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºé”™: {e}")

if __name__ == "__main__":
    main()
